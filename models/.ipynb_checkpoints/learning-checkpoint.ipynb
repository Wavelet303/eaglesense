{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../data/topviewkinect/\"\n",
    "\n",
    "PREPROCESSED_DIRECTORY = DATA_DIRECTORY + \"all/\"\n",
    "\n",
    "DATA_ALL = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for dataset_id in next(os.walk(DATA_DIRECTORY))[1]:\n",
    "    if not dataset_id.isdigit():\n",
    "        continue\n",
    "\n",
    "    features_csv = \"{data_dir}/{dataset_id}/features.csv\".format(data_dir=DATA_DIRECTORY, dataset_id=dataset_id)\n",
    "    features_df = pd.read_csv(features_csv)\n",
    "    labels_csv = \"{data_dir}/{dataset_id}/labels.csv\".format(data_dir=DATA_DIRECTORY, dataset_id=dataset_id)\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "    \n",
    "    if -1 in labels_df[\"activity\"].values:\n",
    "        print(dataset_id, \"missing labels\")\n",
    "    \n",
    "    if 1 in labels_df[\"skeleton_id\"].values:\n",
    "        print(dataset_id, \"multiple people labels\")\n",
    "\n",
    "    if 1 in features_df[\"skeleton_id\"].values:\n",
    "        print(dataset_id, \"multiple people features\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ignored_features_cols = [\"frame_id\", \"skeleton_id\", \"x\", \"y\", \"z\"]\n",
    "ignored_labels_cols = [\"frame_id\", \"skeleton_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_csv = \"{data_dir}/{data}_features.csv\".format(data_dir=PREPROCESSED_DIRECTORY, data=DATA_ALL)\n",
    "all_labels_csv = \"{data_dir}/{data}_labels.csv\".format(data_dir=PREPROCESSED_DIRECTORY, data=DATA_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , 10 , 11 , 12 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Overwrite previous data files\n",
    "open(all_features_csv, \"w\").close()\n",
    "open(all_labels_csv, \"w\").close()\n",
    "\n",
    "# Open data files\n",
    "all_features_f = open(all_features_csv, \"a\")\n",
    "all_labels_f = open(all_labels_csv, \"a\")\n",
    "header=True\n",
    "\n",
    "for dataset_id in next(os.walk(DATA_DIRECTORY))[1]:\n",
    "    if not dataset_id.isdigit():\n",
    "        continue\n",
    "    else:\n",
    "        print(dataset_id, \", \", end=\"\")\n",
    "\n",
    "    features_csv = \"{data_dir}/{dataset_id}/features.csv\".format(data_dir=DATA_DIRECTORY, dataset_id=dataset_id)\n",
    "    features_df = pd.read_csv(features_csv, low_memory=False)\n",
    "    labels_csv = \"{data_dir}/{dataset_id}/labels.csv\".format(data_dir=DATA_DIRECTORY, dataset_id=dataset_id)\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "    # Keep only tracking skeletons\n",
    "    labels_df = labels_df.loc[labels_df[\"skeleton_id\"] == 0]\n",
    "    labels_df = labels_df.loc[labels_df[\"activity\"] != 6]\n",
    "    frame_indices = labels_df[\"frame_id\"].values\n",
    "    \n",
    "    features_df = features_df.loc[features_df[\"frame_id\"].isin(frame_indices)]\n",
    "    labels_df = labels_df.loc[labels_df[\"frame_id\"].isin(features_df[\"frame_id\"].values)]\n",
    "    \n",
    "    # Append features and labels\n",
    "    features_df = features_df.drop(labels=ignored_features_cols, axis=1)\n",
    "    features_df[\"subject\"] = int(dataset_id)\n",
    "    features_df = features_df.astype(np.float32)\n",
    "    features_df.to_csv(all_features_f, header=header, index=False)\n",
    "    \n",
    "    labels_df = labels_df.drop(labels=ignored_labels_cols, axis=1)\n",
    "    labels_df[\"subject\"] = int(dataset_id)\n",
    "    labels_df = labels_df.astype(np.int)\n",
    "    labels_df.to_csv(all_labels_f, header=header, index=False)\n",
    "    \n",
    "    header = False\n",
    "    \n",
    "all_features_f.close()\n",
    "all_labels_f.close()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features_df = pd.read_csv(all_features_csv)\n",
    "all_labels_df = pd.read_csv(all_labels_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77024, 73)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_area_0</th>\n",
       "      <th>layer_area_1</th>\n",
       "      <th>layer_area_2</th>\n",
       "      <th>layer_contours_0</th>\n",
       "      <th>layer_contours_1</th>\n",
       "      <th>layer_distance_0</th>\n",
       "      <th>layer_distance_1</th>\n",
       "      <th>layer_distance_2</th>\n",
       "      <th>layer_distance_3</th>\n",
       "      <th>layer_distance_4</th>\n",
       "      <th>...</th>\n",
       "      <th>interlayer_pos_16</th>\n",
       "      <th>interlayer_pos_17</th>\n",
       "      <th>extremities0</th>\n",
       "      <th>extreme_infrared_0</th>\n",
       "      <th>extreme_infrared_1</th>\n",
       "      <th>extreme_infrared_2</th>\n",
       "      <th>extreme_infrared_3</th>\n",
       "      <th>extreme_infrared_4</th>\n",
       "      <th>extreme_infrared_5</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.297578</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.290657</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.552900</td>\n",
       "      <td>26.683300</td>\n",
       "      <td>26.019199</td>\n",
       "      <td>26.683300</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.419238</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.401199</td>\n",
       "      <td>26.476400</td>\n",
       "      <td>26.019199</td>\n",
       "      <td>26.476400</td>\n",
       "      <td>191.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318015</td>\n",
       "      <td>0.386029</td>\n",
       "      <td>0.295956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.124500</td>\n",
       "      <td>26.248800</td>\n",
       "      <td>27.018499</td>\n",
       "      <td>26.248800</td>\n",
       "      <td>174.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348399</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.267420</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.401199</td>\n",
       "      <td>26.419701</td>\n",
       "      <td>26.476400</td>\n",
       "      <td>26.419701</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.370567</td>\n",
       "      <td>0.273050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>27.459101</td>\n",
       "      <td>27.459101</td>\n",
       "      <td>27.459101</td>\n",
       "      <td>164.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer_area_0  layer_area_1  layer_area_2  layer_contours_0  \\\n",
       "0      0.297578      0.411765      0.290657               3.0   \n",
       "1      0.310345      0.419238      0.270417               3.0   \n",
       "2      0.318015      0.386029      0.295956               3.0   \n",
       "3      0.348399      0.384181      0.267420               3.0   \n",
       "4      0.356383      0.370567      0.273050               3.0   \n",
       "\n",
       "   layer_contours_1  layer_distance_0  layer_distance_1  layer_distance_2  \\\n",
       "0               3.0         16.552900         26.683300         26.019199   \n",
       "1               3.0         16.401199         26.476400         26.019199   \n",
       "2               3.0         16.124500         26.248800         27.018499   \n",
       "3               3.0         16.401199         26.419701         26.476400   \n",
       "4               3.0         17.719999         27.459101         27.459101   \n",
       "\n",
       "   layer_distance_3  layer_distance_4   ...     interlayer_pos_16  \\\n",
       "0         26.683300             201.0   ...                 -26.0   \n",
       "1         26.476400             191.5   ...                 -26.0   \n",
       "2         26.248800             174.5   ...                 -26.0   \n",
       "3         26.419701             164.0   ...                 -25.0   \n",
       "4         27.459101             164.5   ...                 -26.0   \n",
       "\n",
       "   interlayer_pos_17  extremities0  extreme_infrared_0  extreme_infrared_1  \\\n",
       "0             -107.0           4.0                 0.0                10.0   \n",
       "1             -105.0           5.0                 0.5                 9.0   \n",
       "2             -104.0           5.0                 0.0                12.5   \n",
       "3             -103.0           5.0                 0.0                 6.0   \n",
       "4             -107.0           3.0                 0.0                 0.0   \n",
       "\n",
       "   extreme_infrared_2  extreme_infrared_3  extreme_infrared_4  \\\n",
       "0                11.5                11.5                 0.0   \n",
       "1                11.0                 1.0                 0.5   \n",
       "2                 4.5                 4.5                 0.5   \n",
       "3                 4.5                 0.0                 0.0   \n",
       "4                 0.5                 0.0                 0.0   \n",
       "\n",
       "   extreme_infrared_5  subject  \n",
       "0                11.5      1.0  \n",
       "1                11.0      1.0  \n",
       "2                13.0      1.0  \n",
       "3                 7.0      1.0  \n",
       "4                 0.5      1.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77024, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>orientation</th>\n",
       "      <th>orientation_accurate</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  orientation  orientation_accurate  subject\n",
       "0         0          130                    -1        1\n",
       "1         0          130                    -1        1\n",
       "2         0          120                    -1        1\n",
       "3         0          130                    -1        1\n",
       "4         0          150                    -1        1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_list = np.unique(all_labels_df[\"subject\"])\n",
    "subjects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_list = np.unique(all_labels_df[\"activity\"])\n",
    "activities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = all_features_df.drop(labels=\"subject\", axis=1).values\n",
    "y = all_labels_df[\"activity\"].values.ravel()\n",
    "all_dmatrix = xgb.DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Cross-Subject Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# odd-numbered subjects as training subject\n",
    "\n",
    "initial_cs_odd = [subject for subject in subjects_list if subject % 2 == 1]\n",
    "initial_cs_even = [subject for subject in subjects_list if subject % 2 == 0]\n",
    "initial_cs_split = [\n",
    "    {\"train\": initial_cs_odd, \"test\": initial_cs_even}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INITIAL_CS_SPLIT_FN = \"{data_dir}/{data}_split_init_cs.pickle\".format(data_dir=PREPROCESSED_DIRECTORY, data=DATA_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(INITIAL_CS_SPLIT_FN, \"wb\") as f:\n",
    "    pickle.dump(initial_cs_split, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Cross-Subject Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_cs_train_indices = list(itertools.combinations(subjects_list, int(len(subjects_list)/2)))\n",
    "complete_cs_split = [\n",
    "    {\n",
    "        \"train\": list(train_indices),\n",
    "        \"test\": list(set(subjects_list) - set(train_indices))\n",
    "    } for train_indices in complete_cs_train_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_cs_split_fn = \"{data_dir}/{data}_split_complete_cs.pickle\".format(data_dir=PREPROCESSED_DIRECTORY, data=DATA_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(complete_cs_split_fn, \"wb\") as f:\n",
    "    pickle.dump(complete_cs_split, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Subject-Fold (10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_subject_split = [\n",
    "    {\n",
    "        \"train\": list(set(subjects_list) - {test_idx}),\n",
    "        \"test\": [test_idx]\n",
    "    } for test_idx in subjects_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_subject_split_fn = \"{data_dir}/{data}_split_n_subject.pickle\".format(data_dir=PREPROCESSED_DIRECTORY, data=DATA_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(n_subject_split_fn, \"wb\") as f:\n",
    "    pickle.dump(n_subject_split, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Cross-Subject Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(INITIAL_CS_SPLIT_FN, \"rb\") as f:\n",
    "    initial_cs_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test': [2, 4, 6, 8, 10, 12], 'train': [1, 3, 5, 7, 9, 11]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_cs_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_cs_X_train_df = all_features_df[all_features_df[\"subject\"].isin(initial_cs_split[0][\"train\"])].reset_index()\n",
    "initial_cs_y_train_df = all_labels_df[all_labels_df[\"subject\"].isin(initial_cs_split[0][\"train\"])].reset_index()\n",
    "\n",
    "initial_cs_X_test_df = all_features_df[all_features_df[\"subject\"].isin(initial_cs_split[0][\"test\"])].reset_index()\n",
    "initial_cs_y_test_df = all_labels_df[all_labels_df[\"subject\"].isin(initial_cs_split[0][\"test\"])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation - tune parameters\n",
    "\n",
    "xgboost_clf = xgb.XGBClassifier(learning_rate=0.3, n_estimators=100, objective=\"multi:softmax\", seed=42)\n",
    "\n",
    "xgboost_knobs = {\n",
    "    \"max_depth\": [5, 6, 7, 8],\n",
    "    \"gamma\": [1, 2, 3],\n",
    "    \"reg_lambda\": [1, 2, 3],\n",
    "    \"reg_alpha\": [1, 2, 3],\n",
    "    \"subsample\": [0.5, 0.8, 1],\n",
    "    \"colsample_bytree\": [0.5, 0.8, 1],\n",
    "    \"colsample_bylevel\": [0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "# 5-fold-subject CV \n",
    "initial_cs_train_val_cv = []\n",
    "for subject_idx in initial_cs_split[0][\"train\"]:\n",
    "    train_indices = initial_cs_y_train_df[initial_cs_y_train_df[\"subject\"] != subject_idx].index.tolist()\n",
    "    validation_indices = initial_cs_y_train_df[initial_cs_y_train_df[\"subject\"] == subject_idx].index.tolist()\n",
    "    initial_cs_train_val_cv.append((train_indices, validation_indices))\n",
    "\n",
    "initial_cs_params_search = model_selection.RandomizedSearchCV(\n",
    "    xgboost_clf, param_distributions=xgboost_knobs, cv=initial_cs_train_val_cv,\n",
    "    n_iter=50, random_state=42, verbose=2, n_jobs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get X and y values\n",
    "\n",
    "initial_cs_X_train = initial_cs_X_train_df.drop(labels=\"subject\", axis=1).values\n",
    "initial_cs_y_train = initial_cs_y_train_df[\"activity\"].values.ravel()\n",
    "\n",
    "initial_cs_X_test = initial_cs_X_test_df.drop(labels=\"subject\", axis=1).values\n",
    "initial_cs_y_test = initial_cs_y_test_df[\"activity\"].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 50 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 58.8min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed: 110.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[([5589, 5590, 5591, 5592, 5593, 5594, 5595, 5596, 5597, 5598, 5599, 5600, 5601, 5602, 5603, 5604, 5605, 5606, 5607, 5608, 5609, 5610, 5611, 5612, 5613, 5614, 5615, 5616, 5617, 5618, 5619, 5620, 5621, 5622, 5623, 5624, 5625, 5626, 5627, 5628, 5629, 5630, 5631, 5632, 5633, 5634, 5635, 5636, 5637, ... 15105, 15106, 15107, 15108, 15109, 15110, 15111, 15112, 15113, 15114, 15115, 15116, 15117, 15118])],\n",
       "          error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softmax', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1),\n",
       "          fit_params={}, iid=True, n_iter=50, n_jobs=4,\n",
       "          param_distributions={'max_depth': [5, 6, 7, 8], 'gamma': [1, 2, 3], 'reg_lambda': [1, 2, 3], 'reg_alpha': [1, 2, 3], 'subsample': [0.5, 0.8, 1], 'colsample_bytree': [0.5, 0.8, 1], 'colsample_bylevel': [0.5, 0.8, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_cs_params_search.fit(initial_cs_X_train, initial_cs_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"results/init_cs_params\", \"wb\") as f:\n",
    "    pickle.dump(initial_cs_params_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.5,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'gamma': 2,\n",
       " 'max_depth': 8,\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 3,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_cs_params_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INITIAL_CS_PARAMS = {\n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 8,\n",
    "    \"gamma\": 2,\n",
    "    \"lambda\": 3,\n",
    "    \"alpha\": 1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"colsample_bylevel\": 0.5,\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"eval_metric\": \"merror\",\n",
    "    \"num_class\": len(activities_list),\n",
    "    \"silent\": 0\n",
    "}\n",
    "NUM_ROUNDS = 100\n",
    "NUM_EARLYSTOPPING_ROUNDS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [3, 3, 3]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,1,1],[2,2,2],[3,3,3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Find best number of iterations(boosting rounds)\n",
    "\n",
    "initial_cs_boosting_errors = []\n",
    "\n",
    "for cv_index, (train_indices, validation_indices) in enumerate(initial_cs_train_val_cv):\n",
    "    X_train = np.take(initial_cs_X_train, train_indices, axis=0)\n",
    "    y_train = np.take(initial_cs_y_train, train_indices, axis=0)\n",
    "    X_validation = np.take(initial_cs_X_train, validation_indices, axis=0)\n",
    "    y_validation = np.take(initial_cs_y_train, validation_indices, axis=0)\n",
    "    \n",
    "    train_dmatrix = xgb.DMatrix(X_train, y_train)\n",
    "    validation_dmatrix = xgb.DMatrix(X_validation, y_validation)\n",
    "    watchlist = [(train_dmatrix, \"train\"), (validation_dmatrix, \"eval\")]\n",
    "    results = {}\n",
    "    \n",
    "    xgb.train(params=INITIAL_CS_PARAMS, dtrain=train_dmatrix, evals=watchlist, evals_result=results,\n",
    "                 num_boost_round=NUM_ROUNDS, verbose_eval=NUM_ROUNDS/2)\n",
    "    initial_cs_boosting_errors.append(results[\"eval\"][\"merror\"])\n",
    "    print(\"CV - finding best number of boosting rounds\", cv_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average across results\n",
    "\n",
    "initial_cs_boosting_errors_avg = [sum(errors) / len(initial_cs_train_val_cv) for errors in zip(*initial_cs_boosting_errors)]\n",
    "initial_cs_boosting_errors_avg\n",
    "\n",
    "initial_cs_min_error = initial_cs_boosting_errors_avg[0]\n",
    "initial_cs_num_rounds = 0\n",
    "initial_cs_early_stopping = 0\n",
    "for boosting_round, error in enumerate(initial_cs_boosting_errors_avg):\n",
    "    if error <= initial_cs_min_error:\n",
    "        initial_cs_min_error = error\n",
    "        initial_cs_num_rounds = boosting_round + 1\n",
    "        initial_cs_early_stopping = 1\n",
    "    else:\n",
    "        initial_cs_early_stopping += 1\n",
    "    if initial_cs_early_stopping == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_cs_num_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861427315288\n"
     ]
    }
   ],
   "source": [
    "# Testing set accuracy\n",
    "\n",
    "initial_cs_train_dmatrix = xgb.DMatrix(initial_cs_X_train, initial_cs_y_train)\n",
    "initial_cs_test_dmatrix = xgb.DMatrix(initial_cs_X_test, initial_cs_y_test)\n",
    "\n",
    "initial_cs_booster = xgb.train(params=INITIAL_CS_PARAMS, dtrain=initial_cs_train_dmatrix,\n",
    "                               um_boost_round=initial_cs_num_rounds)\n",
    "\n",
    "initial_cs_y_predicted = initial_cs_booster.predict(initial_cs_test_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861427315288\n",
      "[[ 96.88   0.04   0.     1.4    1.4    0.28]\n",
      " [  0.68  97.85   0.47   0.     0.99   0.01]\n",
      " [  0.42   6.26  93.2    0.     0.02   0.1 ]\n",
      " [ 39.52   0.02   0.    56.06   3.79   0.61]\n",
      " [  2.85   0.05   0.     7.33  87.47   2.3 ]\n",
      " [ 18.74   1.19   0.07   1.68   0.36  77.97]]\n"
     ]
    }
   ],
   "source": [
    "initial_cs_accuracy = metrics.accuracy_score(initial_cs_y_test, initial_cs_y_predicted)\n",
    "print(initial_cs_accuracy)\n",
    "\n",
    "initial_cs_cm = metrics.confusion_matrix(initial_cs_y_test, initial_cs_y_predicted)\n",
    "initial_cs_cm = initial_cs_cm.astype(\"float\") / initial_cs_cm.sum(axis=1)[:, np.newaxis]\n",
    "initial_cs_cm *= 100\n",
    "print(initial_cs_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train final Booster\n",
    "\n",
    "initial_cs_booster = xgb.train(params=INITIAL_CS_PARAMS, dtrain=X_all, num_boost_round=initial_cs_num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "initial_cs_booster.save_model(\"initial_cs.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Cross-Subject Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(complete_cs_split_fn, \"rb\") as f:\n",
    "    complete_cs_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune parameters\n",
    "\n",
    "xgboost_clf = xgb.XGBClassifier(learning_rate=0.3, n_estimators=100, objective=\"multi:softmax\", seed=42)\n",
    "\n",
    "xgboost_knobs = {\n",
    "    \"max_depth\": [5, 6, 7, 8],\n",
    "    \"gamma\": [1, 2, 3],\n",
    "    \"reg_lambda\": [1, 2, 3],\n",
    "    \"reg_alpha\": [1, 2, 3],\n",
    "    \"subsample\": [0.5, 0.8, 1],\n",
    "    \"colsample_bytree\": [0.5, 0.8, 1],\n",
    "    \"colsample_bylevel\": [0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "complete_cs_train_test_cv = []\n",
    "for train_test in complete_cs_split:\n",
    "    train_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"train\"])].index.tolist()\n",
    "    test_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"test\"])].index.tolist()\n",
    "    complete_cs_train_test_cv.append((train_indices, test_indices))\n",
    "\n",
    "# Get 100 random splits\n",
    "random.shuffle(complete_cs_train_test_cv)\n",
    "complete_cs_train_test_cv = complete_cs_train_test_cv[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_cs_params_search = model_selection.RandomizedSearchCV(\n",
    "    xgboost_clf, param_distributions=xgboost_knobs, cv=complete_cs_train_test_cv, n_iter=20, random_state=42, verbose=2, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 100 folds for each of 20 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 76.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 154.5min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 268.7min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 415.8min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 618.9min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 887.9min\n",
      "[Parallel(n_jobs=4)]: Done 2000 out of 2000 | elapsed: 899.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[([16318, 16319, 16320, 16321, 16322, 16323, 16324, 16325, 16326, 16327, 16328, 16329, 16330, 16331, 16332, 16333, 16334, 16335, 16336, 16337, 16338, 16339, 16340, 16341, 16342, 16343, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351, 16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, ... 72277, 72278, 72279, 72280, 72281, 72282, 72283, 72284, 72285, 72286, 72287, 72288, 72289, 72290])],\n",
       "          error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softmax', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1),\n",
       "          fit_params={}, iid=True, n_iter=20, n_jobs=4,\n",
       "          param_distributions={'max_depth': [5, 6, 7, 8], 'gamma': [1, 2, 3], 'reg_lambda': [1, 2, 3], 'reg_alpha': [1, 2, 3], 'subsample': [0.5, 0.8, 1], 'colsample_bytree': [0.5, 0.8, 1], 'colsample_bylevel': [0.5, 0.8, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_cs_params_search.fit(X.values, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"results/complete_cs_params\", \"wb\") as f:\n",
    "    pickle.dump(complete_cs_params_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.5,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 5,\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 3,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_cs_params_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"results/complete_cs_params\", \"rb\") as f:\n",
    "    complete_cs_params_search = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COMPLETE_CS_PARAMS = {}\n",
    "COMPLETE_CS_PARAMS[\"eta\"] = 0.3\n",
    "COMPLETE_CS_PARAMS[\"max_depth\"] = 5\n",
    "COMPLETE_CS_PARAMS[\"gamma\"] = 1\n",
    "COMPLETE_CS_PARAMS[\"lambda\"] = 3\n",
    "COMPLETE_CS_PARAMS[\"alpha\"] = 1\n",
    "COMPLETE_CS_PARAMS[\"subsample\"] = 0.5\n",
    "COMPLETE_CS_PARAMS[\"colsample_bytree\"] = 0.8\n",
    "COMPLETE_CS_PARAMS[\"colsample_bylevel\"] = 0.5\n",
    "COMPLETE_CS_PARAMS[\"objective\"] = \"multi:softmax\"\n",
    "COMPLETE_CS_PARAMS[\"eval_metric\"] = \"merror\"\n",
    "COMPLETE_CS_PARAMS[\"num_class\"] = len(activities_list)\n",
    "COMPLETE_CS_PARAMS[\"silent\"] = 1\n",
    "NUM_ROUNDS = 100\n",
    "EARLYSTOPPING_ROUNDS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.054004\teval-merror:0.308463\n",
      "[50]\ttrain-merror:0.004218\teval-merror:0.186267\n",
      "0\n",
      "[0]\ttrain-merror:0.048274\teval-merror:0.335839\n",
      "[50]\ttrain-merror:0.004711\teval-merror:0.198976\n",
      "1\n",
      "[0]\ttrain-merror:0.054557\teval-merror:0.376124\n",
      "[50]\ttrain-merror:0.004503\teval-merror:0.171953\n",
      "2\n",
      "[0]\ttrain-merror:0.040945\teval-merror:0.347736\n",
      "[50]\ttrain-merror:0.004188\teval-merror:0.228316\n",
      "3\n",
      "[0]\ttrain-merror:0.048801\teval-merror:0.317888\n",
      "[50]\ttrain-merror:0.004767\teval-merror:0.238868\n",
      "4\n",
      "[0]\ttrain-merror:0.064037\teval-merror:0.280673\n",
      "[50]\ttrain-merror:0.004443\teval-merror:0.163558\n",
      "5\n",
      "[0]\ttrain-merror:0.061728\teval-merror:0.262622\n",
      "[50]\ttrain-merror:0.004527\teval-merror:0.157888\n",
      "6\n",
      "[0]\ttrain-merror:0.051313\teval-merror:0.285424\n",
      "[50]\ttrain-merror:0.004191\teval-merror:0.134375\n",
      "7\n",
      "[0]\ttrain-merror:0.052578\teval-merror:0.280758\n",
      "[50]\ttrain-merror:0.00426\teval-merror:0.124918\n",
      "8\n",
      "[0]\ttrain-merror:0.040972\teval-merror:0.273129\n",
      "[50]\ttrain-merror:0.003907\teval-merror:0.18175\n",
      "9\n",
      "[0]\ttrain-merror:0.057028\teval-merror:0.291806\n",
      "[50]\ttrain-merror:0.004169\teval-merror:0.150809\n",
      "10\n",
      "[0]\ttrain-merror:0.063959\teval-merror:0.238155\n",
      "[50]\ttrain-merror:0.004481\teval-merror:0.107836\n",
      "11\n",
      "[0]\ttrain-merror:0.053434\teval-merror:0.18778\n",
      "[50]\ttrain-merror:0.004425\teval-merror:0.100766\n",
      "12\n",
      "[0]\ttrain-merror:0.053992\teval-merror:0.22991\n",
      "[50]\ttrain-merror:0.004519\teval-merror:0.119356\n",
      "13\n",
      "[0]\ttrain-merror:0.048077\teval-merror:0.367574\n",
      "[50]\ttrain-merror:0.004536\teval-merror:0.14241\n",
      "14\n",
      "[0]\ttrain-merror:0.053911\teval-merror:0.324286\n",
      "[50]\ttrain-merror:0.004388\teval-merror:0.188891\n",
      "15\n",
      "[0]\ttrain-merror:0.066173\teval-merror:0.2142\n",
      "[50]\ttrain-merror:0.004366\teval-merror:0.105917\n",
      "16\n",
      "[0]\ttrain-merror:0.048253\teval-merror:0.208108\n",
      "[50]\ttrain-merror:0.00434\teval-merror:0.125935\n",
      "17\n",
      "[0]\ttrain-merror:0.0435\teval-merror:0.308824\n",
      "[50]\ttrain-merror:0.004595\teval-merror:0.155502\n",
      "18\n",
      "[0]\ttrain-merror:0.059422\teval-merror:0.269037\n",
      "[50]\ttrain-merror:0.004386\teval-merror:0.106364\n",
      "19\n",
      "[0]\ttrain-merror:0.062568\teval-merror:0.265569\n",
      "[50]\ttrain-merror:0.004422\teval-merror:0.120884\n",
      "20\n",
      "[0]\ttrain-merror:0.065313\teval-merror:0.220967\n",
      "[50]\ttrain-merror:0.004784\teval-merror:0.134635\n",
      "21\n",
      "[0]\ttrain-merror:0.055658\teval-merror:0.365499\n",
      "[50]\ttrain-merror:0.004255\teval-merror:0.152658\n",
      "22\n",
      "[0]\ttrain-merror:0.04775\teval-merror:0.266615\n",
      "[50]\ttrain-merror:0.004376\teval-merror:0.114912\n",
      "23\n",
      "[0]\ttrain-merror:0.058824\teval-merror:0.294329\n",
      "[50]\ttrain-merror:0.004435\teval-merror:0.14121\n",
      "24\n",
      "[0]\ttrain-merror:0.055159\teval-merror:0.225606\n",
      "[50]\ttrain-merror:0.004619\teval-merror:0.108043\n",
      "25\n",
      "[0]\ttrain-merror:0.065083\teval-merror:0.247755\n",
      "[50]\ttrain-merror:0.004445\teval-merror:0.129671\n",
      "26\n",
      "[0]\ttrain-merror:0.061712\teval-merror:0.199383\n",
      "[50]\ttrain-merror:0.004503\teval-merror:0.094594\n",
      "27\n",
      "[0]\ttrain-merror:0.07012\teval-merror:0.306154\n",
      "[50]\ttrain-merror:0.004809\teval-merror:0.117108\n",
      "28\n",
      "[0]\ttrain-merror:0.070592\teval-merror:0.260545\n",
      "[50]\ttrain-merror:0.004541\teval-merror:0.134608\n",
      "29\n",
      "[0]\ttrain-merror:0.05428\teval-merror:0.294194\n",
      "[50]\ttrain-merror:0.004429\teval-merror:0.152\n",
      "30\n",
      "[0]\ttrain-merror:0.067483\teval-merror:0.240598\n",
      "[50]\ttrain-merror:0.004495\teval-merror:0.154454\n",
      "31\n",
      "[0]\ttrain-merror:0.063002\teval-merror:0.210728\n",
      "[50]\ttrain-merror:0.004618\teval-merror:0.116479\n",
      "32\n",
      "[0]\ttrain-merror:0.06372\teval-merror:0.207179\n",
      "[50]\ttrain-merror:0.004969\teval-merror:0.094888\n",
      "33\n",
      "[0]\ttrain-merror:0.056495\teval-merror:0.328555\n",
      "[50]\ttrain-merror:0.004874\teval-merror:0.125283\n",
      "34\n",
      "[0]\ttrain-merror:0.049102\teval-merror:0.299012\n",
      "[50]\ttrain-merror:0.00487\teval-merror:0.17078\n",
      "35\n",
      "[0]\ttrain-merror:0.059437\teval-merror:0.329402\n",
      "[50]\ttrain-merror:0.004386\teval-merror:0.1654\n",
      "36\n",
      "[0]\ttrain-merror:0.055051\teval-merror:0.208669\n",
      "[50]\ttrain-merror:0.004568\teval-merror:0.142465\n",
      "37\n",
      "[0]\ttrain-merror:0.053136\teval-merror:0.217214\n",
      "[50]\ttrain-merror:0.005075\teval-merror:0.11584\n",
      "38\n",
      "[0]\ttrain-merror:0.046574\teval-merror:0.285449\n",
      "[50]\ttrain-merror:0.004882\teval-merror:0.147303\n",
      "39\n",
      "[0]\ttrain-merror:0.056534\teval-merror:0.245565\n",
      "[50]\ttrain-merror:0.004684\teval-merror:0.126293\n",
      "40\n",
      "[0]\ttrain-merror:0.058583\teval-merror:0.279095\n",
      "[50]\ttrain-merror:0.004223\teval-merror:0.143077\n",
      "41\n",
      "[0]\ttrain-merror:0.063423\teval-merror:0.21824\n",
      "[50]\ttrain-merror:0.004503\teval-merror:0.123368\n",
      "42\n",
      "[0]\ttrain-merror:0.045657\teval-merror:0.299581\n",
      "[50]\ttrain-merror:0.004815\teval-merror:0.156267\n",
      "43\n",
      "[0]\ttrain-merror:0.048025\teval-merror:0.274024\n",
      "[50]\ttrain-merror:0.004808\teval-merror:0.165647\n",
      "44\n",
      "[0]\ttrain-merror:0.059762\teval-merror:0.206707\n",
      "[50]\ttrain-merror:0.004827\teval-merror:0.126611\n",
      "45\n",
      "[0]\ttrain-merror:0.063055\teval-merror:0.209785\n",
      "[50]\ttrain-merror:0.004615\teval-merror:0.092647\n",
      "46\n",
      "[0]\ttrain-merror:0.056108\teval-merror:0.213291\n",
      "[50]\ttrain-merror:0.00466\teval-merror:0.122037\n",
      "47\n",
      "[0]\ttrain-merror:0.053007\teval-merror:0.220906\n",
      "[50]\ttrain-merror:0.0046\teval-merror:0.125995\n",
      "48\n",
      "[0]\ttrain-merror:0.059276\teval-merror:0.237653\n",
      "[50]\ttrain-merror:0.004977\teval-merror:0.098863\n",
      "49\n",
      "[0]\ttrain-merror:0.059415\teval-merror:0.309821\n",
      "[50]\ttrain-merror:0.004976\teval-merror:0.130878\n",
      "50\n",
      "[0]\ttrain-merror:0.066643\teval-merror:0.289515\n",
      "[50]\ttrain-merror:0.004369\teval-merror:0.139926\n",
      "51\n",
      "[0]\ttrain-merror:0.073951\teval-merror:0.270687\n",
      "[50]\ttrain-merror:0.004807\teval-merror:0.084971\n",
      "52\n",
      "[0]\ttrain-merror:0.071495\teval-merror:0.248037\n",
      "[50]\ttrain-merror:0.004995\teval-merror:0.079715\n",
      "53\n",
      "[0]\ttrain-merror:0.062966\teval-merror:0.27149\n",
      "[50]\ttrain-merror:0.004341\teval-merror:0.123846\n",
      "54\n",
      "[0]\ttrain-merror:0.06678\teval-merror:0.229966\n",
      "[50]\ttrain-merror:0.004502\teval-merror:0.095112\n",
      "55\n",
      "[0]\ttrain-merror:0.061433\teval-merror:0.21874\n",
      "[50]\ttrain-merror:0.004792\teval-merror:0.098174\n",
      "56\n",
      "[0]\ttrain-merror:0.062974\teval-merror:0.233899\n",
      "[50]\ttrain-merror:0.004811\teval-merror:0.10134\n",
      "57\n",
      "[0]\ttrain-merror:0.053194\teval-merror:0.287149\n",
      "[50]\ttrain-merror:0.004377\teval-merror:0.131933\n",
      "58\n",
      "[0]\ttrain-merror:0.058031\teval-merror:0.221344\n",
      "[50]\ttrain-merror:0.004814\teval-merror:0.114482\n",
      "59\n",
      "[0]\ttrain-merror:0.056125\teval-merror:0.206238\n",
      "[50]\ttrain-merror:0.004386\teval-merror:0.104902\n",
      "60\n",
      "[0]\ttrain-merror:0.058986\teval-merror:0.190823\n",
      "[50]\ttrain-merror:0.004769\teval-merror:0.087178\n",
      "61\n",
      "[0]\ttrain-merror:0.063435\teval-merror:0.168535\n",
      "[50]\ttrain-merror:0.004594\teval-merror:0.089887\n",
      "62\n",
      "[0]\ttrain-merror:0.059026\teval-merror:0.186018\n",
      "[50]\ttrain-merror:0.004902\teval-merror:0.079298\n",
      "63\n",
      "[0]\ttrain-merror:0.044325\teval-merror:0.174227\n",
      "[50]\ttrain-merror:0.004876\teval-merror:0.116052\n",
      "64\n",
      "[0]\ttrain-merror:0.069408\teval-merror:0.224517\n",
      "[50]\ttrain-merror:0.005066\teval-merror:0.102753\n",
      "65\n",
      "[0]\ttrain-merror:0.064694\teval-merror:0.173821\n",
      "[50]\ttrain-merror:0.00472\teval-merror:0.095571\n",
      "66\n",
      "[0]\ttrain-merror:0.055628\teval-merror:0.20665\n",
      "[50]\ttrain-merror:0.005052\teval-merror:0.102399\n",
      "67\n",
      "[0]\ttrain-merror:0.053667\teval-merror:0.252063\n",
      "[50]\ttrain-merror:0.004837\teval-merror:0.134\n",
      "68\n",
      "[0]\ttrain-merror:0.060386\teval-merror:0.250839\n",
      "[50]\ttrain-merror:0.00492\teval-merror:0.100644\n",
      "69\n",
      "[0]\ttrain-merror:0.056891\teval-merror:0.296736\n",
      "[50]\ttrain-merror:0.004821\teval-merror:0.103733\n",
      "70\n",
      "[0]\ttrain-merror:0.071945\teval-merror:0.242305\n",
      "[50]\ttrain-merror:0.004528\teval-merror:0.067264\n",
      "71\n",
      "[0]\ttrain-merror:0.073535\teval-merror:0.253566\n",
      "[50]\ttrain-merror:0.004749\teval-merror:0.102203\n",
      "72\n",
      "[0]\ttrain-merror:0.059902\teval-merror:0.15225\n",
      "[50]\ttrain-merror:0.004792\teval-merror:0.067737\n",
      "73\n",
      "[0]\ttrain-merror:0.056873\teval-merror:0.30255\n",
      "[50]\ttrain-merror:0.005183\teval-merror:0.108418\n",
      "74\n",
      "[0]\ttrain-merror:0.054889\teval-merror:0.238284\n",
      "[50]\ttrain-merror:0.004872\teval-merror:0.127764\n",
      "75\n",
      "[0]\ttrain-merror:0.050776\teval-merror:0.242494\n",
      "[50]\ttrain-merror:0.004861\teval-merror:0.124795\n",
      "76\n",
      "[0]\ttrain-merror:0.074403\teval-merror:0.240286\n",
      "[50]\ttrain-merror:0.004842\teval-merror:0.080985\n",
      "77\n",
      "[0]\ttrain-merror:0.074524\teval-merror:0.191055\n",
      "[50]\ttrain-merror:0.004497\teval-merror:0.085609\n",
      "78\n",
      "[0]\ttrain-merror:0.060914\teval-merror:0.209312\n",
      "[50]\ttrain-merror:0.00468\teval-merror:0.104452\n",
      "79\n",
      "[0]\ttrain-merror:0.058963\teval-merror:0.251058\n",
      "[50]\ttrain-merror:0.004611\teval-merror:0.104076\n",
      "80\n",
      "[0]\ttrain-merror:0.067043\teval-merror:0.251578\n",
      "[50]\ttrain-merror:0.004706\teval-merror:0.097755\n",
      "81\n",
      "[0]\ttrain-merror:0.076066\teval-merror:0.202115\n",
      "[50]\ttrain-merror:0.005002\teval-merror:0.099955\n",
      "82\n",
      "[0]\ttrain-merror:0.081683\teval-merror:0.200152\n",
      "[50]\ttrain-merror:0.004165\teval-merror:0.073607\n",
      "83\n",
      "[0]\ttrain-merror:0.07244\teval-merror:0.235239\n",
      "[50]\ttrain-merror:0.003945\teval-merror:0.125765\n",
      "84\n",
      "[0]\ttrain-merror:0.053155\teval-merror:0.309268\n",
      "[50]\ttrain-merror:0.003803\teval-merror:0.140429\n",
      "85\n",
      "[0]\ttrain-merror:0.06207\teval-merror:0.265812\n",
      "[50]\ttrain-merror:0.004119\teval-merror:0.169895\n",
      "86\n",
      "[0]\ttrain-merror:0.064034\teval-merror:0.177722\n",
      "[50]\ttrain-merror:0.004073\teval-merror:0.141227\n",
      "87\n",
      "[0]\ttrain-merror:0.054801\teval-merror:0.210285\n",
      "[50]\ttrain-merror:0.004209\teval-merror:0.121874\n",
      "88\n",
      "[0]\ttrain-merror:0.061101\teval-merror:0.233621\n",
      "[50]\ttrain-merror:0.003943\teval-merror:0.100574\n",
      "89\n",
      "[0]\ttrain-merror:0.067361\teval-merror:0.278326\n",
      "[50]\ttrain-merror:0.004656\teval-merror:0.129478\n",
      "90\n",
      "[0]\ttrain-merror:0.054211\teval-merror:0.325153\n",
      "[50]\ttrain-merror:0.004476\teval-merror:0.176718\n",
      "91\n",
      "[0]\ttrain-merror:0.061882\teval-merror:0.362954\n",
      "[50]\ttrain-merror:0.00406\teval-merror:0.203626\n",
      "92\n",
      "[0]\ttrain-merror:0.061569\teval-merror:0.289885\n",
      "[50]\ttrain-merror:0.004085\teval-merror:0.109645\n",
      "93\n",
      "[0]\ttrain-merror:0.061049\teval-merror:0.23939\n",
      "[50]\ttrain-merror:0.004716\teval-merror:0.129056\n",
      "94\n",
      "[0]\ttrain-merror:0.050986\teval-merror:0.285052\n",
      "[50]\ttrain-merror:0.004729\teval-merror:0.157281\n",
      "95\n",
      "[0]\ttrain-merror:0.056853\teval-merror:0.223722\n",
      "[50]\ttrain-merror:0.004665\teval-merror:0.145504\n",
      "96\n",
      "[0]\ttrain-merror:0.062381\teval-merror:0.29055\n",
      "[50]\ttrain-merror:0.004458\teval-merror:0.13952\n",
      "97\n",
      "[0]\ttrain-merror:0.055841\teval-merror:0.299881\n",
      "[50]\ttrain-merror:0.004485\teval-merror:0.140844\n",
      "98\n",
      "[0]\ttrain-merror:0.059104\teval-merror:0.316754\n",
      "[50]\ttrain-merror:0.004628\teval-merror:0.187098\n",
      "99\n",
      "[0]\ttrain-merror:0.063167\teval-merror:0.290504\n",
      "[50]\ttrain-merror:0.00424\teval-merror:0.155522\n",
      "100\n",
      "[0]\ttrain-merror:0.052179\teval-merror:0.231582\n",
      "[50]\ttrain-merror:0.004133\teval-merror:0.140445\n",
      "101\n",
      "[0]\ttrain-merror:0.056976\teval-merror:0.297926\n",
      "[50]\ttrain-merror:0.004549\teval-merror:0.136586\n",
      "102\n",
      "[0]\ttrain-merror:0.065582\teval-merror:0.205313\n",
      "[50]\ttrain-merror:0.004403\teval-merror:0.134638\n",
      "103\n",
      "[0]\ttrain-merror:0.063839\teval-merror:0.297788\n",
      "[50]\ttrain-merror:0.004509\teval-merror:0.134163\n",
      "104\n",
      "[0]\ttrain-merror:0.061732\teval-merror:0.218686\n",
      "[50]\ttrain-merror:0.004375\teval-merror:0.091602\n",
      "105\n",
      "[0]\ttrain-merror:0.05906\teval-merror:0.2921\n",
      "[50]\ttrain-merror:0.004254\teval-merror:0.129155\n",
      "106\n",
      "[0]\ttrain-merror:0.056756\teval-merror:0.226991\n",
      "[50]\ttrain-merror:0.003963\teval-merror:0.116488\n",
      "107\n",
      "[0]\ttrain-merror:0.068453\teval-merror:0.225349\n",
      "[50]\ttrain-merror:0.004185\teval-merror:0.085503\n",
      "108\n",
      "[0]\ttrain-merror:0.064692\teval-merror:0.261452\n",
      "[50]\ttrain-merror:0.004164\teval-merror:0.084313\n",
      "109\n",
      "[0]\ttrain-merror:0.05483\teval-merror:0.283386\n",
      "[50]\ttrain-merror:0.004353\teval-merror:0.11747\n",
      "110\n",
      "[0]\ttrain-merror:0.073876\teval-merror:0.280174\n",
      "[50]\ttrain-merror:0.004162\teval-merror:0.11215\n",
      "111\n",
      "[0]\ttrain-merror:0.061211\teval-merror:0.241771\n",
      "[50]\ttrain-merror:0.004606\teval-merror:0.103794\n",
      "112\n",
      "[0]\ttrain-merror:0.060505\teval-merror:0.262742\n",
      "[50]\ttrain-merror:0.003952\teval-merror:0.106249\n",
      "113\n",
      "[0]\ttrain-merror:0.055684\teval-merror:0.31326\n",
      "[50]\ttrain-merror:0.004029\teval-merror:0.155894\n",
      "114\n",
      "[0]\ttrain-merror:0.050912\teval-merror:0.248982\n",
      "[50]\ttrain-merror:0.004167\teval-merror:0.12224\n",
      "115\n",
      "[0]\ttrain-merror:0.063493\teval-merror:0.223328\n",
      "[50]\ttrain-merror:0.004118\teval-merror:0.099749\n",
      "116\n",
      "[0]\ttrain-merror:0.074031\teval-merror:0.207353\n",
      "[50]\ttrain-merror:0.004338\teval-merror:0.078667\n",
      "117\n",
      "[0]\ttrain-merror:0.067578\teval-merror:0.247015\n",
      "[50]\ttrain-merror:0.004316\teval-merror:0.081056\n",
      "118\n",
      "[0]\ttrain-merror:0.065246\teval-merror:0.21201\n",
      "[50]\ttrain-merror:0.004664\teval-merror:0.088877\n",
      "119\n",
      "[0]\ttrain-merror:0.055319\teval-merror:0.201366\n",
      "[50]\ttrain-merror:0.004585\teval-merror:0.1127\n",
      "120\n",
      "[0]\ttrain-merror:0.049391\teval-merror:0.253652\n",
      "[50]\ttrain-merror:0.004794\teval-merror:0.101295\n",
      "121\n",
      "[0]\ttrain-merror:0.057126\teval-merror:0.216526\n",
      "[50]\ttrain-merror:0.004527\teval-merror:0.097672\n",
      "122\n",
      "[0]\ttrain-merror:0.056805\teval-merror:0.210105\n",
      "[50]\ttrain-merror:0.004441\teval-merror:0.107538\n",
      "123\n",
      "[0]\ttrain-merror:0.053757\teval-merror:0.274884\n",
      "[50]\ttrain-merror:0.004186\teval-merror:0.135674\n",
      "124\n",
      "[0]\ttrain-merror:0.046051\teval-merror:0.228475\n",
      "[50]\ttrain-merror:0.004305\teval-merror:0.098676\n",
      "125\n",
      "[0]\ttrain-merror:0.060121\teval-merror:0.229031\n",
      "[50]\ttrain-merror:0.004453\teval-merror:0.113844\n",
      "126\n",
      "[0]\ttrain-merror:0.066665\teval-merror:0.27142\n",
      "[50]\ttrain-merror:0.004486\teval-merror:0.080459\n",
      "127\n",
      "[0]\ttrain-merror:0.074379\teval-merror:0.235486\n",
      "[50]\ttrain-merror:0.004436\teval-merror:0.110129\n",
      "128\n",
      "[0]\ttrain-merror:0.062727\teval-merror:0.225144\n",
      "[50]\ttrain-merror:0.004165\teval-merror:0.080166\n",
      "129\n",
      "[0]\ttrain-merror:0.055421\teval-merror:0.2654\n",
      "[50]\ttrain-merror:0.004413\teval-merror:0.120026\n",
      "130\n",
      "[0]\ttrain-merror:0.05219\teval-merror:0.252264\n",
      "[50]\ttrain-merror:0.004478\teval-merror:0.119602\n",
      "131\n",
      "[0]\ttrain-merror:0.067415\teval-merror:0.278082\n",
      "[50]\ttrain-merror:0.004254\teval-merror:0.134464\n",
      "132\n",
      "[0]\ttrain-merror:0.066569\teval-merror:0.204509\n",
      "[50]\ttrain-merror:0.0048\teval-merror:0.086865\n",
      "133\n",
      "[0]\ttrain-merror:0.061467\teval-merror:0.220746\n",
      "[50]\ttrain-merror:0.004553\teval-merror:0.10778\n",
      "134\n",
      "[0]\ttrain-merror:0.065012\teval-merror:0.228373\n",
      "[50]\ttrain-merror:0.004663\teval-merror:0.12216\n",
      "135\n",
      "[0]\ttrain-merror:0.052696\teval-merror:0.215342\n",
      "[50]\ttrain-merror:0.004569\teval-merror:0.10029\n",
      "136\n",
      "[0]\ttrain-merror:0.061082\teval-merror:0.220379\n",
      "[50]\ttrain-merror:0.004493\teval-merror:0.095668\n",
      "137\n",
      "[0]\ttrain-merror:0.068525\teval-merror:0.258595\n",
      "[50]\ttrain-merror:0.004477\teval-merror:0.107599\n",
      "138\n",
      "[0]\ttrain-merror:0.065035\teval-merror:0.174853\n",
      "[50]\ttrain-merror:0.004063\teval-merror:0.094047\n",
      "139\n",
      "[0]\ttrain-merror:0.063122\teval-merror:0.260106\n",
      "[50]\ttrain-merror:0.00469\teval-merror:0.087604\n",
      "140\n",
      "[0]\ttrain-merror:0.067768\teval-merror:0.229705\n",
      "[50]\ttrain-merror:0.004581\teval-merror:0.116197\n",
      "141\n",
      "[0]\ttrain-merror:0.064531\teval-merror:0.253212\n",
      "[50]\ttrain-merror:0.004432\teval-merror:0.117574\n",
      "142\n",
      "[0]\ttrain-merror:0.064966\teval-merror:0.231166\n",
      "[50]\ttrain-merror:0.004412\teval-merror:0.086831\n",
      "143\n",
      "[0]\ttrain-merror:0.069311\teval-merror:0.241887\n",
      "[50]\ttrain-merror:0.004606\teval-merror:0.070842\n",
      "144\n",
      "[0]\ttrain-merror:0.057577\teval-merror:0.184639\n",
      "[50]\ttrain-merror:0.005045\teval-merror:0.112646\n",
      "145\n",
      "[0]\ttrain-merror:0.066905\teval-merror:0.231139\n",
      "[50]\ttrain-merror:0.0048\teval-merror:0.127664\n",
      "146\n",
      "[0]\ttrain-merror:0.06661\teval-merror:0.249056\n",
      "[50]\ttrain-merror:0.004437\teval-merror:0.121442\n",
      "147\n",
      "[0]\ttrain-merror:0.064901\teval-merror:0.245298\n",
      "[50]\ttrain-merror:0.004571\teval-merror:0.109535\n",
      "148\n",
      "[0]\ttrain-merror:0.063876\teval-merror:0.219736\n",
      "[50]\ttrain-merror:0.004467\teval-merror:0.139313\n",
      "149\n",
      "[0]\ttrain-merror:0.059471\teval-merror:0.239045\n",
      "[50]\ttrain-merror:0.004534\teval-merror:0.118258\n",
      "150\n",
      "[0]\ttrain-merror:0.065718\teval-merror:0.194898\n",
      "[50]\ttrain-merror:0.004229\teval-merror:0.095122\n",
      "151\n",
      "[0]\ttrain-merror:0.079019\teval-merror:0.240603\n",
      "[50]\ttrain-merror:0.004553\teval-merror:0.105364\n",
      "152\n",
      "[0]\ttrain-merror:0.076234\teval-merror:0.190033\n",
      "[50]\ttrain-merror:0.004575\teval-merror:0.099928\n",
      "153\n",
      "[0]\ttrain-merror:0.082868\teval-merror:0.250768\n",
      "[50]\ttrain-merror:0.004465\teval-merror:0.09097\n",
      "154\n",
      "[0]\ttrain-merror:0.053899\teval-merror:0.283109\n",
      "[50]\ttrain-merror:0.005271\teval-merror:0.129052\n",
      "155\n",
      "[0]\ttrain-merror:0.065091\teval-merror:0.316214\n",
      "[50]\ttrain-merror:0.004732\teval-merror:0.112993\n",
      "156\n",
      "[0]\ttrain-merror:0.053371\teval-merror:0.236137\n",
      "[50]\ttrain-merror:0.004637\teval-merror:0.091751\n",
      "157\n",
      "[0]\ttrain-merror:0.062136\teval-merror:0.303851\n",
      "[50]\ttrain-merror:0.004716\teval-merror:0.107605\n",
      "158\n",
      "[0]\ttrain-merror:0.053351\teval-merror:0.317832\n",
      "[50]\ttrain-merror:0.004781\teval-merror:0.16819\n",
      "159\n",
      "[0]\ttrain-merror:0.054697\teval-merror:0.325457\n",
      "[50]\ttrain-merror:0.004334\teval-merror:0.121245\n",
      "160\n",
      "[0]\ttrain-merror:0.058171\teval-merror:0.290408\n",
      "[50]\ttrain-merror:0.004593\teval-merror:0.11105\n",
      "161\n",
      "[0]\ttrain-merror:0.073752\teval-merror:0.308222\n",
      "[50]\ttrain-merror:0.004683\teval-merror:0.113868\n",
      "162\n",
      "[0]\ttrain-merror:0.060661\teval-merror:0.22048\n",
      "[50]\ttrain-merror:0.004653\teval-merror:0.108934\n",
      "163\n",
      "[0]\ttrain-merror:0.063615\teval-merror:0.282017\n",
      "[50]\ttrain-merror:0.004467\teval-merror:0.089953\n",
      "164\n",
      "[0]\ttrain-merror:0.054979\teval-merror:0.251956\n",
      "[50]\ttrain-merror:0.004849\teval-merror:0.114958\n",
      "165\n",
      "[0]\ttrain-merror:0.048774\teval-merror:0.173402\n",
      "[50]\ttrain-merror:0.004787\teval-merror:0.126037\n",
      "166\n",
      "[0]\ttrain-merror:0.064989\teval-merror:0.233157\n",
      "[50]\ttrain-merror:0.004751\teval-merror:0.126317\n",
      "167\n",
      "[0]\ttrain-merror:0.059779\teval-merror:0.23263\n",
      "[50]\ttrain-merror:0.004721\teval-merror:0.100974\n",
      "168\n",
      "[0]\ttrain-merror:0.070897\teval-merror:0.236316\n",
      "[50]\ttrain-merror:0.004644\teval-merror:0.097582\n",
      "169\n",
      "[0]\ttrain-merror:0.072165\teval-merror:0.241137\n",
      "[50]\ttrain-merror:0.00439\teval-merror:0.125066\n",
      "170\n",
      "[0]\ttrain-merror:0.06508\teval-merror:0.24281\n",
      "[50]\ttrain-merror:0.004665\teval-merror:0.125953\n",
      "171\n",
      "[0]\ttrain-merror:0.065188\teval-merror:0.207398\n",
      "[50]\ttrain-merror:0.004781\teval-merror:0.107231\n",
      "172\n",
      "[0]\ttrain-merror:0.078015\teval-merror:0.198925\n",
      "[50]\ttrain-merror:0.004349\teval-merror:0.099814\n",
      "173\n",
      "[0]\ttrain-merror:0.067585\teval-merror:0.172678\n",
      "[50]\ttrain-merror:0.004804\teval-merror:0.086645\n",
      "174\n",
      "[0]\ttrain-merror:0.053769\teval-merror:0.205551\n",
      "[50]\ttrain-merror:0.004524\teval-merror:0.102462\n",
      "175\n",
      "[0]\ttrain-merror:0.074319\teval-merror:0.263696\n",
      "[50]\ttrain-merror:0.00482\teval-merror:0.086666\n",
      "176\n",
      "[0]\ttrain-merror:0.066862\teval-merror:0.196805\n",
      "[50]\ttrain-merror:0.004561\teval-merror:0.071874\n",
      "177\n",
      "[0]\ttrain-merror:0.069163\teval-merror:0.251188\n",
      "[50]\ttrain-merror:0.005134\teval-merror:0.082137\n",
      "178\n",
      "[0]\ttrain-merror:0.069453\teval-merror:0.205946\n",
      "[50]\ttrain-merror:0.004199\teval-merror:0.120115\n",
      "179\n",
      "[0]\ttrain-merror:0.064739\teval-merror:0.181855\n",
      "[50]\ttrain-merror:0.004895\teval-merror:0.079198\n",
      "180\n",
      "[0]\ttrain-merror:0.068797\teval-merror:0.188457\n",
      "[50]\ttrain-merror:0.004714\teval-merror:0.079037\n",
      "181\n",
      "[0]\ttrain-merror:0.080728\teval-merror:0.244268\n",
      "[50]\ttrain-merror:0.004294\teval-merror:0.071798\n",
      "182\n",
      "[0]\ttrain-merror:0.074531\teval-merror:0.1868\n",
      "[50]\ttrain-merror:0.004394\teval-merror:0.066788\n",
      "183\n",
      "[0]\ttrain-merror:0.06825\teval-merror:0.270107\n",
      "[50]\ttrain-merror:0.004973\teval-merror:0.059124\n",
      "184\n",
      "[0]\ttrain-merror:0.058981\teval-merror:0.235703\n",
      "[50]\ttrain-merror:0.004556\teval-merror:0.102844\n",
      "185\n",
      "[0]\ttrain-merror:0.063234\teval-merror:0.224974\n",
      "[50]\ttrain-merror:0.004625\teval-merror:0.09979\n",
      "186\n",
      "[0]\ttrain-merror:0.064029\teval-merror:0.25416\n",
      "[50]\ttrain-merror:0.004429\teval-merror:0.097584\n",
      "187\n",
      "[0]\ttrain-merror:0.066326\teval-merror:0.187802\n",
      "[50]\ttrain-merror:0.004631\teval-merror:0.08789\n",
      "188\n",
      "[0]\ttrain-merror:0.096376\teval-merror:0.206961\n",
      "[50]\ttrain-merror:0.004815\teval-merror:0.090709\n",
      "189\n",
      "[0]\ttrain-merror:0.070769\teval-merror:0.20561\n",
      "[50]\ttrain-merror:0.005003\teval-merror:0.098962\n",
      "190\n",
      "[0]\ttrain-merror:0.06311\teval-merror:0.133236\n",
      "[50]\ttrain-merror:0.004548\teval-merror:0.090016\n",
      "191\n",
      "[0]\ttrain-merror:0.073818\teval-merror:0.232616\n",
      "[50]\ttrain-merror:0.004594\teval-merror:0.083811\n",
      "192\n",
      "[0]\ttrain-merror:0.084877\teval-merror:0.213218\n",
      "[50]\ttrain-merror:0.004631\teval-merror:0.090701\n",
      "193\n",
      "[0]\ttrain-merror:0.075692\teval-merror:0.188732\n",
      "[50]\ttrain-merror:0.004658\teval-merror:0.068544\n",
      "194\n",
      "[0]\ttrain-merror:0.060904\teval-merror:0.199571\n",
      "[50]\ttrain-merror:0.004787\teval-merror:0.098316\n",
      "195\n",
      "[0]\ttrain-merror:0.070084\teval-merror:0.181652\n",
      "[50]\ttrain-merror:0.004954\teval-merror:0.076824\n",
      "196\n",
      "[0]\ttrain-merror:0.060739\teval-merror:0.257917\n",
      "[50]\ttrain-merror:0.004856\teval-merror:0.105745\n",
      "197\n",
      "[0]\ttrain-merror:0.093272\teval-merror:0.236435\n",
      "[50]\ttrain-merror:0.004564\teval-merror:0.058646\n",
      "198\n",
      "[0]\ttrain-merror:0.078788\teval-merror:0.178041\n",
      "[50]\ttrain-merror:0.00512\teval-merror:0.070591\n",
      "199\n",
      "[0]\ttrain-merror:0.063304\teval-merror:0.242144\n",
      "[50]\ttrain-merror:0.004798\teval-merror:0.085515\n",
      "200\n",
      "[0]\ttrain-merror:0.080887\teval-merror:0.259905\n",
      "[50]\ttrain-merror:0.004655\teval-merror:0.089764\n",
      "201\n",
      "[0]\ttrain-merror:0.065077\teval-merror:0.26884\n",
      "[50]\ttrain-merror:0.004625\teval-merror:0.097175\n",
      "202\n",
      "[0]\ttrain-merror:0.066692\teval-merror:0.158278\n",
      "[50]\ttrain-merror:0.004947\teval-merror:0.075719\n",
      "203\n",
      "[0]\ttrain-merror:0.065739\teval-merror:0.160091\n",
      "[50]\ttrain-merror:0.004621\teval-merror:0.047637\n",
      "204\n",
      "[0]\ttrain-merror:0.06583\teval-merror:0.199639\n",
      "[50]\ttrain-merror:0.005041\teval-merror:0.091312\n",
      "205\n",
      "[0]\ttrain-merror:0.068241\teval-merror:0.227872\n",
      "[50]\ttrain-merror:0.00527\teval-merror:0.092831\n",
      "206\n",
      "[0]\ttrain-merror:0.055914\teval-merror:0.165514\n",
      "[50]\ttrain-merror:0.004805\teval-merror:0.094505\n",
      "207\n",
      "[0]\ttrain-merror:0.072436\teval-merror:0.201303\n",
      "[50]\ttrain-merror:0.004722\teval-merror:0.077773\n",
      "208\n",
      "[0]\ttrain-merror:0.084486\teval-merror:0.250651\n",
      "[50]\ttrain-merror:0.004694\teval-merror:0.084408\n",
      "209\n",
      "[0]\ttrain-merror:0.05294\teval-merror:0.271469\n",
      "[50]\ttrain-merror:0.003847\teval-merror:0.157827\n",
      "210\n",
      "[0]\ttrain-merror:0.054185\teval-merror:0.295414\n",
      "[50]\ttrain-merror:0.003894\teval-merror:0.135794\n",
      "211\n",
      "[0]\ttrain-merror:0.048947\teval-merror:0.295816\n",
      "[50]\ttrain-merror:0.003891\teval-merror:0.170221\n",
      "212\n",
      "[0]\ttrain-merror:0.055536\teval-merror:0.289476\n",
      "[50]\ttrain-merror:0.003908\teval-merror:0.159307\n",
      "213\n",
      "[0]\ttrain-merror:0.059534\teval-merror:0.259441\n",
      "[50]\ttrain-merror:0.004036\teval-merror:0.128878\n",
      "214\n",
      "[0]\ttrain-merror:0.070619\teval-merror:0.214543\n",
      "[50]\ttrain-merror:0.004232\teval-merror:0.103913\n",
      "215\n",
      "[0]\ttrain-merror:0.047543\teval-merror:0.267554\n",
      "[50]\ttrain-merror:0.004253\teval-merror:0.145048\n",
      "216\n",
      "[0]\ttrain-merror:0.044182\teval-merror:0.306617\n",
      "[50]\ttrain-merror:0.003802\teval-merror:0.197682\n",
      "217\n",
      "[0]\ttrain-merror:0.07155\teval-merror:0.299645\n",
      "[50]\ttrain-merror:0.003945\teval-merror:0.213337\n",
      "218\n",
      "[0]\ttrain-merror:0.056391\teval-merror:0.218017\n",
      "[50]\ttrain-merror:0.00388\teval-merror:0.111753\n",
      "219\n",
      "[0]\ttrain-merror:0.052835\teval-merror:0.196805\n",
      "[50]\ttrain-merror:0.003784\teval-merror:0.138692\n",
      "220\n",
      "[0]\ttrain-merror:0.04074\teval-merror:0.309766\n",
      "[50]\ttrain-merror:0.004106\teval-merror:0.175794\n",
      "221\n",
      "[0]\ttrain-merror:0.049575\teval-merror:0.325983\n",
      "[50]\ttrain-merror:0.004195\teval-merror:0.167463\n",
      "222\n",
      "[0]\ttrain-merror:0.05968\teval-merror:0.301383\n",
      "[50]\ttrain-merror:0.003977\teval-merror:0.143505\n",
      "223\n",
      "[0]\ttrain-merror:0.050668\teval-merror:0.217155\n",
      "[50]\ttrain-merror:0.004122\teval-merror:0.137433\n",
      "224\n",
      "[0]\ttrain-merror:0.043969\teval-merror:0.319211\n",
      "[50]\ttrain-merror:0.004173\teval-merror:0.223106\n",
      "225\n",
      "[0]\ttrain-merror:0.051124\teval-merror:0.292991\n",
      "[50]\ttrain-merror:0.003863\teval-merror:0.142682\n",
      "226\n",
      "[0]\ttrain-merror:0.060309\teval-merror:0.28349\n",
      "[50]\ttrain-merror:0.004125\teval-merror:0.148201\n",
      "227\n",
      "[0]\ttrain-merror:0.056441\teval-merror:0.261465\n",
      "[50]\ttrain-merror:0.004197\teval-merror:0.142106\n",
      "228\n",
      "[0]\ttrain-merror:0.077056\teval-merror:0.264561\n",
      "[50]\ttrain-merror:0.004037\teval-merror:0.153959\n",
      "229\n",
      "[0]\ttrain-merror:0.075486\teval-merror:0.254266\n",
      "[50]\ttrain-merror:0.00396\teval-merror:0.099515\n",
      "230\n",
      "[0]\ttrain-merror:0.063365\teval-merror:0.27199\n",
      "[50]\ttrain-merror:0.003796\teval-merror:0.121453\n",
      "231\n",
      "[0]\ttrain-merror:0.046274\teval-merror:0.325835\n",
      "[50]\ttrain-merror:0.003724\teval-merror:0.148495\n",
      "232\n",
      "[0]\ttrain-merror:0.059332\teval-merror:0.256831\n",
      "[50]\ttrain-merror:0.003661\teval-merror:0.138142\n",
      "233\n",
      "[0]\ttrain-merror:0.060626\teval-merror:0.205147\n",
      "[50]\ttrain-merror:0.00426\teval-merror:0.083442\n",
      "234\n",
      "[0]\ttrain-merror:0.06277\teval-merror:0.19416\n",
      "[50]\ttrain-merror:0.003937\teval-merror:0.077882\n",
      "235\n",
      "[0]\ttrain-merror:0.050101\teval-merror:0.330992\n",
      "[50]\ttrain-merror:0.004183\teval-merror:0.135122\n",
      "236\n",
      "[0]\ttrain-merror:0.049512\teval-merror:0.221117\n",
      "[50]\ttrain-merror:0.004233\teval-merror:0.121253\n",
      "237\n",
      "[0]\ttrain-merror:0.055142\teval-merror:0.217332\n",
      "[50]\ttrain-merror:0.004073\teval-merror:0.10726\n",
      "238\n",
      "[0]\ttrain-merror:0.076195\teval-merror:0.298381\n",
      "[50]\ttrain-merror:0.003869\teval-merror:0.101878\n",
      "239\n",
      "[0]\ttrain-merror:0.051549\teval-merror:0.299993\n",
      "[50]\ttrain-merror:0.003726\teval-merror:0.193093\n",
      "240\n",
      "[0]\ttrain-merror:0.058269\teval-merror:0.238747\n",
      "[50]\ttrain-merror:0.004242\teval-merror:0.110002\n",
      "241\n",
      "[0]\ttrain-merror:0.057658\teval-merror:0.25788\n",
      "[50]\ttrain-merror:0.003675\teval-merror:0.120204\n",
      "242\n",
      "[0]\ttrain-merror:0.059861\teval-merror:0.178383\n",
      "[50]\ttrain-merror:0.004112\teval-merror:0.098568\n",
      "243\n",
      "[0]\ttrain-merror:0.055465\teval-merror:0.218755\n",
      "[50]\ttrain-merror:0.003861\teval-merror:0.108241\n",
      "244\n",
      "[0]\ttrain-merror:0.059835\teval-merror:0.184346\n",
      "[50]\ttrain-merror:0.004045\teval-merror:0.080748\n",
      "245\n",
      "[0]\ttrain-merror:0.048575\teval-merror:0.326602\n",
      "[50]\ttrain-merror:0.004238\teval-merror:0.13521\n",
      "246\n",
      "[0]\ttrain-merror:0.057158\teval-merror:0.227437\n",
      "[50]\ttrain-merror:0.004145\teval-merror:0.12653\n",
      "247\n",
      "[0]\ttrain-merror:0.057033\teval-merror:0.231295\n",
      "[50]\ttrain-merror:0.004144\teval-merror:0.085241\n",
      "248\n",
      "[0]\ttrain-merror:0.055731\teval-merror:0.201412\n",
      "[50]\ttrain-merror:0.004014\teval-merror:0.110447\n",
      "249\n",
      "[0]\ttrain-merror:0.052282\teval-merror:0.383077\n",
      "[50]\ttrain-merror:0.004121\teval-merror:0.164055\n",
      "250\n",
      "[0]\ttrain-merror:0.045688\teval-merror:0.246716\n",
      "[50]\ttrain-merror:0.003916\teval-merror:0.094498\n",
      "251\n",
      "[0]\ttrain-merror:0.054731\teval-merror:0.255288\n",
      "[50]\ttrain-merror:0.004043\teval-merror:0.120693\n",
      "252\n",
      "[0]\ttrain-merror:0.057031\teval-merror:0.262317\n",
      "[50]\ttrain-merror:0.00388\teval-merror:0.095254\n",
      "253\n",
      "[0]\ttrain-merror:0.058909\teval-merror:0.199187\n",
      "[50]\ttrain-merror:0.003843\teval-merror:0.116814\n",
      "254\n",
      "[0]\ttrain-merror:0.05885\teval-merror:0.181364\n",
      "[50]\ttrain-merror:0.004058\teval-merror:0.078716\n",
      "255\n",
      "[0]\ttrain-merror:0.044018\teval-merror:0.361585\n",
      "[50]\ttrain-merror:0.004372\teval-merror:0.13839\n",
      "256\n",
      "[0]\ttrain-merror:0.049232\teval-merror:0.221055\n",
      "[50]\ttrain-merror:0.00407\teval-merror:0.130227\n",
      "257\n",
      "[0]\ttrain-merror:0.054234\teval-merror:0.261649\n",
      "[50]\ttrain-merror:0.004161\teval-merror:0.129343\n",
      "258\n",
      "[0]\ttrain-merror:0.059174\teval-merror:0.208949\n",
      "[50]\ttrain-merror:0.00406\teval-merror:0.09093\n",
      "259\n",
      "[0]\ttrain-merror:0.0547\teval-merror:0.207791\n",
      "[50]\ttrain-merror:0.004021\teval-merror:0.11049\n",
      "260\n",
      "[0]\ttrain-merror:0.073613\teval-merror:0.22563\n",
      "[50]\ttrain-merror:0.003751\teval-merror:0.102409\n",
      "261\n",
      "[0]\ttrain-merror:0.051298\teval-merror:0.253029\n",
      "[50]\ttrain-merror:0.004086\teval-merror:0.137421\n",
      "262\n",
      "[0]\ttrain-merror:0.065358\teval-merror:0.206907\n",
      "[50]\ttrain-merror:0.003853\teval-merror:0.119947\n",
      "263\n",
      "[0]\ttrain-merror:0.064028\teval-merror:0.25045\n",
      "[50]\ttrain-merror:0.003943\teval-merror:0.105428\n",
      "264\n",
      "[0]\ttrain-merror:0.067096\teval-merror:0.212787\n",
      "[50]\ttrain-merror:0.004037\teval-merror:0.094489\n",
      "265\n",
      "[0]\ttrain-merror:0.056258\teval-merror:0.226692\n",
      "[50]\ttrain-merror:0.004235\teval-merror:0.130571\n",
      "266\n",
      "[0]\ttrain-merror:0.063152\teval-merror:0.290732\n",
      "[50]\ttrain-merror:0.004083\teval-merror:0.134133\n",
      "267\n",
      "[0]\ttrain-merror:0.064875\teval-merror:0.219912\n",
      "[50]\ttrain-merror:0.004096\teval-merror:0.139786\n",
      "268\n",
      "[0]\ttrain-merror:0.073582\teval-merror:0.20825\n",
      "[50]\ttrain-merror:0.004454\teval-merror:0.09199\n",
      "269\n",
      "[0]\ttrain-merror:0.055223\teval-merror:0.163932\n",
      "[50]\ttrain-merror:0.00386\teval-merror:0.085631\n",
      "270\n",
      "[0]\ttrain-merror:0.051158\teval-merror:0.225734\n",
      "[50]\ttrain-merror:0.00403\teval-merror:0.129568\n",
      "271\n",
      "[0]\ttrain-merror:0.069086\teval-merror:0.248488\n",
      "[50]\ttrain-merror:0.003974\teval-merror:0.112951\n",
      "272\n",
      "[0]\ttrain-merror:0.059672\teval-merror:0.198766\n",
      "[50]\ttrain-merror:0.00437\teval-merror:0.106621\n",
      "273\n",
      "[0]\ttrain-merror:0.06871\teval-merror:0.213962\n",
      "[50]\ttrain-merror:0.004267\teval-merror:0.095286\n",
      "274\n",
      "[0]\ttrain-merror:0.053486\teval-merror:0.298995\n",
      "[50]\ttrain-merror:0.004079\teval-merror:0.144057\n",
      "275\n",
      "[0]\ttrain-merror:0.050846\teval-merror:0.219166\n",
      "[50]\ttrain-merror:0.004049\teval-merror:0.13763\n",
      "276\n",
      "[0]\ttrain-merror:0.069451\teval-merror:0.242604\n",
      "[50]\ttrain-merror:0.003978\teval-merror:0.096765\n",
      "277\n",
      "[0]\ttrain-merror:0.084819\teval-merror:0.248632\n",
      "[50]\ttrain-merror:0.004255\teval-merror:0.103249\n",
      "278\n",
      "[0]\ttrain-merror:0.076154\teval-merror:0.195671\n",
      "[50]\ttrain-merror:0.00419\teval-merror:0.094997\n",
      "279\n",
      "[0]\ttrain-merror:0.073376\teval-merror:0.186345\n",
      "[50]\ttrain-merror:0.004047\teval-merror:0.081237\n",
      "280\n",
      "[0]\ttrain-merror:0.053747\teval-merror:0.257247\n",
      "[50]\ttrain-merror:0.004367\teval-merror:0.12494\n",
      "281\n",
      "[0]\ttrain-merror:0.059474\teval-merror:0.246653\n",
      "[50]\ttrain-merror:0.004523\teval-merror:0.11875\n",
      "282\n",
      "[0]\ttrain-merror:0.057925\teval-merror:0.244347\n",
      "[50]\ttrain-merror:0.004034\teval-merror:0.087534\n",
      "283\n",
      "[0]\ttrain-merror:0.072253\teval-merror:0.235285\n",
      "[50]\ttrain-merror:0.00456\teval-merror:0.106493\n",
      "284\n",
      "[0]\ttrain-merror:0.053453\teval-merror:0.337206\n",
      "[50]\ttrain-merror:0.004676\teval-merror:0.160616\n",
      "285\n",
      "[0]\ttrain-merror:0.049421\teval-merror:0.205613\n",
      "[50]\ttrain-merror:0.004149\teval-merror:0.12082\n",
      "286\n",
      "[0]\ttrain-merror:0.056047\teval-merror:0.247165\n",
      "[50]\ttrain-merror:0.004603\teval-merror:0.110032\n",
      "287\n",
      "[0]\ttrain-merror:0.065949\teval-merror:0.206884\n",
      "[50]\ttrain-merror:0.004226\teval-merror:0.103373\n",
      "288\n",
      "[0]\ttrain-merror:0.069931\teval-merror:0.24779\n",
      "[50]\ttrain-merror:0.004445\teval-merror:0.129551\n",
      "289\n",
      "[0]\ttrain-merror:0.072191\teval-merror:0.151036\n",
      "[50]\ttrain-merror:0.003937\teval-merror:0.080122\n",
      "290\n",
      "[0]\ttrain-merror:0.052871\teval-merror:0.285002\n",
      "[50]\ttrain-merror:0.004558\teval-merror:0.126114\n",
      "291\n",
      "[0]\ttrain-merror:0.070445\teval-merror:0.335956\n",
      "[50]\ttrain-merror:0.004321\teval-merror:0.138424\n",
      "292\n",
      "[0]\ttrain-merror:0.054839\teval-merror:0.274054\n",
      "[50]\ttrain-merror:0.004108\teval-merror:0.114953\n",
      "293\n",
      "[0]\ttrain-merror:0.064236\teval-merror:0.233789\n",
      "[50]\ttrain-merror:0.004229\teval-merror:0.10152\n",
      "294\n",
      "[0]\ttrain-merror:0.056379\teval-merror:0.227306\n",
      "[50]\ttrain-merror:0.004024\teval-merror:0.114638\n",
      "295\n",
      "[0]\ttrain-merror:0.071394\teval-merror:0.282417\n",
      "[50]\ttrain-merror:0.004354\teval-merror:0.111531\n",
      "296\n",
      "[0]\ttrain-merror:0.058958\teval-merror:0.218192\n",
      "[50]\ttrain-merror:0.004234\teval-merror:0.116319\n",
      "297\n",
      "[0]\ttrain-merror:0.069695\teval-merror:0.224712\n",
      "[50]\ttrain-merror:0.004334\teval-merror:0.123048\n",
      "298\n",
      "[0]\ttrain-merror:0.062013\teval-merror:0.198338\n",
      "[50]\ttrain-merror:0.00424\teval-merror:0.105394\n",
      "299\n",
      "[0]\ttrain-merror:0.060243\teval-merror:0.144195\n",
      "[50]\ttrain-merror:0.004018\teval-merror:0.080946\n",
      "300\n",
      "[0]\ttrain-merror:0.05854\teval-merror:0.240073\n",
      "[50]\ttrain-merror:0.004156\teval-merror:0.111741\n",
      "301\n",
      "[0]\ttrain-merror:0.070429\teval-merror:0.248133\n",
      "[50]\ttrain-merror:0.004718\teval-merror:0.117765\n",
      "302\n",
      "[0]\ttrain-merror:0.075646\teval-merror:0.269663\n",
      "[50]\ttrain-merror:0.004406\teval-merror:0.06566\n",
      "303\n",
      "[0]\ttrain-merror:0.059225\teval-merror:0.172344\n",
      "[50]\ttrain-merror:0.004461\teval-merror:0.082442\n",
      "304\n",
      "[0]\ttrain-merror:0.051431\teval-merror:0.261102\n",
      "[50]\ttrain-merror:0.003998\teval-merror:0.133007\n",
      "305\n",
      "[0]\ttrain-merror:0.059293\teval-merror:0.264985\n",
      "[50]\ttrain-merror:0.004446\teval-merror:0.081903\n",
      "306\n",
      "[0]\ttrain-merror:0.070273\teval-merror:0.263674\n",
      "[50]\ttrain-merror:0.00428\teval-merror:0.091869\n",
      "307\n",
      "[0]\ttrain-merror:0.081453\teval-merror:0.212954\n",
      "[50]\ttrain-merror:0.004188\teval-merror:0.078825\n",
      "308\n",
      "[0]\ttrain-merror:0.068038\teval-merror:0.171607\n",
      "[50]\ttrain-merror:0.004264\teval-merror:0.078134\n",
      "309\n",
      "[0]\ttrain-merror:0.069612\teval-merror:0.174447\n",
      "[50]\ttrain-merror:0.004218\teval-merror:0.052373\n",
      "310\n",
      "[0]\ttrain-merror:0.056678\teval-merror:0.314649\n",
      "[50]\ttrain-merror:0.004327\teval-merror:0.110126\n",
      "311\n",
      "[0]\ttrain-merror:0.060982\teval-merror:0.257188\n",
      "[50]\ttrain-merror:0.004579\teval-merror:0.111407\n",
      "312\n",
      "[0]\ttrain-merror:0.05681\teval-merror:0.230342\n",
      "[50]\ttrain-merror:0.004228\teval-merror:0.099864\n",
      "313\n",
      "[0]\ttrain-merror:0.0665\teval-merror:0.203368\n",
      "[50]\ttrain-merror:0.004733\teval-merror:0.086087\n",
      "314\n",
      "[0]\ttrain-merror:0.063345\teval-merror:0.181918\n",
      "[50]\ttrain-merror:0.004358\teval-merror:0.090617\n",
      "315\n",
      "[0]\ttrain-merror:0.069533\teval-merror:0.207103\n",
      "[50]\ttrain-merror:0.004482\teval-merror:0.088849\n",
      "316\n",
      "[0]\ttrain-merror:0.057056\teval-merror:0.221735\n",
      "[50]\ttrain-merror:0.004268\teval-merror:0.092868\n",
      "317\n",
      "[0]\ttrain-merror:0.059762\teval-merror:0.232572\n",
      "[50]\ttrain-merror:0.004201\teval-merror:0.100791\n",
      "318\n",
      "[0]\ttrain-merror:0.067211\teval-merror:0.21375\n",
      "[50]\ttrain-merror:0.004178\teval-merror:0.085232\n",
      "319\n",
      "[0]\ttrain-merror:0.091233\teval-merror:0.219934\n",
      "[50]\ttrain-merror:0.004452\teval-merror:0.070498\n",
      "320\n",
      "[0]\ttrain-merror:0.052468\teval-merror:0.268936\n",
      "[50]\ttrain-merror:0.004462\teval-merror:0.117079\n",
      "321\n",
      "[0]\ttrain-merror:0.071805\teval-merror:0.272909\n",
      "[50]\ttrain-merror:0.004728\teval-merror:0.097388\n",
      "322\n",
      "[0]\ttrain-merror:0.060402\teval-merror:0.238132\n",
      "[50]\ttrain-merror:0.004499\teval-merror:0.113519\n",
      "323\n",
      "[0]\ttrain-merror:0.061574\teval-merror:0.200757\n",
      "[50]\ttrain-merror:0.004233\teval-merror:0.065314\n",
      "324\n",
      "[0]\ttrain-merror:0.083681\teval-merror:0.228676\n",
      "[50]\ttrain-merror:0.004428\teval-merror:0.094634\n",
      "325\n",
      "[0]\ttrain-merror:0.082047\teval-merror:0.195814\n",
      "[50]\ttrain-merror:0.004044\teval-merror:0.076288\n",
      "326\n",
      "[0]\ttrain-merror:0.053432\teval-merror:0.200314\n",
      "[50]\ttrain-merror:0.004164\teval-merror:0.082726\n",
      "327\n",
      "[0]\ttrain-merror:0.059136\teval-merror:0.244746\n",
      "[50]\ttrain-merror:0.004609\teval-merror:0.10595\n",
      "328\n",
      "[0]\ttrain-merror:0.062751\teval-merror:0.170196\n",
      "[50]\ttrain-merror:0.00427\teval-merror:0.074323\n",
      "329\n",
      "[0]\ttrain-merror:0.092154\teval-merror:0.211755\n",
      "[50]\ttrain-merror:0.00417\teval-merror:0.060474\n",
      "330\n",
      "[0]\ttrain-merror:0.06139\teval-merror:0.222856\n",
      "[50]\ttrain-merror:0.004847\teval-merror:0.085927\n",
      "331\n",
      "[0]\ttrain-merror:0.059107\teval-merror:0.247139\n",
      "[50]\ttrain-merror:0.004388\teval-merror:0.103778\n",
      "332\n",
      "[0]\ttrain-merror:0.069406\teval-merror:0.228606\n",
      "[50]\ttrain-merror:0.004101\teval-merror:0.107287\n",
      "333\n",
      "[0]\ttrain-merror:0.072959\teval-merror:0.18037\n",
      "[50]\ttrain-merror:0.004557\teval-merror:0.086044\n",
      "334\n",
      "[0]\ttrain-merror:0.060574\teval-merror:0.210018\n",
      "[50]\ttrain-merror:0.004178\teval-merror:0.083183\n",
      "335\n",
      "[0]\ttrain-merror:0.068745\teval-merror:0.259775\n",
      "[50]\ttrain-merror:0.003785\teval-merror:0.130662\n",
      "336\n",
      "[0]\ttrain-merror:0.055176\teval-merror:0.246063\n",
      "[50]\ttrain-merror:0.003841\teval-merror:0.156112\n",
      "337\n",
      "[0]\ttrain-merror:0.081531\teval-merror:0.286802\n",
      "[50]\ttrain-merror:0.003707\teval-merror:0.131094\n",
      "338\n",
      "[0]\ttrain-merror:0.063147\teval-merror:0.233427\n",
      "[50]\ttrain-merror:0.003912\teval-merror:0.102411\n",
      "339\n",
      "[0]\ttrain-merror:0.068636\teval-merror:0.309581\n",
      "[50]\ttrain-merror:0.004033\teval-merror:0.091996\n",
      "340\n",
      "[0]\ttrain-merror:0.044069\teval-merror:0.24987\n",
      "[50]\ttrain-merror:0.003583\teval-merror:0.146357\n",
      "341\n",
      "[0]\ttrain-merror:0.056069\teval-merror:0.371935\n",
      "[50]\ttrain-merror:0.003985\teval-merror:0.141055\n",
      "342\n",
      "[0]\ttrain-merror:0.057917\teval-merror:0.25638\n",
      "[50]\ttrain-merror:0.003899\teval-merror:0.128367\n",
      "343\n",
      "[0]\ttrain-merror:0.055802\teval-merror:0.240782\n",
      "[50]\ttrain-merror:0.00399\teval-merror:0.108367\n",
      "344\n",
      "[0]\ttrain-merror:0.054022\teval-merror:0.273614\n",
      "[50]\ttrain-merror:0.00425\teval-merror:0.14802\n",
      "345\n",
      "[0]\ttrain-merror:0.04938\teval-merror:0.250739\n",
      "[50]\ttrain-merror:0.003978\teval-merror:0.136424\n",
      "346\n",
      "[0]\ttrain-merror:0.079434\teval-merror:0.27072\n",
      "[50]\ttrain-merror:0.003962\teval-merror:0.102415\n",
      "347\n",
      "[0]\ttrain-merror:0.067706\teval-merror:0.292399\n",
      "[50]\ttrain-merror:0.003746\teval-merror:0.112274\n",
      "348\n",
      "[0]\ttrain-merror:0.07103\teval-merror:0.260928\n",
      "[50]\ttrain-merror:0.003829\teval-merror:0.099952\n",
      "349\n",
      "[0]\ttrain-merror:0.064723\teval-merror:0.261964\n",
      "[50]\ttrain-merror:0.003725\teval-merror:0.097892\n",
      "350\n",
      "[0]\ttrain-merror:0.042471\teval-merror:0.25879\n",
      "[50]\ttrain-merror:0.004506\teval-merror:0.135769\n",
      "351\n",
      "[0]\ttrain-merror:0.050606\teval-merror:0.238927\n",
      "[50]\ttrain-merror:0.003996\teval-merror:0.136451\n",
      "352\n",
      "[0]\ttrain-merror:0.056665\teval-merror:0.276389\n",
      "[50]\ttrain-merror:0.003685\teval-merror:0.110883\n",
      "353\n",
      "[0]\ttrain-merror:0.050637\teval-merror:0.247983\n",
      "[50]\ttrain-merror:0.003947\teval-merror:0.113051\n",
      "354\n",
      "[0]\ttrain-merror:0.056655\teval-merror:0.339102\n",
      "[50]\ttrain-merror:0.003996\teval-merror:0.203614\n",
      "355\n",
      "[0]\ttrain-merror:0.040979\teval-merror:0.24749\n",
      "[50]\ttrain-merror:0.004075\teval-merror:0.132092\n",
      "356\n",
      "[0]\ttrain-merror:0.067989\teval-merror:0.276265\n",
      "[50]\ttrain-merror:0.004001\teval-merror:0.126995\n",
      "357\n",
      "[0]\ttrain-merror:0.058437\teval-merror:0.293235\n",
      "[50]\ttrain-merror:0.003699\teval-merror:0.126471\n",
      "358\n",
      "[0]\ttrain-merror:0.056208\teval-merror:0.28233\n",
      "[50]\ttrain-merror:0.003811\teval-merror:0.138368\n",
      "359\n",
      "[0]\ttrain-merror:0.059184\teval-merror:0.234215\n",
      "[50]\ttrain-merror:0.003874\teval-merror:0.109504\n",
      "360\n",
      "[0]\ttrain-merror:0.051837\teval-merror:0.287569\n",
      "[50]\ttrain-merror:0.004006\teval-merror:0.149899\n",
      "361\n",
      "[0]\ttrain-merror:0.055456\teval-merror:0.284239\n",
      "[50]\ttrain-merror:0.004194\teval-merror:0.162927\n",
      "362\n",
      "[0]\ttrain-merror:0.057558\teval-merror:0.240678\n",
      "[50]\ttrain-merror:0.003796\teval-merror:0.132877\n",
      "363\n",
      "[0]\ttrain-merror:0.059539\teval-merror:0.271598\n",
      "[50]\ttrain-merror:0.003788\teval-merror:0.107236\n",
      "364\n",
      "[0]\ttrain-merror:0.062446\teval-merror:0.239914\n",
      "[50]\ttrain-merror:0.003941\teval-merror:0.137385\n",
      "365\n",
      "[0]\ttrain-merror:0.052215\teval-merror:0.249986\n",
      "[50]\ttrain-merror:0.003886\teval-merror:0.125934\n",
      "366\n",
      "[0]\ttrain-merror:0.05938\teval-merror:0.316173\n",
      "[50]\ttrain-merror:0.003976\teval-merror:0.127973\n",
      "367\n",
      "[0]\ttrain-merror:0.053935\teval-merror:0.214529\n",
      "[50]\ttrain-merror:0.004105\teval-merror:0.133884\n",
      "368\n",
      "[0]\ttrain-merror:0.063428\teval-merror:0.267184\n",
      "[50]\ttrain-merror:0.003835\teval-merror:0.120565\n",
      "369\n",
      "[0]\ttrain-merror:0.059416\teval-merror:0.191763\n",
      "[50]\ttrain-merror:0.003622\teval-merror:0.10341\n",
      "370\n",
      "[0]\ttrain-merror:0.053817\teval-merror:0.24574\n",
      "[50]\ttrain-merror:0.004137\teval-merror:0.117987\n",
      "371\n",
      "[0]\ttrain-merror:0.064341\teval-merror:0.245243\n",
      "[50]\ttrain-merror:0.004196\teval-merror:0.103798\n",
      "372\n",
      "[0]\ttrain-merror:0.056226\teval-merror:0.227295\n",
      "[50]\ttrain-merror:0.003922\teval-merror:0.070136\n",
      "373\n",
      "[0]\ttrain-merror:0.061483\teval-merror:0.230133\n",
      "[50]\ttrain-merror:0.004149\teval-merror:0.091418\n",
      "374\n",
      "[0]\ttrain-merror:0.061919\teval-merror:0.310458\n",
      "[50]\ttrain-merror:0.003655\teval-merror:0.138989\n",
      "375\n",
      "[0]\ttrain-merror:0.064097\teval-merror:0.243732\n",
      "[50]\ttrain-merror:0.004004\teval-merror:0.095761\n",
      "376\n",
      "[0]\ttrain-merror:0.061245\teval-merror:0.24893\n",
      "[50]\ttrain-merror:0.003988\teval-merror:0.092789\n",
      "377\n",
      "[0]\ttrain-merror:0.063004\teval-merror:0.175083\n",
      "[50]\ttrain-merror:0.003739\teval-merror:0.070545\n",
      "378\n",
      "[0]\ttrain-merror:0.072666\teval-merror:0.223793\n",
      "[50]\ttrain-merror:0.004084\teval-merror:0.093925\n",
      "379\n",
      "[0]\ttrain-merror:0.063194\teval-merror:0.195873\n",
      "[50]\ttrain-merror:0.004179\teval-merror:0.060505\n",
      "380\n",
      "[0]\ttrain-merror:0.066878\teval-merror:0.284246\n",
      "[50]\ttrain-merror:0.003887\teval-merror:0.127394\n",
      "381\n",
      "[0]\ttrain-merror:0.055741\teval-merror:0.202905\n",
      "[50]\ttrain-merror:0.004151\teval-merror:0.125718\n",
      "382\n",
      "[0]\ttrain-merror:0.072849\teval-merror:0.286448\n",
      "[50]\ttrain-merror:0.004132\teval-merror:0.098512\n",
      "383\n",
      "[0]\ttrain-merror:0.056158\teval-merror:0.229426\n",
      "[50]\ttrain-merror:0.00413\teval-merror:0.084447\n",
      "384\n",
      "[0]\ttrain-merror:0.067866\teval-merror:0.187963\n",
      "[50]\ttrain-merror:0.004091\teval-merror:0.095309\n",
      "385\n",
      "[0]\ttrain-merror:0.065677\teval-merror:0.177926\n",
      "[50]\ttrain-merror:0.004396\teval-merror:0.098787\n",
      "386\n",
      "[0]\ttrain-merror:0.061374\teval-merror:0.23259\n",
      "[50]\ttrain-merror:0.003893\teval-merror:0.115984\n",
      "387\n",
      "[0]\ttrain-merror:0.059063\teval-merror:0.19829\n",
      "[50]\ttrain-merror:0.003928\teval-merror:0.103332\n",
      "388\n",
      "[0]\ttrain-merror:0.063415\teval-merror:0.23081\n",
      "[50]\ttrain-merror:0.003848\teval-merror:0.103867\n",
      "389\n",
      "[0]\ttrain-merror:0.070089\teval-merror:0.149631\n",
      "[50]\ttrain-merror:0.003931\teval-merror:0.069767\n",
      "390\n",
      "[0]\ttrain-merror:0.062407\teval-merror:0.292457\n",
      "[50]\ttrain-merror:0.00395\teval-merror:0.122184\n",
      "391\n",
      "[0]\ttrain-merror:0.050971\teval-merror:0.220139\n",
      "[50]\ttrain-merror:0.004453\teval-merror:0.085686\n",
      "392\n",
      "[0]\ttrain-merror:0.065966\teval-merror:0.268443\n",
      "[50]\ttrain-merror:0.004176\teval-merror:0.113656\n",
      "393\n",
      "[0]\ttrain-merror:0.06235\teval-merror:0.252593\n",
      "[50]\ttrain-merror:0.004291\teval-merror:0.071367\n",
      "394\n",
      "[0]\ttrain-merror:0.065194\teval-merror:0.239727\n",
      "[50]\ttrain-merror:0.004223\teval-merror:0.112609\n",
      "395\n",
      "[0]\ttrain-merror:0.058801\teval-merror:0.260923\n",
      "[50]\ttrain-merror:0.003712\teval-merror:0.091151\n",
      "396\n",
      "[0]\ttrain-merror:0.061188\teval-merror:0.273014\n",
      "[50]\ttrain-merror:0.004099\teval-merror:0.09774\n",
      "397\n",
      "[0]\ttrain-merror:0.063616\teval-merror:0.222659\n",
      "[50]\ttrain-merror:0.003985\teval-merror:0.125143\n",
      "398\n",
      "[0]\ttrain-merror:0.064649\teval-merror:0.228109\n",
      "[50]\ttrain-merror:0.00428\teval-merror:0.081953\n",
      "399\n",
      "[0]\ttrain-merror:0.078977\teval-merror:0.18649\n",
      "[50]\ttrain-merror:0.004004\teval-merror:0.066937\n",
      "400\n",
      "[0]\ttrain-merror:0.062043\teval-merror:0.200943\n",
      "[50]\ttrain-merror:0.004178\teval-merror:0.083724\n",
      "401\n",
      "[0]\ttrain-merror:0.06753\teval-merror:0.23922\n",
      "[50]\ttrain-merror:0.003995\teval-merror:0.128352\n",
      "402\n",
      "[0]\ttrain-merror:0.07327\teval-merror:0.258631\n",
      "[50]\ttrain-merror:0.004233\teval-merror:0.116383\n",
      "403\n",
      "[0]\ttrain-merror:0.065302\teval-merror:0.195856\n",
      "[50]\ttrain-merror:0.004161\teval-merror:0.091176\n",
      "404\n",
      "[0]\ttrain-merror:0.070425\teval-merror:0.189889\n",
      "[50]\ttrain-merror:0.004078\teval-merror:0.095964\n",
      "405\n",
      "[0]\ttrain-merror:0.057819\teval-merror:0.29544\n",
      "[50]\ttrain-merror:0.003828\teval-merror:0.108579\n",
      "406\n",
      "[0]\ttrain-merror:0.064882\teval-merror:0.208829\n",
      "[50]\ttrain-merror:0.004432\teval-merror:0.110303\n",
      "407\n",
      "[0]\ttrain-merror:0.063062\teval-merror:0.213459\n",
      "[50]\ttrain-merror:0.00398\teval-merror:0.083234\n",
      "408\n",
      "[0]\ttrain-merror:0.064971\teval-merror:0.188865\n",
      "[50]\ttrain-merror:0.004229\teval-merror:0.076954\n",
      "409\n",
      "[0]\ttrain-merror:0.079956\teval-merror:0.255095\n",
      "[50]\ttrain-merror:0.003851\teval-merror:0.118924\n",
      "410\n",
      "[0]\ttrain-merror:0.066539\teval-merror:0.236457\n",
      "[50]\ttrain-merror:0.004119\teval-merror:0.095984\n",
      "411\n",
      "[0]\ttrain-merror:0.066433\teval-merror:0.150037\n",
      "[50]\ttrain-merror:0.004127\teval-merror:0.094078\n",
      "412\n",
      "[0]\ttrain-merror:0.062032\teval-merror:0.205078\n",
      "[50]\ttrain-merror:0.004197\teval-merror:0.085342\n",
      "413\n",
      "[0]\ttrain-merror:0.076465\teval-merror:0.174563\n",
      "[50]\ttrain-merror:0.003689\teval-merror:0.082441\n",
      "414\n",
      "[0]\ttrain-merror:0.067834\teval-merror:0.18255\n",
      "[50]\ttrain-merror:0.004588\teval-merror:0.053203\n",
      "415\n",
      "[0]\ttrain-merror:0.064774\teval-merror:0.276454\n",
      "[50]\ttrain-merror:0.004649\teval-merror:0.112915\n",
      "416\n",
      "[0]\ttrain-merror:0.056622\teval-merror:0.280424\n",
      "[50]\ttrain-merror:0.004314\teval-merror:0.127204\n",
      "417\n",
      "[0]\ttrain-merror:0.057781\teval-merror:0.21119\n",
      "[50]\ttrain-merror:0.004212\teval-merror:0.102623\n",
      "418\n",
      "[0]\ttrain-merror:0.060603\teval-merror:0.294137\n",
      "[50]\ttrain-merror:0.004433\teval-merror:0.100442\n",
      "419\n",
      "[0]\ttrain-merror:0.066865\teval-merror:0.255508\n",
      "[50]\ttrain-merror:0.004547\teval-merror:0.098668\n",
      "420\n",
      "[0]\ttrain-merror:0.064088\teval-merror:0.213499\n",
      "[50]\ttrain-merror:0.004347\teval-merror:0.093344\n",
      "421\n",
      "[0]\ttrain-merror:0.065295\teval-merror:0.253535\n",
      "[50]\ttrain-merror:0.004039\teval-merror:0.11632\n",
      "422\n",
      "[0]\ttrain-merror:0.065347\teval-merror:0.213467\n",
      "[50]\ttrain-merror:0.004141\teval-merror:0.101005\n",
      "423\n",
      "[0]\ttrain-merror:0.08395\teval-merror:0.26072\n",
      "[50]\ttrain-merror:0.004451\teval-merror:0.096745\n",
      "424\n",
      "[0]\ttrain-merror:0.076533\teval-merror:0.178722\n",
      "[50]\ttrain-merror:0.004081\teval-merror:0.070312\n",
      "425\n",
      "[0]\ttrain-merror:0.077371\teval-merror:0.311836\n",
      "[50]\ttrain-merror:0.004468\teval-merror:0.117088\n",
      "426\n",
      "[0]\ttrain-merror:0.064937\teval-merror:0.255636\n",
      "[50]\ttrain-merror:0.004059\teval-merror:0.098143\n",
      "427\n",
      "[0]\ttrain-merror:0.055806\teval-merror:0.207812\n",
      "[50]\ttrain-merror:0.004532\teval-merror:0.10783\n",
      "428\n",
      "[0]\ttrain-merror:0.081706\teval-merror:0.279822\n",
      "[50]\ttrain-merror:0.004146\teval-merror:0.080791\n",
      "429\n",
      "[0]\ttrain-merror:0.063581\teval-merror:0.213482\n",
      "[50]\ttrain-merror:0.004293\teval-merror:0.107613\n",
      "430\n",
      "[0]\ttrain-merror:0.061486\teval-merror:0.254579\n",
      "[50]\ttrain-merror:0.004466\teval-merror:0.088933\n",
      "431\n",
      "[0]\ttrain-merror:0.066814\teval-merror:0.246122\n",
      "[50]\ttrain-merror:0.004395\teval-merror:0.101408\n",
      "432\n",
      "[0]\ttrain-merror:0.061189\teval-merror:0.234752\n",
      "[50]\ttrain-merror:0.004396\teval-merror:0.103506\n",
      "433\n",
      "[0]\ttrain-merror:0.083807\teval-merror:0.20012\n",
      "[50]\ttrain-merror:0.004601\teval-merror:0.071643\n",
      "434\n",
      "[0]\ttrain-merror:0.081772\teval-merror:0.232207\n",
      "[50]\ttrain-merror:0.004524\teval-merror:0.06712\n",
      "435\n",
      "[0]\ttrain-merror:0.062704\teval-merror:0.278418\n",
      "[50]\ttrain-merror:0.004226\teval-merror:0.103912\n",
      "436\n",
      "[0]\ttrain-merror:0.066294\teval-merror:0.24643\n",
      "[50]\ttrain-merror:0.004325\teval-merror:0.106001\n",
      "437\n",
      "[0]\ttrain-merror:0.062843\teval-merror:0.203956\n",
      "[50]\ttrain-merror:0.004257\teval-merror:0.122955\n",
      "438\n",
      "[0]\ttrain-merror:0.065874\teval-merror:0.200727\n",
      "[50]\ttrain-merror:0.004015\teval-merror:0.099124\n",
      "439\n",
      "[0]\ttrain-merror:0.085384\teval-merror:0.202161\n",
      "[50]\ttrain-merror:0.004036\teval-merror:0.087499\n",
      "440\n",
      "[0]\ttrain-merror:0.063303\teval-merror:0.254713\n",
      "[50]\ttrain-merror:0.004236\teval-merror:0.101568\n",
      "441\n",
      "[0]\ttrain-merror:0.065073\teval-merror:0.200411\n",
      "[50]\ttrain-merror:0.004626\teval-merror:0.069882\n",
      "442\n",
      "[0]\ttrain-merror:0.073517\teval-merror:0.234123\n",
      "[50]\ttrain-merror:0.004487\teval-merror:0.084245\n",
      "443\n",
      "[0]\ttrain-merror:0.079774\teval-merror:0.209218\n",
      "[50]\ttrain-merror:0.004585\teval-merror:0.068995\n",
      "444\n",
      "[0]\ttrain-merror:0.077662\teval-merror:0.222333\n",
      "[50]\ttrain-merror:0.004303\teval-merror:0.08375\n",
      "445\n",
      "[0]\ttrain-merror:0.074937\teval-merror:0.222033\n",
      "[50]\ttrain-merror:0.004498\teval-merror:0.064748\n",
      "446\n",
      "[0]\ttrain-merror:0.070566\teval-merror:0.190214\n",
      "[50]\ttrain-merror:0.003991\teval-merror:0.078741\n",
      "447\n",
      "[0]\ttrain-merror:0.067197\teval-merror:0.233899\n",
      "[50]\ttrain-merror:0.004286\teval-merror:0.091156\n",
      "448\n",
      "[0]\ttrain-merror:0.065618\teval-merror:0.159522\n",
      "[50]\ttrain-merror:0.004339\teval-merror:0.059238\n",
      "449\n",
      "[0]\ttrain-merror:0.081551\teval-merror:0.236843\n",
      "[50]\ttrain-merror:0.004167\teval-merror:0.039198\n",
      "450\n",
      "[0]\ttrain-merror:0.069112\teval-merror:0.229338\n",
      "[50]\ttrain-merror:0.004473\teval-merror:0.088744\n",
      "451\n",
      "[0]\ttrain-merror:0.066628\teval-merror:0.205143\n",
      "[50]\ttrain-merror:0.004195\teval-merror:0.110055\n",
      "452\n",
      "[0]\ttrain-merror:0.081857\teval-merror:0.235252\n",
      "[50]\ttrain-merror:0.004315\teval-merror:0.097853\n",
      "453\n",
      "[0]\ttrain-merror:0.066949\teval-merror:0.206899\n",
      "[50]\ttrain-merror:0.004401\teval-merror:0.06696\n",
      "454\n",
      "[0]\ttrain-merror:0.071482\teval-merror:0.173799\n",
      "[50]\ttrain-merror:0.004324\teval-merror:0.080399\n",
      "455\n",
      "[0]\ttrain-merror:0.057962\teval-merror:0.182759\n",
      "[50]\ttrain-merror:0.004158\teval-merror:0.062709\n",
      "456\n",
      "[0]\ttrain-merror:0.055182\teval-merror:0.259259\n",
      "[50]\ttrain-merror:0.004475\teval-merror:0.098169\n",
      "457\n",
      "[0]\ttrain-merror:0.068638\teval-merror:0.172833\n",
      "[50]\ttrain-merror:0.004804\teval-merror:0.0788\n",
      "458\n",
      "[0]\ttrain-merror:0.068797\teval-merror:0.141665\n",
      "[50]\ttrain-merror:0.00425\teval-merror:0.054471\n",
      "459\n",
      "[0]\ttrain-merror:0.090243\teval-merror:0.183198\n",
      "[50]\ttrain-merror:0.004234\teval-merror:0.063494\n",
      "460\n",
      "[0]\ttrain-merror:0.068889\teval-merror:0.216399\n",
      "[50]\ttrain-merror:0.004236\teval-merror:0.087973\n",
      "461\n",
      "[0]\ttrain-merror:0.069943\teval-merror:0.300565\n",
      "[50]\ttrain-merror:0.00393\teval-merror:0.137179\n",
      "462\n",
      "[0]\ttrain-merror:0.069793\teval-merror:0.298214\n",
      "[50]\ttrain-merror:0.004167\teval-merror:0.151707\n",
      "463\n",
      "[0]\ttrain-merror:0.059761\teval-merror:0.34358\n",
      "[50]\ttrain-merror:0.004402\teval-merror:0.182673\n",
      "464\n",
      "[0]\ttrain-merror:0.07084\teval-merror:0.31355\n",
      "[50]\ttrain-merror:0.004584\teval-merror:0.187632\n",
      "465\n",
      "[0]\ttrain-merror:0.069845\teval-merror:0.27031\n",
      "[50]\ttrain-merror:0.004541\teval-merror:0.131374\n",
      "466\n",
      "[0]\ttrain-merror:0.066279\teval-merror:0.212967\n",
      "[50]\ttrain-merror:0.004483\teval-merror:0.094451\n",
      "467\n",
      "[0]\ttrain-merror:0.063441\teval-merror:0.300326\n",
      "[50]\ttrain-merror:0.004356\teval-merror:0.151058\n",
      "468\n",
      "[0]\ttrain-merror:0.049008\teval-merror:0.27205\n",
      "[50]\ttrain-merror:0.004918\teval-merror:0.225186\n",
      "469\n",
      "[0]\ttrain-merror:0.061557\teval-merror:0.290029\n",
      "[50]\ttrain-merror:0.004191\teval-merror:0.272342\n",
      "470\n",
      "[0]\ttrain-merror:0.063648\teval-merror:0.291472\n",
      "[50]\ttrain-merror:0.004281\teval-merror:0.137404\n",
      "471\n",
      "[0]\ttrain-merror:0.049232\teval-merror:0.212024\n",
      "[50]\ttrain-merror:0.004371\teval-merror:0.139929\n",
      "472\n",
      "[0]\ttrain-merror:0.05147\teval-merror:0.311393\n",
      "[50]\ttrain-merror:0.004763\teval-merror:0.169726\n",
      "473\n",
      "[0]\ttrain-merror:0.062495\teval-merror:0.377356\n",
      "[50]\ttrain-merror:0.004748\teval-merror:0.170184\n",
      "474\n",
      "[0]\ttrain-merror:0.059467\teval-merror:0.260953\n",
      "[50]\ttrain-merror:0.003826\teval-merror:0.148467\n",
      "475\n",
      "[0]\ttrain-merror:0.074232\teval-merror:0.217612\n",
      "[50]\ttrain-merror:0.004648\teval-merror:0.145489\n",
      "476\n",
      "[0]\ttrain-merror:0.055239\teval-merror:0.431583\n",
      "[50]\ttrain-merror:0.0044\teval-merror:0.260438\n",
      "477\n",
      "[0]\ttrain-merror:0.050573\teval-merror:0.242964\n",
      "[50]\ttrain-merror:0.004555\teval-merror:0.187515\n",
      "478\n",
      "[0]\ttrain-merror:0.053249\teval-merror:0.215114\n",
      "[50]\ttrain-merror:0.004495\teval-merror:0.143488\n",
      "479\n",
      "[0]\ttrain-merror:0.066782\teval-merror:0.236202\n",
      "[50]\ttrain-merror:0.004147\teval-merror:0.142954\n",
      "480\n",
      "[0]\ttrain-merror:0.071568\teval-merror:0.213862\n",
      "[50]\ttrain-merror:0.003909\teval-merror:0.153914\n",
      "481\n",
      "[0]\ttrain-merror:0.069575\teval-merror:0.22664\n",
      "[50]\ttrain-merror:0.004179\teval-merror:0.118079\n",
      "482\n",
      "[0]\ttrain-merror:0.05899\teval-merror:0.264503\n",
      "[50]\ttrain-merror:0.0045\teval-merror:0.12171\n",
      "483\n",
      "[0]\ttrain-merror:0.053518\teval-merror:0.327665\n",
      "[50]\ttrain-merror:0.004381\teval-merror:0.142278\n",
      "484\n",
      "[0]\ttrain-merror:0.05386\teval-merror:0.227585\n",
      "[50]\ttrain-merror:0.004176\teval-merror:0.163203\n",
      "485\n",
      "[0]\ttrain-merror:0.078931\teval-merror:0.235536\n",
      "[50]\ttrain-merror:0.004351\teval-merror:0.078683\n",
      "486\n",
      "[0]\ttrain-merror:0.067236\teval-merror:0.216743\n",
      "[50]\ttrain-merror:0.004496\teval-merror:0.082595\n",
      "487\n",
      "[0]\ttrain-merror:0.056434\teval-merror:0.327108\n",
      "[50]\ttrain-merror:0.004411\teval-merror:0.128237\n",
      "488\n",
      "[0]\ttrain-merror:0.061014\teval-merror:0.222678\n",
      "[50]\ttrain-merror:0.004536\teval-merror:0.108841\n",
      "489\n",
      "[0]\ttrain-merror:0.06729\teval-merror:0.222703\n",
      "[50]\ttrain-merror:0.00435\teval-merror:0.090282\n",
      "490\n",
      "[0]\ttrain-merror:0.069258\teval-merror:0.216255\n",
      "[50]\ttrain-merror:0.004243\teval-merror:0.094487\n",
      "491\n",
      "[0]\ttrain-merror:0.070702\teval-merror:0.273465\n",
      "[50]\ttrain-merror:0.004185\teval-merror:0.164397\n",
      "492\n",
      "[0]\ttrain-merror:0.063893\teval-merror:0.25681\n",
      "[50]\ttrain-merror:0.004593\teval-merror:0.112709\n",
      "493\n",
      "[0]\ttrain-merror:0.063284\teval-merror:0.220813\n",
      "[50]\ttrain-merror:0.004277\teval-merror:0.096158\n",
      "494\n",
      "[0]\ttrain-merror:0.063024\teval-merror:0.211674\n",
      "[50]\ttrain-merror:0.004679\teval-merror:0.092609\n",
      "495\n",
      "[0]\ttrain-merror:0.065259\teval-merror:0.179892\n",
      "[50]\ttrain-merror:0.004359\teval-merror:0.099505\n",
      "496\n",
      "[0]\ttrain-merror:0.079705\teval-merror:0.182256\n",
      "[50]\ttrain-merror:0.00414\teval-merror:0.080973\n",
      "497\n",
      "[0]\ttrain-merror:0.052426\teval-merror:0.273172\n",
      "[50]\ttrain-merror:0.004617\teval-merror:0.125379\n",
      "498\n",
      "[0]\ttrain-merror:0.05639\teval-merror:0.269007\n",
      "[50]\ttrain-merror:0.004853\teval-merror:0.12803\n",
      "499\n",
      "[0]\ttrain-merror:0.058023\teval-merror:0.198693\n",
      "[50]\ttrain-merror:0.004436\teval-merror:0.081771\n",
      "500\n",
      "[0]\ttrain-merror:0.053552\teval-merror:0.203108\n",
      "[50]\ttrain-merror:0.00478\teval-merror:0.112769\n",
      "501\n",
      "[0]\ttrain-merror:0.057449\teval-merror:0.303938\n",
      "[50]\ttrain-merror:0.004673\teval-merror:0.205563\n",
      "502\n",
      "[0]\ttrain-merror:0.060048\teval-merror:0.271781\n",
      "[50]\ttrain-merror:0.004086\teval-merror:0.130889\n",
      "503\n",
      "[0]\ttrain-merror:0.054744\teval-merror:0.222426\n",
      "[50]\ttrain-merror:0.004066\teval-merror:0.134946\n",
      "504\n",
      "[0]\ttrain-merror:0.066221\teval-merror:0.17087\n",
      "[50]\ttrain-merror:0.004586\teval-merror:0.107244\n",
      "505\n",
      "[0]\ttrain-merror:0.097706\teval-merror:0.236357\n",
      "[50]\ttrain-merror:0.004056\teval-merror:0.128424\n",
      "506\n",
      "[0]\ttrain-merror:0.071276\teval-merror:0.190352\n",
      "[50]\ttrain-merror:0.004285\teval-merror:0.081725\n",
      "507\n",
      "[0]\ttrain-merror:0.060379\teval-merror:0.308784\n",
      "[50]\ttrain-merror:0.004577\teval-merror:0.10963\n",
      "508\n",
      "[0]\ttrain-merror:0.055595\teval-merror:0.192342\n",
      "[50]\ttrain-merror:0.004591\teval-merror:0.119099\n",
      "509\n",
      "[0]\ttrain-merror:0.054539\teval-merror:0.226163\n",
      "[50]\ttrain-merror:0.004588\teval-merror:0.154424\n",
      "510\n",
      "[0]\ttrain-merror:0.061956\teval-merror:0.16816\n",
      "[50]\ttrain-merror:0.004678\teval-merror:0.078026\n",
      "511\n",
      "[0]\ttrain-merror:0.07503\teval-merror:0.174514\n",
      "[50]\ttrain-merror:0.004454\teval-merror:0.097512\n",
      "512\n",
      "[0]\ttrain-merror:0.05856\teval-merror:0.203619\n",
      "[50]\ttrain-merror:0.004412\teval-merror:0.104031\n",
      "513\n",
      "[0]\ttrain-merror:0.056848\teval-merror:0.271939\n",
      "[50]\ttrain-merror:0.00444\teval-merror:0.113079\n",
      "514\n",
      "[0]\ttrain-merror:0.054525\teval-merror:0.256498\n",
      "[50]\ttrain-merror:0.004415\teval-merror:0.141178\n",
      "515\n",
      "[0]\ttrain-merror:0.063508\teval-merror:0.230521\n",
      "[50]\ttrain-merror:0.00432\teval-merror:0.102515\n",
      "516\n",
      "[0]\ttrain-merror:0.074539\teval-merror:0.168539\n",
      "[50]\ttrain-merror:0.004233\teval-merror:0.071573\n",
      "517\n",
      "[0]\ttrain-merror:0.064267\teval-merror:0.27363\n",
      "[50]\ttrain-merror:0.004366\teval-merror:0.108923\n",
      "518\n",
      "[0]\ttrain-merror:0.069418\teval-merror:0.315451\n",
      "[50]\ttrain-merror:0.004512\teval-merror:0.146187\n",
      "519\n",
      "[0]\ttrain-merror:0.08673\teval-merror:0.281332\n",
      "[50]\ttrain-merror:0.004538\teval-merror:0.128369\n",
      "520\n",
      "[0]\ttrain-merror:0.073393\teval-merror:0.23606\n",
      "[50]\ttrain-merror:0.004609\teval-merror:0.095422\n",
      "521\n",
      "[0]\ttrain-merror:0.068057\teval-merror:0.180597\n",
      "[50]\ttrain-merror:0.004745\teval-merror:0.079842\n",
      "522\n",
      "[0]\ttrain-merror:0.062818\teval-merror:0.305288\n",
      "[50]\ttrain-merror:0.004698\teval-merror:0.145049\n",
      "523\n",
      "[0]\ttrain-merror:0.070542\teval-merror:0.30027\n",
      "[50]\ttrain-merror:0.00491\teval-merror:0.097712\n",
      "524\n",
      "[0]\ttrain-merror:0.062781\teval-merror:0.166039\n",
      "[50]\ttrain-merror:0.004683\teval-merror:0.11066\n",
      "525\n",
      "[0]\ttrain-merror:0.064235\teval-merror:0.162025\n",
      "[50]\ttrain-merror:0.004433\teval-merror:0.100042\n",
      "526\n",
      "[0]\ttrain-merror:0.067199\teval-merror:0.284089\n",
      "[50]\ttrain-merror:0.004796\teval-merror:0.166707\n",
      "527\n",
      "[0]\ttrain-merror:0.070312\teval-merror:0.318664\n",
      "[50]\ttrain-merror:0.004301\teval-merror:0.119784\n",
      "528\n",
      "[0]\ttrain-merror:0.068543\teval-merror:0.186492\n",
      "[50]\ttrain-merror:0.004221\teval-merror:0.10664\n",
      "529\n",
      "[0]\ttrain-merror:0.070542\teval-merror:0.219002\n",
      "[50]\ttrain-merror:0.004429\teval-merror:0.102973\n",
      "530\n",
      "[0]\ttrain-merror:0.073188\teval-merror:0.176911\n",
      "[50]\ttrain-merror:0.004956\teval-merror:0.083392\n",
      "531\n",
      "[0]\ttrain-merror:0.082105\teval-merror:0.172958\n",
      "[50]\ttrain-merror:0.005127\teval-merror:0.081829\n",
      "532\n",
      "[0]\ttrain-merror:0.056137\teval-merror:0.283507\n",
      "[50]\ttrain-merror:0.004678\teval-merror:0.153305\n",
      "533\n",
      "[0]\ttrain-merror:0.059201\teval-merror:0.276268\n",
      "[50]\ttrain-merror:0.004761\teval-merror:0.120295\n",
      "534\n",
      "[0]\ttrain-merror:0.059229\teval-merror:0.211742\n",
      "[50]\ttrain-merror:0.004723\teval-merror:0.094534\n",
      "535\n",
      "[0]\ttrain-merror:0.060096\teval-merror:0.218076\n",
      "[50]\ttrain-merror:0.004857\teval-merror:0.116187\n",
      "536\n",
      "[0]\ttrain-merror:0.05589\teval-merror:0.302909\n",
      "[50]\ttrain-merror:0.004926\teval-merror:0.190863\n",
      "537\n",
      "[0]\ttrain-merror:0.0615\teval-merror:0.26703\n",
      "[50]\ttrain-merror:0.004774\teval-merror:0.134078\n",
      "538\n",
      "[0]\ttrain-merror:0.06242\teval-merror:0.231907\n",
      "[50]\ttrain-merror:0.005056\teval-merror:0.121445\n",
      "539\n",
      "[0]\ttrain-merror:0.06343\teval-merror:0.235659\n",
      "[50]\ttrain-merror:0.004202\teval-merror:0.122481\n",
      "540\n",
      "[0]\ttrain-merror:0.08184\teval-merror:0.212202\n",
      "[50]\ttrain-merror:0.004578\teval-merror:0.12683\n",
      "541\n",
      "[0]\ttrain-merror:0.071489\teval-merror:0.169377\n",
      "[50]\ttrain-merror:0.004744\teval-merror:0.108608\n",
      "542\n",
      "[0]\ttrain-merror:0.061843\teval-merror:0.365995\n",
      "[50]\ttrain-merror:0.004824\teval-merror:0.136908\n",
      "543\n",
      "[0]\ttrain-merror:0.064963\teval-merror:0.278979\n",
      "[50]\ttrain-merror:0.004846\teval-merror:0.156263\n",
      "544\n",
      "[0]\ttrain-merror:0.061941\teval-merror:0.241232\n",
      "[50]\ttrain-merror:0.004695\teval-merror:0.137778\n",
      "545\n",
      "[0]\ttrain-merror:0.061359\teval-merror:0.238023\n",
      "[50]\ttrain-merror:0.004771\teval-merror:0.10005\n",
      "546\n",
      "[0]\ttrain-merror:0.066383\teval-merror:0.203288\n",
      "[50]\ttrain-merror:0.004812\teval-merror:0.114602\n",
      "547\n",
      "[0]\ttrain-merror:0.065629\teval-merror:0.226971\n",
      "[50]\ttrain-merror:0.004757\teval-merror:0.113336\n",
      "548\n",
      "[0]\ttrain-merror:0.056575\teval-merror:0.246333\n",
      "[50]\ttrain-merror:0.004765\teval-merror:0.129684\n",
      "549\n",
      "[0]\ttrain-merror:0.070037\teval-merror:0.242375\n",
      "[50]\ttrain-merror:0.004832\teval-merror:0.138645\n",
      "550\n",
      "[0]\ttrain-merror:0.076261\teval-merror:0.225471\n",
      "[50]\ttrain-merror:0.004674\teval-merror:0.111713\n",
      "551\n",
      "[0]\ttrain-merror:0.081281\teval-merror:0.172757\n",
      "[50]\ttrain-merror:0.004475\teval-merror:0.080504\n",
      "552\n",
      "[0]\ttrain-merror:0.05478\teval-merror:0.254857\n",
      "[50]\ttrain-merror:0.00492\teval-merror:0.115126\n",
      "553\n",
      "[0]\ttrain-merror:0.069235\teval-merror:0.253541\n",
      "[50]\ttrain-merror:0.004656\teval-merror:0.095008\n",
      "554\n",
      "[0]\ttrain-merror:0.058141\teval-merror:0.185511\n",
      "[50]\ttrain-merror:0.004386\teval-merror:0.067793\n",
      "555\n",
      "[0]\ttrain-merror:0.077276\teval-merror:0.245957\n",
      "[50]\ttrain-merror:0.004388\teval-merror:0.080523\n",
      "556\n",
      "[0]\ttrain-merror:0.067556\teval-merror:0.31\n",
      "[50]\ttrain-merror:0.004789\teval-merror:0.120094\n",
      "557\n",
      "[0]\ttrain-merror:0.065372\teval-merror:0.17109\n",
      "[50]\ttrain-merror:0.005017\teval-merror:0.08412\n",
      "558\n",
      "[0]\ttrain-merror:0.077078\teval-merror:0.287493\n",
      "[50]\ttrain-merror:0.004715\teval-merror:0.095358\n",
      "559\n",
      "[0]\ttrain-merror:0.079516\teval-merror:0.156791\n",
      "[50]\ttrain-merror:0.00489\teval-merror:0.078422\n",
      "560\n",
      "[0]\ttrain-merror:0.101523\teval-merror:0.205573\n",
      "[50]\ttrain-merror:0.004537\teval-merror:0.079266\n",
      "561\n",
      "[0]\ttrain-merror:0.07385\teval-merror:0.1878\n",
      "[50]\ttrain-merror:0.0048\teval-merror:0.045508\n",
      "562\n",
      "[0]\ttrain-merror:0.078072\teval-merror:0.275498\n",
      "[50]\ttrain-merror:0.004857\teval-merror:0.108071\n",
      "563\n",
      "[0]\ttrain-merror:0.065788\teval-merror:0.227832\n",
      "[50]\ttrain-merror:0.00451\teval-merror:0.091838\n",
      "564\n",
      "[0]\ttrain-merror:0.065504\teval-merror:0.253219\n",
      "[50]\ttrain-merror:0.004925\teval-merror:0.097598\n",
      "565\n",
      "[0]\ttrain-merror:0.083762\teval-merror:0.196549\n",
      "[50]\ttrain-merror:0.005215\teval-merror:0.079048\n",
      "566\n",
      "[0]\ttrain-merror:0.075191\teval-merror:0.198484\n",
      "[50]\ttrain-merror:0.005056\teval-merror:0.0768\n",
      "567\n",
      "[0]\ttrain-merror:0.069181\teval-merror:0.2062\n",
      "[50]\ttrain-merror:0.004419\teval-merror:0.075172\n",
      "568\n",
      "[0]\ttrain-merror:0.07481\teval-merror:0.252345\n",
      "[50]\ttrain-merror:0.004721\teval-merror:0.096786\n",
      "569\n",
      "[0]\ttrain-merror:0.073311\teval-merror:0.22547\n",
      "[50]\ttrain-merror:0.00469\teval-merror:0.094793\n",
      "570\n",
      "[0]\ttrain-merror:0.078166\teval-merror:0.201164\n",
      "[50]\ttrain-merror:0.004731\teval-merror:0.080938\n",
      "571\n",
      "[0]\ttrain-merror:0.074827\teval-merror:0.154576\n",
      "[50]\ttrain-merror:0.004373\teval-merror:0.0534\n",
      "572\n",
      "[0]\ttrain-merror:0.075068\teval-merror:0.277682\n",
      "[50]\ttrain-merror:0.005391\teval-merror:0.103253\n",
      "573\n",
      "[0]\ttrain-merror:0.064972\teval-merror:0.252838\n",
      "[50]\ttrain-merror:0.005137\teval-merror:0.079819\n",
      "574\n",
      "[0]\ttrain-merror:0.07268\teval-merror:0.217513\n",
      "[50]\ttrain-merror:0.00509\teval-merror:0.107944\n",
      "575\n",
      "[0]\ttrain-merror:0.066747\teval-merror:0.203175\n",
      "[50]\ttrain-merror:0.004814\teval-merror:0.062861\n",
      "576\n",
      "[0]\ttrain-merror:0.084442\teval-merror:0.204872\n",
      "[50]\ttrain-merror:0.004831\teval-merror:0.07706\n",
      "577\n",
      "[0]\ttrain-merror:0.068575\teval-merror:0.266394\n",
      "[50]\ttrain-merror:0.004622\teval-merror:0.090303\n",
      "578\n",
      "[0]\ttrain-merror:0.062393\teval-merror:0.240834\n",
      "[50]\ttrain-merror:0.00499\teval-merror:0.10558\n",
      "579\n",
      "[0]\ttrain-merror:0.088695\teval-merror:0.24534\n",
      "[50]\ttrain-merror:0.004675\teval-merror:0.100134\n",
      "580\n",
      "[0]\ttrain-merror:0.063922\teval-merror:0.175089\n",
      "[50]\ttrain-merror:0.004847\teval-merror:0.087402\n",
      "581\n",
      "[0]\ttrain-merror:0.074553\teval-merror:0.154503\n",
      "[50]\ttrain-merror:0.004327\teval-merror:0.064772\n",
      "582\n",
      "[0]\ttrain-merror:0.075701\teval-merror:0.31248\n",
      "[50]\ttrain-merror:0.004996\teval-merror:0.077266\n",
      "583\n",
      "[0]\ttrain-merror:0.073561\teval-merror:0.225149\n",
      "[50]\ttrain-merror:0.004739\teval-merror:0.107312\n",
      "584\n",
      "[0]\ttrain-merror:0.065522\teval-merror:0.191092\n",
      "[50]\ttrain-merror:0.004756\teval-merror:0.100573\n",
      "585\n",
      "[0]\ttrain-merror:0.084525\teval-merror:0.174958\n",
      "[50]\ttrain-merror:0.004854\teval-merror:0.070574\n",
      "586\n",
      "[0]\ttrain-merror:0.069284\teval-merror:0.174755\n",
      "[50]\ttrain-merror:0.004581\teval-merror:0.074807\n",
      "587\n",
      "[0]\ttrain-merror:0.054726\teval-merror:0.251458\n",
      "[50]\ttrain-merror:0.004185\teval-merror:0.117689\n",
      "588\n",
      "[0]\ttrain-merror:0.061897\teval-merror:0.277759\n",
      "[50]\ttrain-merror:0.00439\teval-merror:0.137186\n",
      "589\n",
      "[0]\ttrain-merror:0.066441\teval-merror:0.265563\n",
      "[50]\ttrain-merror:0.003744\teval-merror:0.117401\n",
      "590\n",
      "[0]\ttrain-merror:0.062789\teval-merror:0.263205\n",
      "[50]\ttrain-merror:0.004389\teval-merror:0.094542\n",
      "591\n",
      "[0]\ttrain-merror:0.065571\teval-merror:0.273503\n",
      "[50]\ttrain-merror:0.004278\teval-merror:0.092581\n",
      "592\n",
      "[0]\ttrain-merror:0.059033\teval-merror:0.306611\n",
      "[50]\ttrain-merror:0.004388\teval-merror:0.129006\n",
      "593\n",
      "[0]\ttrain-merror:0.061479\teval-merror:0.26658\n",
      "[50]\ttrain-merror:0.004111\teval-merror:0.123216\n",
      "594\n",
      "[0]\ttrain-merror:0.056168\teval-merror:0.218329\n",
      "[50]\ttrain-merror:0.003915\teval-merror:0.104275\n",
      "595\n",
      "[0]\ttrain-merror:0.069859\teval-merror:0.203082\n",
      "[50]\ttrain-merror:0.004117\teval-merror:0.105019\n",
      "596\n",
      "[0]\ttrain-merror:0.071649\teval-merror:0.288683\n",
      "[50]\ttrain-merror:0.004556\teval-merror:0.175906\n",
      "597\n",
      "[0]\ttrain-merror:0.064993\teval-merror:0.241495\n",
      "[50]\ttrain-merror:0.004369\teval-merror:0.127033\n",
      "598\n",
      "[0]\ttrain-merror:0.064618\teval-merror:0.214062\n",
      "[50]\ttrain-merror:0.004315\teval-merror:0.093079\n",
      "599\n",
      "[0]\ttrain-merror:0.071462\teval-merror:0.191952\n",
      "[50]\ttrain-merror:0.004389\teval-merror:0.105751\n",
      "600\n",
      "[0]\ttrain-merror:0.070834\teval-merror:0.158763\n",
      "[50]\ttrain-merror:0.004151\teval-merror:0.093025\n",
      "601\n",
      "[0]\ttrain-merror:0.071151\teval-merror:0.244326\n",
      "[50]\ttrain-merror:0.004028\teval-merror:0.106505\n",
      "602\n",
      "[0]\ttrain-merror:0.047557\teval-merror:0.233796\n",
      "[50]\ttrain-merror:0.004387\teval-merror:0.122824\n",
      "603\n",
      "[0]\ttrain-merror:0.068944\teval-merror:0.282786\n",
      "[50]\ttrain-merror:0.004016\teval-merror:0.14353\n",
      "604\n",
      "[0]\ttrain-merror:0.059182\teval-merror:0.252573\n",
      "[50]\ttrain-merror:0.004126\teval-merror:0.127455\n",
      "605\n",
      "[0]\ttrain-merror:0.057684\teval-merror:0.296132\n",
      "[50]\ttrain-merror:0.0045\teval-merror:0.136226\n",
      "606\n",
      "[0]\ttrain-merror:0.047996\teval-merror:0.291579\n",
      "[50]\ttrain-merror:0.004533\teval-merror:0.227595\n",
      "607\n",
      "[0]\ttrain-merror:0.053449\teval-merror:0.224093\n",
      "[50]\ttrain-merror:0.004575\teval-merror:0.138772\n",
      "608\n",
      "[0]\ttrain-merror:0.063343\teval-merror:0.278552\n",
      "[50]\ttrain-merror:0.004196\teval-merror:0.117671\n",
      "609\n",
      "[0]\ttrain-merror:0.058279\teval-merror:0.276398\n",
      "[50]\ttrain-merror:0.004211\teval-merror:0.126893\n",
      "610\n",
      "[0]\ttrain-merror:0.067786\teval-merror:0.205128\n",
      "[50]\ttrain-merror:0.004488\teval-merror:0.134083\n",
      "611\n",
      "[0]\ttrain-merror:0.072977\teval-merror:0.289336\n",
      "[50]\ttrain-merror:0.004243\teval-merror:0.124134\n",
      "612\n",
      "[0]\ttrain-merror:0.056094\teval-merror:0.330042\n",
      "[50]\ttrain-merror:0.00436\teval-merror:0.138493\n",
      "613\n",
      "[0]\ttrain-merror:0.053889\teval-merror:0.28364\n",
      "[50]\ttrain-merror:0.00428\teval-merror:0.124206\n",
      "614\n",
      "[0]\ttrain-merror:0.053483\teval-merror:0.209043\n",
      "[50]\ttrain-merror:0.0042\teval-merror:0.141049\n",
      "615\n",
      "[0]\ttrain-merror:0.070109\teval-merror:0.268997\n",
      "[50]\ttrain-merror:0.004166\teval-merror:0.101364\n",
      "616\n",
      "[0]\ttrain-merror:0.059653\teval-merror:0.257419\n",
      "[50]\ttrain-merror:0.004148\teval-merror:0.124844\n",
      "617\n",
      "[0]\ttrain-merror:0.063295\teval-merror:0.268684\n",
      "[50]\ttrain-merror:0.004369\teval-merror:0.156456\n",
      "618\n",
      "[0]\ttrain-merror:0.057523\teval-merror:0.272559\n",
      "[50]\ttrain-merror:0.004421\teval-merror:0.152765\n",
      "619\n",
      "[0]\ttrain-merror:0.064603\teval-merror:0.227956\n",
      "[50]\ttrain-merror:0.004299\teval-merror:0.142424\n",
      "620\n",
      "[0]\ttrain-merror:0.073296\teval-merror:0.188228\n",
      "[50]\ttrain-merror:0.004176\teval-merror:0.115827\n",
      "621\n",
      "[0]\ttrain-merror:0.073439\teval-merror:0.219247\n",
      "[50]\ttrain-merror:0.004351\teval-merror:0.104103\n",
      "622\n",
      "[0]\ttrain-merror:0.05994\teval-merror:0.269629\n",
      "[50]\ttrain-merror:0.0044\teval-merror:0.104693\n",
      "623\n",
      "[0]\ttrain-merror:0.082013\teval-merror:0.253836\n",
      "[50]\ttrain-merror:0.004223\teval-merror:0.099196\n",
      "624\n",
      "[0]\ttrain-merror:0.064779\teval-merror:0.229159\n",
      "[50]\ttrain-merror:0.004397\teval-merror:0.072148\n",
      "625\n",
      "[0]\ttrain-merror:0.069947\teval-merror:0.263645\n",
      "[50]\ttrain-merror:0.004314\teval-merror:0.073558\n",
      "626\n",
      "[0]\ttrain-merror:0.075678\teval-merror:0.262513\n",
      "[50]\ttrain-merror:0.004116\teval-merror:0.141114\n",
      "627\n",
      "[0]\ttrain-merror:0.059067\teval-merror:0.207071\n",
      "[50]\ttrain-merror:0.004467\teval-merror:0.086684\n",
      "628\n",
      "[0]\ttrain-merror:0.063958\teval-merror:0.190308\n",
      "[50]\ttrain-merror:0.004094\teval-merror:0.077776\n",
      "629\n",
      "[0]\ttrain-merror:0.07248\teval-merror:0.157896\n",
      "[50]\ttrain-merror:0.004047\teval-merror:0.080435\n",
      "630\n",
      "[0]\ttrain-merror:0.087844\teval-merror:0.230837\n",
      "[50]\ttrain-merror:0.004154\teval-merror:0.065237\n",
      "631\n",
      "[0]\ttrain-merror:0.07368\teval-merror:0.204595\n",
      "[50]\ttrain-merror:0.004632\teval-merror:0.057376\n",
      "632\n",
      "[0]\ttrain-merror:0.062778\teval-merror:0.242409\n",
      "[50]\ttrain-merror:0.004288\teval-merror:0.096452\n",
      "633\n",
      "[0]\ttrain-merror:0.060882\teval-merror:0.220764\n",
      "[50]\ttrain-merror:0.00432\teval-merror:0.118448\n",
      "634\n",
      "[0]\ttrain-merror:0.060416\teval-merror:0.209497\n",
      "[50]\ttrain-merror:0.003963\teval-merror:0.108034\n",
      "635\n",
      "[0]\ttrain-merror:0.067316\teval-merror:0.174697\n",
      "[50]\ttrain-merror:0.004371\teval-merror:0.093012\n",
      "636\n",
      "[0]\ttrain-merror:0.072411\teval-merror:0.235026\n",
      "[50]\ttrain-merror:0.004373\teval-merror:0.100615\n",
      "637\n",
      "[0]\ttrain-merror:0.060445\teval-merror:0.238629\n",
      "[50]\ttrain-merror:0.004648\teval-merror:0.094871\n",
      "638\n",
      "[0]\ttrain-merror:0.061945\teval-merror:0.205684\n",
      "[50]\ttrain-merror:0.00433\teval-merror:0.104796\n",
      "639\n",
      "[0]\ttrain-merror:0.067063\teval-merror:0.203544\n",
      "[50]\ttrain-merror:0.004065\teval-merror:0.077317\n",
      "640\n",
      "[0]\ttrain-merror:0.061481\teval-merror:0.150127\n",
      "[50]\ttrain-merror:0.004112\teval-merror:0.08726\n",
      "641\n",
      "[0]\ttrain-merror:0.085967\teval-merror:0.188531\n",
      "[50]\ttrain-merror:0.00449\teval-merror:0.062223\n",
      "642\n",
      "[0]\ttrain-merror:0.066417\teval-merror:0.250768\n",
      "[50]\ttrain-merror:0.004683\teval-merror:0.099183\n",
      "643\n",
      "[0]\ttrain-merror:0.067471\teval-merror:0.239572\n",
      "[50]\ttrain-merror:0.004376\teval-merror:0.087079\n",
      "644\n",
      "[0]\ttrain-merror:0.063562\teval-merror:0.233133\n",
      "[50]\ttrain-merror:0.004694\teval-merror:0.100255\n",
      "645\n",
      "[0]\ttrain-merror:0.07906\teval-merror:0.224614\n",
      "[50]\ttrain-merror:0.004345\teval-merror:0.090604\n",
      "646\n",
      "[0]\ttrain-merror:0.07046\teval-merror:0.225941\n",
      "[50]\ttrain-merror:0.00415\teval-merror:0.083044\n",
      "647\n",
      "[0]\ttrain-merror:0.058326\teval-merror:0.235382\n",
      "[50]\ttrain-merror:0.004555\teval-merror:0.108599\n",
      "648\n",
      "[0]\ttrain-merror:0.066332\teval-merror:0.246964\n",
      "[50]\ttrain-merror:0.004688\teval-merror:0.097791\n",
      "649\n",
      "[0]\ttrain-merror:0.06065\teval-merror:0.261232\n",
      "[50]\ttrain-merror:0.004305\teval-merror:0.116904\n",
      "650\n",
      "[0]\ttrain-merror:0.072117\teval-merror:0.200764\n",
      "[50]\ttrain-merror:0.004335\teval-merror:0.084175\n",
      "651\n",
      "[0]\ttrain-merror:0.072781\teval-merror:0.225336\n",
      "[50]\ttrain-merror:0.00456\teval-merror:0.061679\n",
      "652\n",
      "[0]\ttrain-merror:0.073898\teval-merror:0.206397\n",
      "[50]\ttrain-merror:0.004778\teval-merror:0.084238\n",
      "653\n",
      "[0]\ttrain-merror:0.068454\teval-merror:0.211037\n",
      "[50]\ttrain-merror:0.004673\teval-merror:0.104232\n",
      "654\n",
      "[0]\ttrain-merror:0.059408\teval-merror:0.208198\n",
      "[50]\ttrain-merror:0.004411\teval-merror:0.109401\n",
      "655\n",
      "[0]\ttrain-merror:0.089466\teval-merror:0.232705\n",
      "[50]\ttrain-merror:0.004445\teval-merror:0.080981\n",
      "656\n",
      "[0]\ttrain-merror:0.075459\teval-merror:0.20531\n",
      "[50]\ttrain-merror:0.00432\teval-merror:0.070724\n",
      "657\n",
      "[0]\ttrain-merror:0.061853\teval-merror:0.248089\n",
      "[50]\ttrain-merror:0.005244\teval-merror:0.110444\n",
      "658\n",
      "[0]\ttrain-merror:0.078451\teval-merror:0.215717\n",
      "[50]\ttrain-merror:0.004632\teval-merror:0.09024\n",
      "659\n",
      "[0]\ttrain-merror:0.068593\teval-merror:0.277375\n",
      "[50]\ttrain-merror:0.004479\teval-merror:0.082336\n",
      "660\n",
      "[0]\ttrain-merror:0.07709\teval-merror:0.253809\n",
      "[50]\ttrain-merror:0.00467\teval-merror:0.083274\n",
      "661\n",
      "[0]\ttrain-merror:0.072045\teval-merror:0.287581\n",
      "[50]\ttrain-merror:0.004734\teval-merror:0.126561\n",
      "662\n",
      "[0]\ttrain-merror:0.057477\teval-merror:0.219317\n",
      "[50]\ttrain-merror:0.004782\teval-merror:0.09496\n",
      "663\n",
      "[0]\ttrain-merror:0.068105\teval-merror:0.225644\n",
      "[50]\ttrain-merror:0.004915\teval-merror:0.07294\n",
      "664\n",
      "[0]\ttrain-merror:0.081883\teval-merror:0.214143\n",
      "[50]\ttrain-merror:0.004766\teval-merror:0.080133\n",
      "665\n",
      "[0]\ttrain-merror:0.080296\teval-merror:0.206978\n",
      "[50]\ttrain-merror:0.004638\teval-merror:0.071771\n",
      "666\n",
      "[0]\ttrain-merror:0.06978\teval-merror:0.230272\n",
      "[50]\ttrain-merror:0.004528\teval-merror:0.051322\n",
      "667\n",
      "[0]\ttrain-merror:0.063657\teval-merror:0.221758\n",
      "[50]\ttrain-merror:0.004423\teval-merror:0.116903\n",
      "668\n",
      "[0]\ttrain-merror:0.066022\teval-merror:0.224879\n",
      "[50]\ttrain-merror:0.004151\teval-merror:0.120017\n",
      "669\n",
      "[0]\ttrain-merror:0.076953\teval-merror:0.201932\n",
      "[50]\ttrain-merror:0.004568\teval-merror:0.096741\n",
      "670\n",
      "[0]\ttrain-merror:0.085928\teval-merror:0.242982\n",
      "[50]\ttrain-merror:0.004922\teval-merror:0.098691\n",
      "671\n",
      "[0]\ttrain-merror:0.062983\teval-merror:0.204305\n",
      "[50]\ttrain-merror:0.004583\teval-merror:0.097874\n",
      "672\n",
      "[0]\ttrain-merror:0.082971\teval-merror:0.275762\n",
      "[50]\ttrain-merror:0.005078\teval-merror:0.093799\n",
      "673\n",
      "[0]\ttrain-merror:0.068753\teval-merror:0.217838\n",
      "[50]\ttrain-merror:0.004969\teval-merror:0.105001\n",
      "674\n",
      "[0]\ttrain-merror:0.071499\teval-merror:0.200615\n",
      "[50]\ttrain-merror:0.004452\teval-merror:0.094077\n",
      "675\n",
      "[0]\ttrain-merror:0.064281\teval-merror:0.219716\n",
      "[50]\ttrain-merror:0.004981\teval-merror:0.088683\n",
      "676\n",
      "[0]\ttrain-merror:0.085998\teval-merror:0.148138\n",
      "[50]\ttrain-merror:0.004293\teval-merror:0.068234\n",
      "677\n",
      "[0]\ttrain-merror:0.053391\teval-merror:0.287857\n",
      "[50]\ttrain-merror:0.004762\teval-merror:0.129999\n",
      "678\n",
      "[0]\ttrain-merror:0.063422\teval-merror:0.300819\n",
      "[50]\ttrain-merror:0.004636\teval-merror:0.091622\n",
      "679\n",
      "[0]\ttrain-merror:0.070665\teval-merror:0.25771\n",
      "[50]\ttrain-merror:0.004972\teval-merror:0.103036\n",
      "680\n",
      "[0]\ttrain-merror:0.066071\teval-merror:0.217237\n",
      "[50]\ttrain-merror:0.004344\teval-merror:0.07655\n",
      "681\n",
      "[0]\ttrain-merror:0.063681\teval-merror:0.183513\n",
      "[50]\ttrain-merror:0.004394\teval-merror:0.089719\n",
      "682\n",
      "[0]\ttrain-merror:0.062314\teval-merror:0.258202\n",
      "[50]\ttrain-merror:0.004601\teval-merror:0.087301\n",
      "683\n",
      "[0]\ttrain-merror:0.074163\teval-merror:0.22787\n",
      "[50]\ttrain-merror:0.004377\teval-merror:0.120852\n",
      "684\n",
      "[0]\ttrain-merror:0.07917\teval-merror:0.256353\n",
      "[50]\ttrain-merror:0.004752\teval-merror:0.11862\n",
      "685\n",
      "[0]\ttrain-merror:0.066063\teval-merror:0.196445\n",
      "[50]\ttrain-merror:0.005001\teval-merror:0.083248\n",
      "686\n",
      "[0]\ttrain-merror:0.082554\teval-merror:0.194381\n",
      "[50]\ttrain-merror:0.004534\teval-merror:0.064117\n",
      "687\n",
      "[0]\ttrain-merror:0.05699\teval-merror:0.203346\n",
      "[50]\ttrain-merror:0.005044\teval-merror:0.086473\n",
      "688\n",
      "[0]\ttrain-merror:0.082209\teval-merror:0.246735\n",
      "[50]\ttrain-merror:0.004789\teval-merror:0.095717\n",
      "689\n",
      "[0]\ttrain-merror:0.072259\teval-merror:0.243594\n",
      "[50]\ttrain-merror:0.004409\teval-merror:0.11815\n",
      "690\n",
      "[0]\ttrain-merror:0.066554\teval-merror:0.227648\n",
      "[50]\ttrain-merror:0.004789\teval-merror:0.080535\n",
      "691\n",
      "[0]\ttrain-merror:0.075401\teval-merror:0.181562\n",
      "[50]\ttrain-merror:0.004519\teval-merror:0.077857\n",
      "692\n",
      "[0]\ttrain-merror:0.066334\teval-merror:0.239407\n",
      "[50]\ttrain-merror:0.004573\teval-merror:0.109208\n",
      "693\n",
      "[0]\ttrain-merror:0.068167\teval-merror:0.223117\n",
      "[50]\ttrain-merror:0.004904\teval-merror:0.079487\n",
      "694\n",
      "[0]\ttrain-merror:0.068073\teval-merror:0.223594\n",
      "[50]\ttrain-merror:0.004808\teval-merror:0.087412\n",
      "695\n",
      "[0]\ttrain-merror:0.078773\teval-merror:0.193933\n",
      "[50]\ttrain-merror:0.004624\teval-merror:0.048318\n",
      "696\n",
      "[0]\ttrain-merror:0.076803\teval-merror:0.210501\n",
      "[50]\ttrain-merror:0.004331\teval-merror:0.059724\n",
      "697\n",
      "[0]\ttrain-merror:0.07128\teval-merror:0.189515\n",
      "[50]\ttrain-merror:0.004509\teval-merror:0.054443\n",
      "698\n",
      "[0]\ttrain-merror:0.07236\teval-merror:0.210407\n",
      "[50]\ttrain-merror:0.004513\teval-merror:0.076952\n",
      "699\n",
      "[0]\ttrain-merror:0.074181\teval-merror:0.184444\n",
      "[50]\ttrain-merror:0.004314\teval-merror:0.071885\n",
      "700\n",
      "[0]\ttrain-merror:0.065364\teval-merror:0.224137\n",
      "[50]\ttrain-merror:0.004751\teval-merror:0.051514\n",
      "701\n",
      "[0]\ttrain-merror:0.083664\teval-merror:0.177647\n",
      "[50]\ttrain-merror:0.004674\teval-merror:0.032497\n",
      "702\n",
      "[0]\ttrain-merror:0.071318\teval-merror:0.209959\n",
      "[50]\ttrain-merror:0.004385\teval-merror:0.089099\n",
      "703\n",
      "[0]\ttrain-merror:0.077091\teval-merror:0.186875\n",
      "[50]\ttrain-merror:0.004626\teval-merror:0.086838\n",
      "704\n",
      "[0]\ttrain-merror:0.078903\teval-merror:0.202624\n",
      "[50]\ttrain-merror:0.005134\teval-merror:0.091519\n",
      "705\n",
      "[0]\ttrain-merror:0.073118\teval-merror:0.193543\n",
      "[50]\ttrain-merror:0.004601\teval-merror:0.062012\n",
      "706\n",
      "[0]\ttrain-merror:0.073227\teval-merror:0.15066\n",
      "[50]\ttrain-merror:0.004658\teval-merror:0.058779\n",
      "707\n",
      "[0]\ttrain-merror:0.067822\teval-merror:0.155052\n",
      "[50]\ttrain-merror:0.00479\teval-merror:0.059545\n",
      "708\n",
      "[0]\ttrain-merror:0.071935\teval-merror:0.180975\n",
      "[50]\ttrain-merror:0.004634\teval-merror:0.078024\n",
      "709\n",
      "[0]\ttrain-merror:0.06239\teval-merror:0.204294\n",
      "[50]\ttrain-merror:0.004954\teval-merror:0.072887\n",
      "710\n",
      "[0]\ttrain-merror:0.070959\teval-merror:0.211478\n",
      "[50]\ttrain-merror:0.004872\teval-merror:0.053968\n",
      "711\n",
      "[0]\ttrain-merror:0.082935\teval-merror:0.178405\n",
      "[50]\ttrain-merror:0.004869\teval-merror:0.050929\n",
      "712\n",
      "[0]\ttrain-merror:0.074422\teval-merror:0.154028\n",
      "[50]\ttrain-merror:0.0049\teval-merror:0.071701\n",
      "713\n",
      "[0]\ttrain-merror:0.04787\teval-merror:0.256493\n",
      "[50]\ttrain-merror:0.003767\teval-merror:0.127549\n",
      "714\n",
      "[0]\ttrain-merror:0.053307\teval-merror:0.26336\n",
      "[50]\ttrain-merror:0.003986\teval-merror:0.146778\n",
      "715\n",
      "[0]\ttrain-merror:0.060507\teval-merror:0.309343\n",
      "[50]\ttrain-merror:0.003772\teval-merror:0.169559\n",
      "716\n",
      "[0]\ttrain-merror:0.0686\teval-merror:0.21096\n",
      "[50]\ttrain-merror:0.003786\teval-merror:0.101141\n",
      "717\n",
      "[0]\ttrain-merror:0.075802\teval-merror:0.200677\n",
      "[50]\ttrain-merror:0.003967\teval-merror:0.08288\n",
      "718\n",
      "[0]\ttrain-merror:0.05757\teval-merror:0.32161\n",
      "[50]\ttrain-merror:0.003842\teval-merror:0.158095\n",
      "719\n",
      "[0]\ttrain-merror:0.074614\teval-merror:0.315315\n",
      "[50]\ttrain-merror:0.003815\teval-merror:0.12872\n",
      "720\n",
      "[0]\ttrain-merror:0.052513\teval-merror:0.229348\n",
      "[50]\ttrain-merror:0.003885\teval-merror:0.121525\n",
      "721\n",
      "[0]\ttrain-merror:0.059905\teval-merror:0.241822\n",
      "[50]\ttrain-merror:0.003819\teval-merror:0.109681\n",
      "722\n",
      "[0]\ttrain-merror:0.061576\teval-merror:0.325619\n",
      "[50]\ttrain-merror:0.003891\teval-merror:0.190388\n",
      "723\n",
      "[0]\ttrain-merror:0.054144\teval-merror:0.248496\n",
      "[50]\ttrain-merror:0.003881\teval-merror:0.136902\n",
      "724\n",
      "[0]\ttrain-merror:0.069569\teval-merror:0.248115\n",
      "[50]\ttrain-merror:0.003623\teval-merror:0.113043\n",
      "725\n",
      "[0]\ttrain-merror:0.067116\teval-merror:0.224131\n",
      "[50]\ttrain-merror:0.004281\teval-merror:0.106826\n",
      "726\n",
      "[0]\ttrain-merror:0.07755\teval-merror:0.177002\n",
      "[50]\ttrain-merror:0.003817\teval-merror:0.097127\n",
      "727\n",
      "[0]\ttrain-merror:0.072033\teval-merror:0.167\n",
      "[50]\ttrain-merror:0.003758\teval-merror:0.08633\n",
      "728\n",
      "[0]\ttrain-merror:0.049622\teval-merror:0.297119\n",
      "[50]\ttrain-merror:0.004111\teval-merror:0.164323\n",
      "729\n",
      "[0]\ttrain-merror:0.054737\teval-merror:0.278111\n",
      "[50]\ttrain-merror:0.004066\teval-merror:0.172206\n",
      "730\n",
      "[0]\ttrain-merror:0.062682\teval-merror:0.212892\n",
      "[50]\ttrain-merror:0.003611\teval-merror:0.114324\n",
      "731\n",
      "[0]\ttrain-merror:0.067457\teval-merror:0.222717\n",
      "[50]\ttrain-merror:0.003989\teval-merror:0.122803\n",
      "732\n",
      "[0]\ttrain-merror:0.056353\teval-merror:0.335646\n",
      "[50]\ttrain-merror:0.003647\teval-merror:0.268019\n",
      "733\n",
      "[0]\ttrain-merror:0.045717\teval-merror:0.236535\n",
      "[50]\ttrain-merror:0.004093\teval-merror:0.136495\n",
      "734\n",
      "[0]\ttrain-merror:0.049249\teval-merror:0.194322\n",
      "[50]\ttrain-merror:0.003989\teval-merror:0.137523\n",
      "735\n",
      "[0]\ttrain-merror:0.07469\teval-merror:0.274954\n",
      "[50]\ttrain-merror:0.003882\teval-merror:0.148317\n",
      "736\n",
      "[0]\ttrain-merror:0.063753\teval-merror:0.207669\n",
      "[50]\ttrain-merror:0.003797\teval-merror:0.149508\n",
      "737\n",
      "[0]\ttrain-merror:0.06496\teval-merror:0.19251\n",
      "[50]\ttrain-merror:0.00396\teval-merror:0.088594\n",
      "738\n",
      "[0]\ttrain-merror:0.052087\teval-merror:0.402089\n",
      "[50]\ttrain-merror:0.00432\teval-merror:0.175162\n",
      "739\n",
      "[0]\ttrain-merror:0.04828\teval-merror:0.242522\n",
      "[50]\ttrain-merror:0.004044\teval-merror:0.136556\n",
      "740\n",
      "[0]\ttrain-merror:0.064649\teval-merror:0.254745\n",
      "[50]\ttrain-merror:0.003808\teval-merror:0.126879\n",
      "741\n",
      "[0]\ttrain-merror:0.058003\teval-merror:0.210485\n",
      "[50]\ttrain-merror:0.00387\teval-merror:0.115772\n",
      "742\n",
      "[0]\ttrain-merror:0.069528\teval-merror:0.193668\n",
      "[50]\ttrain-merror:0.003671\teval-merror:0.126727\n",
      "743\n",
      "[0]\ttrain-merror:0.068907\teval-merror:0.20262\n",
      "[50]\ttrain-merror:0.003922\teval-merror:0.105509\n",
      "744\n",
      "[0]\ttrain-merror:0.052287\teval-merror:0.276324\n",
      "[50]\ttrain-merror:0.004113\teval-merror:0.147799\n",
      "745\n",
      "[0]\ttrain-merror:0.056743\teval-merror:0.216492\n",
      "[50]\ttrain-merror:0.004024\teval-merror:0.13865\n",
      "746\n",
      "[0]\ttrain-merror:0.064609\teval-merror:0.190278\n",
      "[50]\ttrain-merror:0.003474\teval-merror:0.114243\n",
      "747\n",
      "[0]\ttrain-merror:0.083693\teval-merror:0.202122\n",
      "[50]\ttrain-merror:0.003931\teval-merror:0.088693\n",
      "748\n",
      "[0]\ttrain-merror:0.057667\teval-merror:0.254234\n",
      "[50]\ttrain-merror:0.0039\teval-merror:0.120584\n",
      "749\n",
      "[0]\ttrain-merror:0.063076\teval-merror:0.221497\n",
      "[50]\ttrain-merror:0.004079\teval-merror:0.127509\n",
      "750\n",
      "[0]\ttrain-merror:0.064098\teval-merror:0.220998\n",
      "[50]\ttrain-merror:0.004076\teval-merror:0.086351\n",
      "751\n",
      "[0]\ttrain-merror:0.073066\teval-merror:0.200154\n",
      "[50]\ttrain-merror:0.003949\teval-merror:0.089222\n",
      "752\n",
      "[0]\ttrain-merror:0.045807\teval-merror:0.300076\n",
      "[50]\ttrain-merror:0.003609\teval-merror:0.165427\n",
      "753\n",
      "[0]\ttrain-merror:0.062604\teval-merror:0.233615\n",
      "[50]\ttrain-merror:0.004193\teval-merror:0.097768\n",
      "754\n",
      "[0]\ttrain-merror:0.061195\teval-merror:0.193816\n",
      "[50]\ttrain-merror:0.004199\teval-merror:0.082006\n",
      "755\n",
      "[0]\ttrain-merror:0.072248\teval-merror:0.182511\n",
      "[50]\ttrain-merror:0.004165\teval-merror:0.091338\n",
      "756\n",
      "[0]\ttrain-merror:0.06949\teval-merror:0.201949\n",
      "[50]\ttrain-merror:0.003931\teval-merror:0.09953\n",
      "757\n",
      "[0]\ttrain-merror:0.072904\teval-merror:0.160307\n",
      "[50]\ttrain-merror:0.004072\teval-merror:0.055581\n",
      "758\n",
      "[0]\ttrain-merror:0.067761\teval-merror:0.274411\n",
      "[50]\ttrain-merror:0.004358\teval-merror:0.116113\n",
      "759\n",
      "[0]\ttrain-merror:0.057427\teval-merror:0.288126\n",
      "[50]\ttrain-merror:0.004142\teval-merror:0.118179\n",
      "760\n",
      "[0]\ttrain-merror:0.05928\teval-merror:0.241531\n",
      "[50]\ttrain-merror:0.004013\teval-merror:0.100827\n",
      "761\n",
      "[0]\ttrain-merror:0.064329\teval-merror:0.17862\n",
      "[50]\ttrain-merror:0.004289\teval-merror:0.083818\n",
      "762\n",
      "[0]\ttrain-merror:0.080962\teval-merror:0.178408\n",
      "[50]\ttrain-merror:0.003942\teval-merror:0.097271\n",
      "763\n",
      "[0]\ttrain-merror:0.071365\teval-merror:0.232893\n",
      "[50]\ttrain-merror:0.004535\teval-merror:0.09533\n",
      "764\n",
      "[0]\ttrain-merror:0.063016\teval-merror:0.219445\n",
      "[50]\ttrain-merror:0.004149\teval-merror:0.128322\n",
      "765\n",
      "[0]\ttrain-merror:0.066891\teval-merror:0.211693\n",
      "[50]\ttrain-merror:0.003821\teval-merror:0.106373\n",
      "766\n",
      "[0]\ttrain-merror:0.064462\teval-merror:0.212743\n",
      "[50]\ttrain-merror:0.004327\teval-merror:0.090621\n",
      "767\n",
      "[0]\ttrain-merror:0.079107\teval-merror:0.207064\n",
      "[50]\ttrain-merror:0.003964\teval-merror:0.07337\n",
      "768\n",
      "[0]\ttrain-merror:0.054029\teval-merror:0.237054\n",
      "[50]\ttrain-merror:0.004188\teval-merror:0.141107\n",
      "769\n",
      "[0]\ttrain-merror:0.048043\teval-merror:0.204721\n",
      "[50]\ttrain-merror:0.003987\teval-merror:0.092221\n",
      "770\n",
      "[0]\ttrain-merror:0.057159\teval-merror:0.200679\n",
      "[50]\ttrain-merror:0.004055\teval-merror:0.126695\n",
      "771\n",
      "[0]\ttrain-merror:0.068725\teval-merror:0.207948\n",
      "[50]\ttrain-merror:0.00394\teval-merror:0.077747\n",
      "772\n",
      "[0]\ttrain-merror:0.073017\teval-merror:0.219525\n",
      "[50]\ttrain-merror:0.003903\teval-merror:0.10782\n",
      "773\n",
      "[0]\ttrain-merror:0.074023\teval-merror:0.210013\n",
      "[50]\ttrain-merror:0.003969\teval-merror:0.082507\n",
      "774\n",
      "[0]\ttrain-merror:0.068361\teval-merror:0.295902\n",
      "[50]\ttrain-merror:0.003938\teval-merror:0.121595\n",
      "775\n",
      "[0]\ttrain-merror:0.0838\teval-merror:0.264085\n",
      "[50]\ttrain-merror:0.003974\teval-merror:0.149763\n",
      "776\n",
      "[0]\ttrain-merror:0.069848\teval-merror:0.185521\n",
      "[50]\ttrain-merror:0.004146\teval-merror:0.078945\n",
      "777\n",
      "[0]\ttrain-merror:0.068837\teval-merror:0.149209\n",
      "[50]\ttrain-merror:0.003708\teval-merror:0.071546\n",
      "778\n",
      "[0]\ttrain-merror:0.064954\teval-merror:0.195907\n",
      "[50]\ttrain-merror:0.004023\teval-merror:0.103373\n",
      "779\n",
      "[0]\ttrain-merror:0.057576\teval-merror:0.206098\n",
      "[50]\ttrain-merror:0.004032\teval-merror:0.115762\n",
      "780\n",
      "[0]\ttrain-merror:0.071909\teval-merror:0.215614\n",
      "[50]\ttrain-merror:0.004226\teval-merror:0.118503\n",
      "781\n",
      "[0]\ttrain-merror:0.074294\teval-merror:0.180334\n",
      "[50]\ttrain-merror:0.004025\teval-merror:0.083082\n",
      "782\n",
      "[0]\ttrain-merror:0.067787\teval-merror:0.179511\n",
      "[50]\ttrain-merror:0.004113\teval-merror:0.087553\n",
      "783\n",
      "[0]\ttrain-merror:0.052294\teval-merror:0.243801\n",
      "[50]\ttrain-merror:0.004032\teval-merror:0.117332\n",
      "784\n",
      "[0]\ttrain-merror:0.071617\teval-merror:0.258923\n",
      "[50]\ttrain-merror:0.003948\teval-merror:0.126553\n",
      "785\n",
      "[0]\ttrain-merror:0.076573\teval-merror:0.20738\n",
      "[50]\ttrain-merror:0.00394\teval-merror:0.098399\n",
      "786\n",
      "[0]\ttrain-merror:0.06695\teval-merror:0.170868\n",
      "[50]\ttrain-merror:0.004329\teval-merror:0.096681\n",
      "787\n",
      "[0]\ttrain-merror:0.059573\teval-merror:0.25119\n",
      "[50]\ttrain-merror:0.004193\teval-merror:0.157262\n",
      "788\n",
      "[0]\ttrain-merror:0.05984\teval-merror:0.218452\n",
      "[50]\ttrain-merror:0.004165\teval-merror:0.102444\n",
      "789\n",
      "[0]\ttrain-merror:0.057551\teval-merror:0.180309\n",
      "[50]\ttrain-merror:0.004227\teval-merror:0.086921\n",
      "790\n",
      "[0]\ttrain-merror:0.074425\teval-merror:0.203448\n",
      "[50]\ttrain-merror:0.004359\teval-merror:0.096575\n",
      "791\n",
      "[0]\ttrain-merror:0.070396\teval-merror:0.160102\n",
      "[50]\ttrain-merror:0.004006\teval-merror:0.090773\n",
      "792\n",
      "[0]\ttrain-merror:0.071138\teval-merror:0.176755\n",
      "[50]\ttrain-merror:0.004367\teval-merror:0.055505\n",
      "793\n",
      "[0]\ttrain-merror:0.073578\teval-merror:0.248546\n",
      "[50]\ttrain-merror:0.004356\teval-merror:0.148818\n",
      "794\n",
      "[0]\ttrain-merror:0.069826\teval-merror:0.249532\n",
      "[50]\ttrain-merror:0.004006\teval-merror:0.098507\n",
      "795\n",
      "[0]\ttrain-merror:0.078853\teval-merror:0.232181\n",
      "[50]\ttrain-merror:0.004311\teval-merror:0.102631\n",
      "796\n",
      "[0]\ttrain-merror:0.067029\teval-merror:0.171718\n",
      "[50]\ttrain-merror:0.004406\teval-merror:0.09037\n",
      "797\n",
      "[0]\ttrain-merror:0.067183\teval-merror:0.209323\n",
      "[50]\ttrain-merror:0.00413\teval-merror:0.099109\n",
      "798\n",
      "[0]\ttrain-merror:0.074054\teval-merror:0.198372\n",
      "[50]\ttrain-merror:0.004342\teval-merror:0.086298\n",
      "799\n",
      "[0]\ttrain-merror:0.063263\teval-merror:0.174406\n",
      "[50]\ttrain-merror:0.004005\teval-merror:0.118585\n",
      "800\n",
      "[0]\ttrain-merror:0.068365\teval-merror:0.154767\n",
      "[50]\ttrain-merror:0.004203\teval-merror:0.092047\n",
      "801\n",
      "[0]\ttrain-merror:0.076846\teval-merror:0.210469\n",
      "[50]\ttrain-merror:0.003961\teval-merror:0.092901\n",
      "802\n",
      "[0]\ttrain-merror:0.079885\teval-merror:0.15207\n",
      "[50]\ttrain-merror:0.004158\teval-merror:0.068304\n",
      "803\n",
      "[0]\ttrain-merror:0.057984\teval-merror:0.246281\n",
      "[50]\ttrain-merror:0.004382\teval-merror:0.143821\n",
      "804\n",
      "[0]\ttrain-merror:0.049848\teval-merror:0.266829\n",
      "[50]\ttrain-merror:0.004218\teval-merror:0.099602\n",
      "805\n",
      "[0]\ttrain-merror:0.056465\teval-merror:0.260009\n",
      "[50]\ttrain-merror:0.004057\teval-merror:0.109462\n",
      "806\n",
      "[0]\ttrain-merror:0.070175\teval-merror:0.165577\n",
      "[50]\ttrain-merror:0.004308\teval-merror:0.080604\n",
      "807\n",
      "[0]\ttrain-merror:0.072815\teval-merror:0.218116\n",
      "[50]\ttrain-merror:0.004025\teval-merror:0.125054\n",
      "808\n",
      "[0]\ttrain-merror:0.074196\teval-merror:0.207478\n",
      "[50]\ttrain-merror:0.004021\teval-merror:0.078118\n",
      "809\n",
      "[0]\ttrain-merror:0.064488\teval-merror:0.212079\n",
      "[50]\ttrain-merror:0.004316\teval-merror:0.13747\n",
      "810\n",
      "[0]\ttrain-merror:0.059412\teval-merror:0.205056\n",
      "[50]\ttrain-merror:0.004489\teval-merror:0.143789\n",
      "811\n",
      "[0]\ttrain-merror:0.067813\teval-merror:0.187255\n",
      "[50]\ttrain-merror:0.004172\teval-merror:0.080348\n",
      "812\n",
      "[0]\ttrain-merror:0.075663\teval-merror:0.152327\n",
      "[50]\ttrain-merror:0.003757\teval-merror:0.065297\n",
      "813\n",
      "[0]\ttrain-merror:0.057518\teval-merror:0.252927\n",
      "[50]\ttrain-merror:0.004462\teval-merror:0.096186\n",
      "814\n",
      "[0]\ttrain-merror:0.073305\teval-merror:0.196474\n",
      "[50]\ttrain-merror:0.004438\teval-merror:0.098896\n",
      "815\n",
      "[0]\ttrain-merror:0.060552\teval-merror:0.18723\n",
      "[50]\ttrain-merror:0.004152\teval-merror:0.099823\n",
      "816\n",
      "[0]\ttrain-merror:0.062319\teval-merror:0.220453\n",
      "[50]\ttrain-merror:0.003899\teval-merror:0.091399\n",
      "817\n",
      "[0]\ttrain-merror:0.074383\teval-merror:0.171299\n",
      "[50]\ttrain-merror:0.004593\teval-merror:0.094544\n",
      "818\n",
      "[0]\ttrain-merror:0.056879\teval-merror:0.242327\n",
      "[50]\ttrain-merror:0.004119\teval-merror:0.127926\n",
      "819\n",
      "[0]\ttrain-merror:0.07688\teval-merror:0.20524\n",
      "[50]\ttrain-merror:0.004118\teval-merror:0.081365\n",
      "820\n",
      "[0]\ttrain-merror:0.070301\teval-merror:0.281439\n",
      "[50]\ttrain-merror:0.003878\teval-merror:0.09192\n",
      "821\n",
      "[0]\ttrain-merror:0.080764\teval-merror:0.20849\n",
      "[50]\ttrain-merror:0.004294\teval-merror:0.064015\n",
      "822\n",
      "[0]\ttrain-merror:0.075388\teval-merror:0.210037\n",
      "[50]\ttrain-merror:0.00451\teval-merror:0.08728\n",
      "823\n",
      "[0]\ttrain-merror:0.081983\teval-merror:0.219967\n",
      "[50]\ttrain-merror:0.004349\teval-merror:0.054783\n",
      "824\n",
      "[0]\ttrain-merror:0.078035\teval-merror:0.220329\n",
      "[50]\ttrain-merror:0.004054\teval-merror:0.086606\n",
      "825\n",
      "[0]\ttrain-merror:0.071308\teval-merror:0.205787\n",
      "[50]\ttrain-merror:0.004038\teval-merror:0.087614\n",
      "826\n",
      "[0]\ttrain-merror:0.056553\teval-merror:0.178045\n",
      "[50]\ttrain-merror:0.004707\teval-merror:0.059918\n",
      "827\n",
      "[0]\ttrain-merror:0.06667\teval-merror:0.1263\n",
      "[50]\ttrain-merror:0.004333\teval-merror:0.041171\n",
      "828\n",
      "[0]\ttrain-merror:0.064504\teval-merror:0.208646\n",
      "[50]\ttrain-merror:0.004158\teval-merror:0.10253\n",
      "829\n",
      "[0]\ttrain-merror:0.079652\teval-merror:0.299241\n",
      "[50]\ttrain-merror:0.004352\teval-merror:0.096975\n",
      "830\n",
      "[0]\ttrain-merror:0.079954\teval-merror:0.236973\n",
      "[50]\ttrain-merror:0.004478\teval-merror:0.090751\n",
      "831\n",
      "[0]\ttrain-merror:0.08411\teval-merror:0.182286\n",
      "[50]\ttrain-merror:0.004545\teval-merror:0.065686\n",
      "832\n",
      "[0]\ttrain-merror:0.077026\teval-merror:0.177926\n",
      "[50]\ttrain-merror:0.004384\teval-merror:0.07231\n",
      "833\n",
      "[0]\ttrain-merror:0.056871\teval-merror:0.201795\n",
      "[50]\ttrain-merror:0.004547\teval-merror:0.074779\n",
      "834\n",
      "[0]\ttrain-merror:0.084158\teval-merror:0.254216\n",
      "[50]\ttrain-merror:0.004423\teval-merror:0.108934\n",
      "835\n",
      "[0]\ttrain-merror:0.081527\teval-merror:0.185629\n",
      "[50]\ttrain-merror:0.00408\teval-merror:0.078033\n",
      "836\n",
      "[0]\ttrain-merror:0.068167\teval-merror:0.165262\n",
      "[50]\ttrain-merror:0.003918\teval-merror:0.054765\n",
      "837\n",
      "[0]\ttrain-merror:0.05691\teval-merror:0.139637\n",
      "[50]\ttrain-merror:0.004027\teval-merror:0.060419\n",
      "838\n",
      "[0]\ttrain-merror:0.070778\teval-merror:0.180454\n",
      "[50]\ttrain-merror:0.004425\teval-merror:0.082595\n",
      "839\n",
      "[0]\ttrain-merror:0.056604\teval-merror:0.232598\n",
      "[50]\ttrain-merror:0.003982\teval-merror:0.115991\n",
      "840\n",
      "[0]\ttrain-merror:0.084916\teval-merror:0.321147\n",
      "[50]\ttrain-merror:0.003587\teval-merror:0.131414\n",
      "841\n",
      "[0]\ttrain-merror:0.060184\teval-merror:0.189942\n",
      "[50]\ttrain-merror:0.003705\teval-merror:0.088306\n",
      "842\n",
      "[0]\ttrain-merror:0.078472\teval-merror:0.293101\n",
      "[50]\ttrain-merror:0.00383\teval-merror:0.084992\n",
      "843\n",
      "[0]\ttrain-merror:0.070772\teval-merror:0.340622\n",
      "[50]\ttrain-merror:0.003739\teval-merror:0.159366\n",
      "844\n",
      "[0]\ttrain-merror:0.071473\teval-merror:0.237134\n",
      "[50]\ttrain-merror:0.004233\teval-merror:0.107469\n",
      "845\n",
      "[0]\ttrain-merror:0.059218\teval-merror:0.177072\n",
      "[50]\ttrain-merror:0.00432\teval-merror:0.090822\n",
      "846\n",
      "[0]\ttrain-merror:0.067888\teval-merror:0.229544\n",
      "[50]\ttrain-merror:0.003982\teval-merror:0.092391\n",
      "847\n",
      "[0]\ttrain-merror:0.07594\teval-merror:0.147659\n",
      "[50]\ttrain-merror:0.003992\teval-merror:0.076338\n",
      "848\n",
      "[0]\ttrain-merror:0.061891\teval-merror:0.229554\n",
      "[50]\ttrain-merror:0.003719\teval-merror:0.062808\n",
      "849\n",
      "[0]\ttrain-merror:0.071204\teval-merror:0.308277\n",
      "[50]\ttrain-merror:0.003519\teval-merror:0.146899\n",
      "850\n",
      "[0]\ttrain-merror:0.068536\teval-merror:0.302993\n",
      "[50]\ttrain-merror:0.003744\teval-merror:0.132031\n",
      "851\n",
      "[0]\ttrain-merror:0.057449\teval-merror:0.247458\n",
      "[50]\ttrain-merror:0.003761\teval-merror:0.114116\n",
      "852\n",
      "[0]\ttrain-merror:0.068021\teval-merror:0.207876\n",
      "[50]\ttrain-merror:0.003827\teval-merror:0.119039\n",
      "853\n",
      "[0]\ttrain-merror:0.087606\teval-merror:0.17782\n",
      "[50]\ttrain-merror:0.003725\teval-merror:0.104968\n",
      "854\n",
      "[0]\ttrain-merror:0.064955\teval-merror:0.324821\n",
      "[50]\ttrain-merror:0.003878\teval-merror:0.096047\n",
      "855\n",
      "[0]\ttrain-merror:0.074485\teval-merror:0.275852\n",
      "[50]\ttrain-merror:0.004039\teval-merror:0.116025\n",
      "856\n",
      "[0]\ttrain-merror:0.068742\teval-merror:0.20106\n",
      "[50]\ttrain-merror:0.00393\teval-merror:0.094434\n",
      "857\n",
      "[0]\ttrain-merror:0.055724\teval-merror:0.204864\n",
      "[50]\ttrain-merror:0.003851\teval-merror:0.105567\n",
      "858\n",
      "[0]\ttrain-merror:0.084459\teval-merror:0.150967\n",
      "[50]\ttrain-merror:0.004081\teval-merror:0.076307\n",
      "859\n",
      "[0]\ttrain-merror:0.05583\teval-merror:0.291018\n",
      "[50]\ttrain-merror:0.004035\teval-merror:0.14158\n",
      "860\n",
      "[0]\ttrain-merror:0.048506\teval-merror:0.205523\n",
      "[50]\ttrain-merror:0.003917\teval-merror:0.096695\n",
      "861\n",
      "[0]\ttrain-merror:0.04893\teval-merror:0.202025\n",
      "[50]\ttrain-merror:0.003875\teval-merror:0.127803\n",
      "862\n",
      "[0]\ttrain-merror:0.05906\teval-merror:0.281939\n",
      "[50]\ttrain-merror:0.003759\teval-merror:0.090236\n",
      "863\n",
      "[0]\ttrain-merror:0.071613\teval-merror:0.26574\n",
      "[50]\ttrain-merror:0.003584\teval-merror:0.119186\n",
      "864\n",
      "[0]\ttrain-merror:0.071439\teval-merror:0.205547\n",
      "[50]\ttrain-merror:0.003665\teval-merror:0.107968\n",
      "865\n",
      "[0]\ttrain-merror:0.055082\teval-merror:0.222651\n",
      "[50]\ttrain-merror:0.003878\teval-merror:0.128177\n",
      "866\n",
      "[0]\ttrain-merror:0.06613\teval-merror:0.243557\n",
      "[50]\ttrain-merror:0.004133\teval-merror:0.141922\n",
      "867\n",
      "[0]\ttrain-merror:0.06158\teval-merror:0.190796\n",
      "[50]\ttrain-merror:0.003781\teval-merror:0.095115\n",
      "868\n",
      "[0]\ttrain-merror:0.082651\teval-merror:0.232763\n",
      "[50]\ttrain-merror:0.003571\teval-merror:0.091169\n",
      "869\n",
      "[0]\ttrain-merror:0.065314\teval-merror:0.279497\n",
      "[50]\ttrain-merror:0.004011\teval-merror:0.10511\n",
      "870\n",
      "[0]\ttrain-merror:0.078326\teval-merror:0.316647\n",
      "[50]\ttrain-merror:0.00376\teval-merror:0.128184\n",
      "871\n",
      "[0]\ttrain-merror:0.063647\teval-merror:0.231009\n",
      "[50]\ttrain-merror:0.004138\teval-merror:0.133508\n",
      "872\n",
      "[0]\ttrain-merror:0.06374\teval-merror:0.233819\n",
      "[50]\ttrain-merror:0.003611\teval-merror:0.107307\n",
      "873\n",
      "[0]\ttrain-merror:0.064231\teval-merror:0.170653\n",
      "[50]\ttrain-merror:0.003537\teval-merror:0.095217\n",
      "874\n",
      "[0]\ttrain-merror:0.076488\teval-merror:0.230775\n",
      "[50]\ttrain-merror:0.003886\teval-merror:0.108053\n",
      "875\n",
      "[0]\ttrain-merror:0.067155\teval-merror:0.175471\n",
      "[50]\ttrain-merror:0.004129\teval-merror:0.076412\n",
      "876\n",
      "[0]\ttrain-merror:0.065226\teval-merror:0.232996\n",
      "[50]\ttrain-merror:0.003972\teval-merror:0.095311\n",
      "877\n",
      "[0]\ttrain-merror:0.069615\teval-merror:0.152919\n",
      "[50]\ttrain-merror:0.004014\teval-merror:0.073792\n",
      "878\n",
      "[0]\ttrain-merror:0.0748\teval-merror:0.184567\n",
      "[50]\ttrain-merror:0.003671\teval-merror:0.081566\n",
      "879\n",
      "[0]\ttrain-merror:0.078763\teval-merror:0.224701\n",
      "[50]\ttrain-merror:0.004068\teval-merror:0.057862\n",
      "880\n",
      "[0]\ttrain-merror:0.062115\teval-merror:0.212454\n",
      "[50]\ttrain-merror:0.003768\teval-merror:0.093542\n",
      "881\n",
      "[0]\ttrain-merror:0.066961\teval-merror:0.206576\n",
      "[50]\ttrain-merror:0.003807\teval-merror:0.102697\n",
      "882\n",
      "[0]\ttrain-merror:0.057341\teval-merror:0.177855\n",
      "[50]\ttrain-merror:0.004119\teval-merror:0.062852\n",
      "883\n",
      "[0]\ttrain-merror:0.077604\teval-merror:0.183759\n",
      "[50]\ttrain-merror:0.003931\teval-merror:0.046412\n",
      "884\n",
      "[0]\ttrain-merror:0.077258\teval-merror:0.251021\n",
      "[50]\ttrain-merror:0.004167\teval-merror:0.105932\n",
      "885\n",
      "[0]\ttrain-merror:0.059476\teval-merror:0.190381\n",
      "[50]\ttrain-merror:0.003821\teval-merror:0.103701\n",
      "886\n",
      "[0]\ttrain-merror:0.048822\teval-merror:0.175612\n",
      "[50]\ttrain-merror:0.00398\teval-merror:0.103017\n",
      "887\n",
      "[0]\ttrain-merror:0.076771\teval-merror:0.167225\n",
      "[50]\ttrain-merror:0.003941\teval-merror:0.075107\n",
      "888\n",
      "[0]\ttrain-merror:0.068238\teval-merror:0.17364\n",
      "[50]\ttrain-merror:0.003961\teval-merror:0.078118\n",
      "889\n",
      "[0]\ttrain-merror:0.055502\teval-merror:0.216714\n",
      "[50]\ttrain-merror:0.003961\teval-merror:0.086052\n",
      "890\n",
      "[0]\ttrain-merror:0.069427\teval-merror:0.260825\n",
      "[50]\ttrain-merror:0.003681\teval-merror:0.120238\n",
      "891\n",
      "[0]\ttrain-merror:0.073374\teval-merror:0.230746\n",
      "[50]\ttrain-merror:0.00409\teval-merror:0.082268\n",
      "892\n",
      "[0]\ttrain-merror:0.086175\teval-merror:0.214826\n",
      "[50]\ttrain-merror:0.004274\teval-merror:0.062945\n",
      "893\n",
      "[0]\ttrain-merror:0.081585\teval-merror:0.212371\n",
      "[50]\ttrain-merror:0.003859\teval-merror:0.075384\n",
      "894\n",
      "[0]\ttrain-merror:0.080544\teval-merror:0.220074\n",
      "[50]\ttrain-merror:0.003806\teval-merror:0.082922\n",
      "895\n",
      "[0]\ttrain-merror:0.07163\teval-merror:0.206118\n",
      "[50]\ttrain-merror:0.004266\teval-merror:0.123626\n",
      "896\n",
      "[0]\ttrain-merror:0.064226\teval-merror:0.224602\n",
      "[50]\ttrain-merror:0.00438\teval-merror:0.094974\n",
      "897\n",
      "[0]\ttrain-merror:0.065015\teval-merror:0.180209\n",
      "[50]\ttrain-merror:0.004381\teval-merror:0.089967\n",
      "898\n",
      "[0]\ttrain-merror:0.070712\teval-merror:0.186084\n",
      "[50]\ttrain-merror:0.004112\teval-merror:0.086719\n",
      "899\n",
      "[0]\ttrain-merror:0.078702\teval-merror:0.206831\n",
      "[50]\ttrain-merror:0.004282\teval-merror:0.076501\n",
      "900\n",
      "[0]\ttrain-merror:0.066981\teval-merror:0.160761\n",
      "[50]\ttrain-merror:0.004094\teval-merror:0.056878\n",
      "901\n",
      "[0]\ttrain-merror:0.070215\teval-merror:0.17388\n",
      "[50]\ttrain-merror:0.004236\teval-merror:0.088234\n",
      "902\n",
      "[0]\ttrain-merror:0.072688\teval-merror:0.231755\n",
      "[50]\ttrain-merror:0.004384\teval-merror:0.072382\n",
      "903\n",
      "[0]\ttrain-merror:0.075414\teval-merror:0.185053\n",
      "[50]\ttrain-merror:0.004169\teval-merror:0.066485\n",
      "904\n",
      "[0]\ttrain-merror:0.087918\teval-merror:0.187254\n",
      "[50]\ttrain-merror:0.004276\teval-merror:0.03917\n",
      "905\n",
      "[0]\ttrain-merror:0.080563\teval-merror:0.255633\n",
      "[50]\ttrain-merror:0.004428\teval-merror:0.113835\n",
      "906\n",
      "[0]\ttrain-merror:0.062952\teval-merror:0.176156\n",
      "[50]\ttrain-merror:0.003965\teval-merror:0.090601\n",
      "907\n",
      "[0]\ttrain-merror:0.071001\teval-merror:0.226984\n",
      "[50]\ttrain-merror:0.003935\teval-merror:0.098732\n",
      "908\n",
      "[0]\ttrain-merror:0.086635\teval-merror:0.210213\n",
      "[50]\ttrain-merror:0.004111\teval-merror:0.074848\n",
      "909\n",
      "[0]\ttrain-merror:0.06996\teval-merror:0.159949\n",
      "[50]\ttrain-merror:0.004326\teval-merror:0.071635\n",
      "910\n",
      "[0]\ttrain-merror:0.055497\teval-merror:0.176425\n",
      "[50]\ttrain-merror:0.003964\teval-merror:0.084852\n",
      "911\n",
      "[0]\ttrain-merror:0.064381\teval-merror:0.185722\n",
      "[50]\ttrain-merror:0.004381\teval-merror:0.101512\n",
      "912\n",
      "[0]\ttrain-merror:0.073383\teval-merror:0.199281\n",
      "[50]\ttrain-merror:0.004289\teval-merror:0.089231\n",
      "913\n",
      "[0]\ttrain-merror:0.075853\teval-merror:0.21589\n",
      "[50]\ttrain-merror:0.003995\teval-merror:0.067072\n",
      "914\n",
      "[0]\ttrain-merror:0.067945\teval-merror:0.181575\n",
      "[50]\ttrain-merror:0.004499\teval-merror:0.066692\n",
      "915\n",
      "[0]\ttrain-merror:0.063463\teval-merror:0.172551\n",
      "[50]\ttrain-merror:0.004431\teval-merror:0.086094\n",
      "916\n",
      "[0]\ttrain-merror:0.075222\teval-merror:0.195468\n",
      "[50]\ttrain-merror:0.00405\teval-merror:0.069552\n",
      "917\n",
      "[0]\ttrain-merror:0.087522\teval-merror:0.222668\n",
      "[50]\ttrain-merror:0.0042\teval-merror:0.092559\n",
      "918\n",
      "[0]\ttrain-merror:0.095532\teval-merror:0.241485\n",
      "[50]\ttrain-merror:0.004348\teval-merror:0.056727\n",
      "919\n",
      "[0]\ttrain-merror:0.091041\teval-merror:0.181329\n",
      "[50]\ttrain-merror:0.004645\teval-merror:0.038851\n",
      "920\n",
      "[0]\ttrain-merror:0.089296\teval-merror:0.180879\n",
      "[50]\ttrain-merror:0.003788\teval-merror:0.043201\n",
      "921\n",
      "[0]\ttrain-merror:0.080355\teval-merror:0.202118\n",
      "[50]\ttrain-merror:0.004162\teval-merror:0.070658\n",
      "922\n",
      "[0]\ttrain-merror:0.082069\teval-merror:0.171918\n",
      "[50]\ttrain-merror:0.004133\teval-merror:0.054931\n",
      "923\n"
     ]
    }
   ],
   "source": [
    "# Find best iteration by early stopping\n",
    "\n",
    "complete_cs_results = []\n",
    "\n",
    "for train_test_idx, train_test in enumerate(complete_cs_split):\n",
    "    train_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"train\"])].index.tolist()\n",
    "    test_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"test\"])].index.tolist()\n",
    "    \n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    train_dmatrix = xgb.DMatrix(X_train, y_train)\n",
    "    test_dmatrix = xgb.DMatrix(X_test, y_test)\n",
    "    watchlist = [(train_dmatrix, \"train\"), (test_dmatrix, \"eval\")]\n",
    "    results = {}\n",
    "    \n",
    "    booster = xgb.train(params=COMPLETE_CS_PARAMS, dtrain=train_dmatrix, num_boost_round=NUM_ROUNDS, \n",
    "                        evals=watchlist, evals_result=results, verbose_eval=50)\n",
    "    \n",
    "    complete_cs_results.append(results[\"eval\"][\"merror\"])\n",
    "    print(train_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"results/complete_cs_trees\", \"wb\") as f:\n",
    "    pickle.dump(complete_cs_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save intermediate results\n",
    "\n",
    "complete_cs_results_csv = \"results/complete_cs.csv\"\n",
    "open(complete_cs_results_csv, \"w\").close()\n",
    "with open(complete_cs_results_csv, \"a\") as f:\n",
    "    complete_cs_results_pdf = pd.DataFrame(columns=[\"train_index\", \"tree\", \"error\"])\n",
    "    complete_cs_results_pdf.to_csv(f, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.04838\teval-merror:0.338531\n",
      "[1]\ttrain-merror:0.032147\teval-merror:0.310103\n",
      "[2]\ttrain-merror:0.025436\teval-merror:0.271463\n",
      "[3]\ttrain-merror:0.022592\teval-merror:0.259545\n",
      "[4]\ttrain-merror:0.021665\teval-merror:0.243407\n",
      "[5]\ttrain-merror:0.019525\teval-merror:0.235141\n",
      "[6]\ttrain-merror:0.01831\teval-merror:0.226285\n",
      "[7]\ttrain-merror:0.016968\teval-merror:0.225716\n",
      "[8]\ttrain-merror:0.015722\teval-merror:0.224185\n",
      "[9]\ttrain-merror:0.014699\teval-merror:0.225038\n",
      "[10]\ttrain-merror:0.013677\teval-merror:0.219287\n",
      "[11]\ttrain-merror:0.012686\teval-merror:0.212049\n",
      "[12]\ttrain-merror:0.011664\teval-merror:0.211284\n",
      "[13]\ttrain-merror:0.010897\teval-merror:0.205248\n",
      "[14]\ttrain-merror:0.010321\teval-merror:0.202887\n",
      "[15]\ttrain-merror:0.009459\teval-merror:0.20422\n",
      "[16]\ttrain-merror:0.008915\teval-merror:0.205904\n",
      "[17]\ttrain-merror:0.008244\teval-merror:0.201137\n",
      "[18]\ttrain-merror:0.007637\teval-merror:0.200197\n",
      "[19]\ttrain-merror:0.007062\teval-merror:0.199759\n",
      "[20]\ttrain-merror:0.006487\teval-merror:0.198579\n",
      "[21]\ttrain-merror:0.005688\teval-merror:0.196567\n",
      "[22]\ttrain-merror:0.005496\teval-merror:0.194008\n",
      "[23]\ttrain-merror:0.005145\teval-merror:0.193134\n",
      "[24]\ttrain-merror:0.00441\teval-merror:0.19075\n",
      "[25]\ttrain-merror:0.00425\teval-merror:0.189963\n",
      "[26]\ttrain-merror:0.00393\teval-merror:0.192499\n",
      "[27]\ttrain-merror:0.003579\teval-merror:0.192018\n",
      "[28]\ttrain-merror:0.003579\teval-merror:0.192281\n",
      "[29]\ttrain-merror:0.003164\teval-merror:0.190903\n",
      "[30]\ttrain-merror:0.0031\teval-merror:0.190072\n",
      "[31]\ttrain-merror:0.002812\teval-merror:0.189832\n",
      "[32]\ttrain-merror:0.002588\teval-merror:0.189219\n",
      "[33]\ttrain-merror:0.002588\teval-merror:0.191931\n",
      "[34]\ttrain-merror:0.00262\teval-merror:0.189547\n",
      "[35]\ttrain-merror:0.002461\teval-merror:0.188935\n",
      "[36]\ttrain-merror:0.002365\teval-merror:0.186901\n",
      "[37]\ttrain-merror:0.002141\teval-merror:0.187798\n",
      "[38]\ttrain-merror:0.002173\teval-merror:0.188498\n",
      "[39]\ttrain-merror:0.002045\teval-merror:0.191712\n",
      "[40]\ttrain-merror:0.001949\teval-merror:0.18981\n",
      "[41]\ttrain-merror:0.001821\teval-merror:0.188563\n",
      "[42]\ttrain-merror:0.001726\teval-merror:0.188869\n",
      "[43]\ttrain-merror:0.001662\teval-merror:0.189394\n",
      "[44]\ttrain-merror:0.001598\teval-merror:0.187754\n",
      "[45]\ttrain-merror:0.001502\teval-merror:0.187557\n",
      "[46]\ttrain-merror:0.00147\teval-merror:0.187579\n",
      "[47]\ttrain-merror:0.00147\teval-merror:0.187404\n",
      "[48]\ttrain-merror:0.00147\teval-merror:0.185939\n",
      "[49]\ttrain-merror:0.001438\teval-merror:0.186355\n",
      "[50]\ttrain-merror:0.00147\teval-merror:0.185065\n",
      "[51]\ttrain-merror:0.001438\teval-merror:0.185349\n",
      "[52]\ttrain-merror:0.001406\teval-merror:0.184255\n",
      "[53]\ttrain-merror:0.001406\teval-merror:0.183709\n",
      "[54]\ttrain-merror:0.001406\teval-merror:0.184649\n",
      "[55]\ttrain-merror:0.001342\teval-merror:0.183818\n",
      "[56]\ttrain-merror:0.001278\teval-merror:0.183949\n",
      "[57]\ttrain-merror:0.001374\teval-merror:0.183665\n",
      "[58]\ttrain-merror:0.001246\teval-merror:0.181719\n",
      "[59]\ttrain-merror:0.001118\teval-merror:0.182965\n",
      "[60]\ttrain-merror:0.001086\teval-merror:0.183184\n",
      "[61]\ttrain-merror:0.001086\teval-merror:0.182528\n",
      "[62]\ttrain-merror:0.001055\teval-merror:0.183031\n",
      "[63]\ttrain-merror:0.001055\teval-merror:0.183578\n",
      "[64]\ttrain-merror:0.001023\teval-merror:0.18255\n",
      "[65]\ttrain-merror:0.000991\teval-merror:0.182572\n",
      "[66]\ttrain-merror:0.000991\teval-merror:0.1829\n",
      "[67]\ttrain-merror:0.000831\teval-merror:0.18126\n",
      "[68]\ttrain-merror:0.000895\teval-merror:0.181281\n",
      "[69]\ttrain-merror:0.000927\teval-merror:0.181609\n",
      "[70]\ttrain-merror:0.000895\teval-merror:0.181741\n",
      "[71]\ttrain-merror:0.000863\teval-merror:0.181763\n",
      "[72]\ttrain-merror:0.000863\teval-merror:0.181719\n",
      "[73]\ttrain-merror:0.000863\teval-merror:0.181763\n",
      "[74]\ttrain-merror:0.000895\teval-merror:0.181631\n",
      "[75]\ttrain-merror:0.000863\teval-merror:0.182047\n",
      "[76]\ttrain-merror:0.000767\teval-merror:0.182659\n",
      "[77]\ttrain-merror:0.000767\teval-merror:0.181325\n",
      "[78]\ttrain-merror:0.000767\teval-merror:0.181281\n",
      "[79]\ttrain-merror:0.000799\teval-merror:0.181435\n",
      "[80]\ttrain-merror:0.000767\teval-merror:0.180538\n",
      "[81]\ttrain-merror:0.000767\teval-merror:0.180319\n",
      "[82]\ttrain-merror:0.000831\teval-merror:0.180297\n",
      "[83]\ttrain-merror:0.000831\teval-merror:0.181544\n",
      "[84]\ttrain-merror:0.000831\teval-merror:0.181588\n",
      "[85]\ttrain-merror:0.000895\teval-merror:0.180276\n",
      "[86]\ttrain-merror:0.000863\teval-merror:0.179926\n",
      "[87]\ttrain-merror:0.000831\teval-merror:0.179401\n",
      "[88]\ttrain-merror:0.000767\teval-merror:0.178963\n",
      "[89]\ttrain-merror:0.000799\teval-merror:0.178723\n",
      "[90]\ttrain-merror:0.000799\teval-merror:0.17881\n",
      "[91]\ttrain-merror:0.000735\teval-merror:0.178439\n",
      "[92]\ttrain-merror:0.000799\teval-merror:0.178329\n",
      "[93]\ttrain-merror:0.000799\teval-merror:0.178592\n",
      "[94]\ttrain-merror:0.000735\teval-merror:0.179138\n",
      "[95]\ttrain-merror:0.000735\teval-merror:0.180516\n",
      "[96]\ttrain-merror:0.000767\teval-merror:0.180385\n",
      "[97]\ttrain-merror:0.000703\teval-merror:0.181106\n",
      "[98]\ttrain-merror:0.000671\teval-merror:0.181128\n",
      "[99]\ttrain-merror:0.000703\teval-merror:0.180538\n",
      "[0]\ttrain-merror:0.044366\teval-merror:0.286063\n",
      "[1]\ttrain-merror:0.028631\teval-merror:0.241893\n",
      "[2]\ttrain-merror:0.025023\teval-merror:0.240364\n",
      "[3]\ttrain-merror:0.022517\teval-merror:0.2506\n",
      "[4]\ttrain-merror:0.021014\teval-merror:0.230362\n",
      "[5]\ttrain-merror:0.01951\teval-merror:0.221911\n",
      "[6]\ttrain-merror:0.018374\teval-merror:0.226094\n",
      "[7]\ttrain-merror:0.016904\teval-merror:0.239154\n",
      "[8]\ttrain-merror:0.015468\teval-merror:0.234355\n",
      "[9]\ttrain-merror:0.014165\teval-merror:0.23788\n",
      "[10]\ttrain-merror:0.012929\teval-merror:0.236712\n",
      "[11]\ttrain-merror:0.012094\teval-merror:0.231212\n",
      "[12]\ttrain-merror:0.010891\teval-merror:0.234079\n",
      "[13]\ttrain-merror:0.010323\teval-merror:0.224544\n",
      "[14]\ttrain-merror:0.009555\teval-merror:0.223886\n",
      "[15]\ttrain-merror:0.008786\teval-merror:0.220722\n",
      "[16]\ttrain-merror:0.008152\teval-merror:0.221847\n",
      "[17]\ttrain-merror:0.00765\teval-merror:0.223673\n",
      "[18]\ttrain-merror:0.007183\teval-merror:0.219299\n",
      "[19]\ttrain-merror:0.006581\teval-merror:0.220488\n",
      "[20]\ttrain-merror:0.006114\teval-merror:0.21881\n",
      "[21]\ttrain-merror:0.005846\teval-merror:0.218917\n",
      "[22]\ttrain-merror:0.005212\teval-merror:0.219108\n",
      "[23]\ttrain-merror:0.005045\teval-merror:0.215752\n",
      "[24]\ttrain-merror:0.004577\teval-merror:0.217919\n",
      "[25]\ttrain-merror:0.004677\teval-merror:0.214861\n",
      "[26]\ttrain-merror:0.004009\teval-merror:0.21227\n",
      "[27]\ttrain-merror:0.003909\teval-merror:0.211675\n",
      "[28]\ttrain-merror:0.003775\teval-merror:0.210295\n",
      "[29]\ttrain-merror:0.003474\teval-merror:0.208214\n",
      "[30]\ttrain-merror:0.003374\teval-merror:0.207386\n",
      "[31]\ttrain-merror:0.003274\teval-merror:0.203542\n",
      "[32]\ttrain-merror:0.00304\teval-merror:0.203563\n",
      "[33]\ttrain-merror:0.00284\teval-merror:0.201801\n",
      "[34]\ttrain-merror:0.002873\teval-merror:0.199826\n",
      "[35]\ttrain-merror:0.002739\teval-merror:0.199274\n",
      "[36]\ttrain-merror:0.002506\teval-merror:0.201334\n",
      "[37]\ttrain-merror:0.002439\teval-merror:0.202098\n",
      "[38]\ttrain-merror:0.002205\teval-merror:0.203308\n",
      "[39]\ttrain-merror:0.002004\teval-merror:0.201737\n",
      "[40]\ttrain-merror:0.002071\teval-merror:0.202119\n",
      "[41]\ttrain-merror:0.002004\teval-merror:0.202183\n",
      "[42]\ttrain-merror:0.001904\teval-merror:0.202502\n",
      "[43]\ttrain-merror:0.001737\teval-merror:0.202417\n",
      "[44]\ttrain-merror:0.001637\teval-merror:0.199635\n",
      "[45]\ttrain-merror:0.001604\teval-merror:0.197702\n",
      "[46]\ttrain-merror:0.001637\teval-merror:0.19628\n",
      "[47]\ttrain-merror:0.001637\teval-merror:0.196152\n",
      "[48]\ttrain-merror:0.00167\teval-merror:0.196959\n",
      "[49]\ttrain-merror:0.00157\teval-merror:0.197978\n",
      "[50]\ttrain-merror:0.001537\teval-merror:0.199805\n",
      "[51]\ttrain-merror:0.001437\teval-merror:0.199656\n",
      "[52]\ttrain-merror:0.001403\teval-merror:0.199422\n",
      "[53]\ttrain-merror:0.00137\teval-merror:0.197193\n",
      "[54]\ttrain-merror:0.00127\teval-merror:0.198892\n",
      "[55]\ttrain-merror:0.001336\teval-merror:0.197809\n",
      "[56]\ttrain-merror:0.00127\teval-merror:0.197639\n",
      "[57]\ttrain-merror:0.00127\teval-merror:0.198424\n",
      "[58]\ttrain-merror:0.001336\teval-merror:0.19955\n",
      "[59]\ttrain-merror:0.001203\teval-merror:0.198\n",
      "[60]\ttrain-merror:0.001236\teval-merror:0.198594\n",
      "[61]\ttrain-merror:0.001169\teval-merror:0.198531\n",
      "[62]\ttrain-merror:0.001136\teval-merror:0.198233\n",
      "[63]\ttrain-merror:0.001136\teval-merror:0.198637\n",
      "[64]\ttrain-merror:0.001102\teval-merror:0.198042\n",
      "[65]\ttrain-merror:0.001102\teval-merror:0.197893\n",
      "[66]\ttrain-merror:0.001069\teval-merror:0.197617\n",
      "[67]\ttrain-merror:0.001036\teval-merror:0.197809\n",
      "[68]\ttrain-merror:0.001036\teval-merror:0.198594\n",
      "[69]\ttrain-merror:0.001002\teval-merror:0.198361\n",
      "[70]\ttrain-merror:0.001036\teval-merror:0.199507\n",
      "[71]\ttrain-merror:0.001036\teval-merror:0.19938\n",
      "[72]\ttrain-merror:0.001069\teval-merror:0.200293\n",
      "[73]\ttrain-merror:0.001002\teval-merror:0.20299\n",
      "[74]\ttrain-merror:0.001002\teval-merror:0.20282\n",
      "[75]\ttrain-merror:0.001002\teval-merror:0.202714\n",
      "[76]\ttrain-merror:0.001002\teval-merror:0.201695\n",
      "[77]\ttrain-merror:0.001002\teval-merror:0.201843\n",
      "[78]\ttrain-merror:0.001036\teval-merror:0.201673\n",
      "[79]\ttrain-merror:0.001002\teval-merror:0.201397\n",
      "[80]\ttrain-merror:0.001036\teval-merror:0.202374\n",
      "[81]\ttrain-merror:0.001036\teval-merror:0.202459\n",
      "[82]\ttrain-merror:0.001002\teval-merror:0.202395\n",
      "[83]\ttrain-merror:0.001002\teval-merror:0.202162\n",
      "[84]\ttrain-merror:0.000935\teval-merror:0.203032\n",
      "[85]\ttrain-merror:0.000969\teval-merror:0.203308\n",
      "[86]\ttrain-merror:0.000935\teval-merror:0.203011\n",
      "[87]\ttrain-merror:0.001002\teval-merror:0.201843\n",
      "[88]\ttrain-merror:0.001002\teval-merror:0.201737\n",
      "[89]\ttrain-merror:0.001002\teval-merror:0.201376\n",
      "[90]\ttrain-merror:0.000969\teval-merror:0.202714\n",
      "[91]\ttrain-merror:0.000869\teval-merror:0.204774\n",
      "[92]\ttrain-merror:0.000902\teval-merror:0.204774\n",
      "[93]\ttrain-merror:0.000902\teval-merror:0.205029\n",
      "[94]\ttrain-merror:0.000935\teval-merror:0.205708\n",
      "[95]\ttrain-merror:0.001002\teval-merror:0.204264\n",
      "[96]\ttrain-merror:0.001002\teval-merror:0.204179\n",
      "[97]\ttrain-merror:0.000969\teval-merror:0.203861\n",
      "[98]\ttrain-merror:0.000969\teval-merror:0.202884\n",
      "[99]\ttrain-merror:0.000935\teval-merror:0.202502\n"
     ]
    }
   ],
   "source": [
    "# Find best iteration\n",
    "\n",
    "for train_index, train_test in enumerate(complete_cs_split):\n",
    "    train_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"train\"])].index.tolist()\n",
    "    test_indices = all_labels_df[all_labels_df[\"subject\"].isin(train_test[\"test\"])].index.tolist()\n",
    "    \n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    train_dmatrix = xgb.DMatrix(X_train, y_train)\n",
    "    test_dmatrix = xgb.DMatrix(X_test, y_test)\n",
    "    watchlist = [(train_dmatrix, \"train\"), (test_dmatrix, \"eval\")]\n",
    "    results = {}\n",
    "    \n",
    "    complete_cs_booster = xgb.train(params=PARAMS, dtrain=train_dmatrix, num_boost_round=NUM_ROUNDS, evals=watchlist, evals_result=results)\n",
    "    results_df = pd.DataFrame(columns=[\"train_index\", \"tree\", \"error\"])\n",
    "    for tree, error in enumerate(results[\"eval\"][\"merror\"]):\n",
    "        results_df.loc[tree] = [train_index, tree, error]\n",
    "    \n",
    "    with open(complete_cs_results_csv, \"a\") as f:\n",
    "        results_df.to_csv(f, header=False, index=False)\n",
    "        \n",
    "    if train_index == 1:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
